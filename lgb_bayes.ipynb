{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# pd.set_option('display.max_rows', 120)\n",
    "# pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maynard\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# train_dtypes = {\n",
    "#     'molecule_name': 'category',\n",
    "#     'atom_index_0': 'int8',\n",
    "#     'atom_index_1': 'int8',\n",
    "#     'type': 'category',\n",
    "#     'scalar_coupling_constant': 'float32'\n",
    "# }\n",
    "train_csv = pd.read_csv('train.csv', index_col='id')\n",
    "train_csv['molecule_index'] = train_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train_csv = train_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type', 'scalar_coupling_constant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    molecule_index  atom_index_0  atom_index_1  type  scalar_coupling_constant\n",
       "id                                                                            \n",
       "0                1             1             0  1JHC                   84.8076\n",
       "1                1             1             2  2JHH                  -11.2570\n",
       "2                1             1             3  2JHH                  -11.2548\n",
       "3                1             1             4  2JHH                  -11.2543\n",
       "4                1             2             0  1JHC                   84.8074"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (4658147, 5)\n",
      "Total:  204958468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                       37265176\n",
       "molecule_index              18632588\n",
       "atom_index_0                37265176\n",
       "atom_index_1                37265176\n",
       "type                        37265176\n",
       "scalar_coupling_constant    37265176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', train_csv.shape)\n",
    "print('Total: ', train_csv.memory_usage().sum())\n",
    "train_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = pd.read_csv('sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('test.csv', index_col='id')\n",
    "test_csv['molecule_index'] = test_csv['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test_csv = test_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         molecule_index  atom_index_0  atom_index_1  type\n",
       "id                                                       \n",
       "4658147               4             2             0  2JHC\n",
       "4658148               4             2             1  1JHC\n",
       "4658149               4             2             3  3JHH\n",
       "4658150               4             3             0  1JHC\n",
       "4658151               4             3             1  2JHC"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structures_dtypes = {\n",
    "#     'molecule_name': 'category',\n",
    "#     'atom_index': 'int8',\n",
    "#     'atom': 'category',\n",
    "#     'x': 'float32',\n",
    "#     'y': 'float32',\n",
    "#     'z': 'float32'\n",
    "# }\n",
    "structures_csv = pd.read_csv('structures.csv')\n",
    "structures_csv['molecule_index'] = structures_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "structures_csv = structures_csv[['molecule_index', 'atom_index', 'atom', 'x', 'y', 'z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>-0.028758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>-0.775543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molecule_index  atom_index  atom         x         y         z\n",
       "0               1           0     6 -0.012698  1.085804  0.008001\n",
       "1               1           1     1  0.002150 -0.006031  0.001976\n",
       "2               1           2     1  1.011731  1.463751  0.000277\n",
       "3               1           3     1 -0.540815  1.447527 -0.876644\n",
       "4               1           4     1 -0.523814  1.437933  0.906397\n",
       "5               2           0     7 -0.040426  1.024108  0.062564\n",
       "6               2           1     1  0.017257  0.012545 -0.027377\n",
       "7               2           2     1  0.915789  1.358745 -0.028758\n",
       "8               2           3     1 -0.520278  1.343532 -0.775543\n",
       "9               3           0     8 -0.034360  0.977540  0.007602"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_csv['atom'] = structures_csv['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "structures_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2358657, 6)\n",
      "Total:  87270389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                   80\n",
       "molecule_index     9434628\n",
       "atom_index        18869256\n",
       "atom               2358657\n",
       "x                 18869256\n",
       "y                 18869256\n",
       "z                 18869256\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', structures_csv.shape)\n",
    "print('Total: ', structures_csv.memory_usage().sum())\n",
    "structures_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_index'].isin(base['molecule_index'])]\n",
    "    return base, structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        (df['x_c'] - df['x'])**np.float32(2) +\n",
    "        (df['y_c'] - df['y'])**np.float32(2) + \n",
    "        (df['z_c'] - df['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_index'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    return df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43363, 73)\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full = build_couple_dataframe(train_csv, structures_csv, '1JHN', n_atoms=10)\n",
    "print(full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'molecule_index', 'atom_index_0', 'atom_index_1',\n",
       "       'scalar_coupling_constant', 'x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1',\n",
       "       'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
       "       'atom_9', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'y_2',\n",
       "       'y_3', 'y_4', 'y_5', 'y_6', 'y_7', 'y_8', 'y_9', 'z_2', 'z_3', 'z_4',\n",
       "       'z_5', 'z_6', 'z_7', 'z_8', 'z_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0',\n",
       "       'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1',\n",
       "       'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1',\n",
       "       'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1',\n",
       "       'd_9_2', 'd_9_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
       "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
       "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3',\n",
       "       'scalar_coupling_constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = take_n_atoms(full, 7)\n",
    "# LightGBM performs better with 0-s then with NaN-s\n",
    "df = df.fillna(0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import itertools\n",
    "from scipy import interp\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve, mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = df.drop(['scalar_coupling_constant'], axis=1)\n",
    "# y_data = df['scalar_coupling_constant']\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=128)\n",
    "# X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
    "    'max_depth': 9,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_y_data(some_csv, coupling_type, n_atoms):\n",
    "    full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    \n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    print(df.columns)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1)\n",
    "        y_data = df['scalar_coupling_constant']\n",
    "    else:\n",
    "        X_data = df\n",
    "        y_data = None\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_data, y_data = build_x_y_data(train_csv, '3JHN', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    learning_rate,\n",
    "    max_depth,\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    feature_fraction,\n",
    "    min_data_in_leaf,\n",
    "    reg_alpha,\n",
    "    reg_lambda\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    \n",
    "    columns = X_data.columns\n",
    "    train_index = range(int(len(X_data)*0.7))\n",
    "    valid_index = range(int(len(X_data)*0.7), len(X_data))\n",
    "    \n",
    "    X_train, X_valid = X_data[columns].iloc[train_index], X_data[columns].iloc[valid_index]\n",
    "    y_train, y_valid = y_data.iloc[train_index], y_data.iloc[valid_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'feature_fraction' : feature_fraction,\n",
    "              'learning_rate' : learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'objective': 'regression',\n",
    "              'save_binary': True,\n",
    "              'seed': 1337,\n",
    "              'feature_fraction_seed': 1337,\n",
    "              'bagging_seed': 1337,\n",
    "              'drop_seed': 1337,\n",
    "              'data_random_seed': 1337,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'verbose': 1,\n",
    "              'is_unbalance': False,\n",
    "              'boost_from_average': True,\n",
    "              'metric':'mae'}    \n",
    "    \n",
    "    \n",
    "    model = LGBMRegressor(**param, n_estimators=10000, n_jobs = -1)\n",
    "    model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n",
    "        verbose=1000, early_stopping_rounds=100)    \n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    score = np.log(mean_absolute_error(y_valid, y_pred))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_LGB = {\n",
    "    'num_leaves': (31, 300), \n",
    "    'min_data_in_leaf': (20, 200),\n",
    "    'max_depth': (5, 50),\n",
    "    'bagging_fraction' : (0.1, 0.9),\n",
    "    'feature_fraction' : (0.1, 0.9),\n",
    "    'learning_rate': (0.01, 0.2),  \n",
    "    'reg_alpha': (0, 1), \n",
    "    'reg_lambda': (0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_points = 10\n",
    "n_iter = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.0838097\tvalid_1's l1: 0.153671\n",
      "[2000]\ttraining's l1: 0.056495\tvalid_1's l1: 0.142359\n",
      "[3000]\ttraining's l1: 0.0434112\tvalid_1's l1: 0.137992\n",
      "[4000]\ttraining's l1: 0.0359163\tvalid_1's l1: 0.13581\n",
      "[5000]\ttraining's l1: 0.031184\tvalid_1's l1: 0.134506\n",
      "[6000]\ttraining's l1: 0.0279322\tvalid_1's l1: 0.133651\n",
      "[7000]\ttraining's l1: 0.0256865\tvalid_1's l1: 0.133075\n",
      "[8000]\ttraining's l1: 0.0240906\tvalid_1's l1: 0.132715\n",
      "Early stopping, best iteration is:\n",
      "[8123]\ttraining's l1: 0.0239607\tvalid_1's l1: 0.132678\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.02    \u001b[0m | \u001b[0m 0.4357  \u001b[0m | \u001b[0m 0.4188  \u001b[0m | \u001b[0m 0.1482  \u001b[0m | \u001b[0m 7.572   \u001b[0m | \u001b[0m 32.75   \u001b[0m | \u001b[0m 90.34   \u001b[0m | \u001b[0m 0.9552  \u001b[0m | \u001b[0m 0.205   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.0350733\tvalid_1's l1: 0.136764\n",
      "[2000]\ttraining's l1: 0.0184358\tvalid_1's l1: 0.133096\n",
      "[3000]\ttraining's l1: 0.0121808\tvalid_1's l1: 0.132062\n",
      "[4000]\ttraining's l1: 0.0090935\tvalid_1's l1: 0.131615\n",
      "[5000]\ttraining's l1: 0.00737009\tvalid_1's l1: 0.131385\n",
      "[6000]\ttraining's l1: 0.00634872\tvalid_1's l1: 0.131251\n",
      "[7000]\ttraining's l1: 0.00576958\tvalid_1's l1: 0.131177\n",
      "Early stopping, best iteration is:\n",
      "[7073]\ttraining's l1: 0.0057408\tvalid_1's l1: 0.131172\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.031   \u001b[0m | \u001b[0m 0.6681  \u001b[0m | \u001b[0m 0.7106  \u001b[0m | \u001b[0m 0.1748  \u001b[0m | \u001b[0m 41.03   \u001b[0m | \u001b[0m 120.3   \u001b[0m | \u001b[0m 214.0   \u001b[0m | \u001b[0m 0.1913  \u001b[0m | \u001b[0m 0.3419  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.105918\tvalid_1's l1: 0.153963\n",
      "[2000]\ttraining's l1: 0.0762218\tvalid_1's l1: 0.137047\n",
      "[3000]\ttraining's l1: 0.0608958\tvalid_1's l1: 0.129773\n",
      "[4000]\ttraining's l1: 0.0510788\tvalid_1's l1: 0.125621\n",
      "[5000]\ttraining's l1: 0.0441994\tvalid_1's l1: 0.122911\n",
      "[6000]\ttraining's l1: 0.0390055\tvalid_1's l1: 0.121103\n",
      "[7000]\ttraining's l1: 0.0349963\tvalid_1's l1: 0.119743\n",
      "[8000]\ttraining's l1: 0.0317683\tvalid_1's l1: 0.118705\n",
      "[9000]\ttraining's l1: 0.0291492\tvalid_1's l1: 0.117897\n",
      "[10000]\ttraining's l1: 0.0269928\tvalid_1's l1: 0.11727\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0269928\tvalid_1's l1: 0.11727\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.143   \u001b[0m | \u001b[0m 0.334   \u001b[0m | \u001b[0m 0.5321  \u001b[0m | \u001b[0m 0.03962 \u001b[0m | \u001b[0m 12.44   \u001b[0m | \u001b[0m 40.23   \u001b[0m | \u001b[0m 107.3   \u001b[0m | \u001b[0m 0.6421  \u001b[0m | \u001b[0m 0.5282  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.111135\tvalid_1's l1: 0.156394\n",
      "[2000]\ttraining's l1: 0.0821397\tvalid_1's l1: 0.13809\n",
      "[3000]\ttraining's l1: 0.0670057\tvalid_1's l1: 0.130285\n",
      "[4000]\ttraining's l1: 0.0569299\tvalid_1's l1: 0.125414\n",
      "[5000]\ttraining's l1: 0.0496409\tvalid_1's l1: 0.122391\n",
      "[6000]\ttraining's l1: 0.0440522\tvalid_1's l1: 0.120235\n",
      "[7000]\ttraining's l1: 0.0395932\tvalid_1's l1: 0.118615\n",
      "[8000]\ttraining's l1: 0.0359033\tvalid_1's l1: 0.117292\n",
      "[9000]\ttraining's l1: 0.0328328\tvalid_1's l1: 0.11627\n",
      "[10000]\ttraining's l1: 0.0302536\tvalid_1's l1: 0.115431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0302536\tvalid_1's l1: 0.115431\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.159   \u001b[0m | \u001b[0m 0.4323  \u001b[0m | \u001b[0m 0.5897  \u001b[0m | \u001b[0m 0.01962 \u001b[0m | \u001b[0m 34.39   \u001b[0m | \u001b[0m 114.0   \u001b[0m | \u001b[0m 184.0   \u001b[0m | \u001b[0m 0.2624  \u001b[0m | \u001b[0m 0.3179  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.0538928\tvalid_1's l1: 0.132819\n",
      "[2000]\ttraining's l1: 0.0329847\tvalid_1's l1: 0.125842\n",
      "[3000]\ttraining's l1: 0.0234214\tvalid_1's l1: 0.123218\n",
      "[4000]\ttraining's l1: 0.018128\tvalid_1's l1: 0.12196\n",
      "[5000]\ttraining's l1: 0.0147971\tvalid_1's l1: 0.121266\n",
      "[6000]\ttraining's l1: 0.0125602\tvalid_1's l1: 0.120855\n",
      "[7000]\ttraining's l1: 0.0109853\tvalid_1's l1: 0.120583\n",
      "[8000]\ttraining's l1: 0.00984046\tvalid_1's l1: 0.120396\n",
      "[9000]\ttraining's l1: 0.00904627\tvalid_1's l1: 0.120263\n",
      "Early stopping, best iteration is:\n",
      "[9371]\ttraining's l1: 0.00883577\tvalid_1's l1: 0.120228\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.118   \u001b[0m | \u001b[0m 0.1592  \u001b[0m | \u001b[0m 0.6376  \u001b[0m | \u001b[0m 0.08383 \u001b[0m | \u001b[0m 34.71   \u001b[0m | \u001b[0m 121.1   \u001b[0m | \u001b[0m 217.0   \u001b[0m | \u001b[0m 0.2841  \u001b[0m | \u001b[0m 0.5093  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.0330869\tvalid_1's l1: 0.136895\n",
      "[2000]\ttraining's l1: 0.0220335\tvalid_1's l1: 0.134016\n",
      "Early stopping, best iteration is:\n",
      "[2613]\ttraining's l1: 0.0199676\tvalid_1's l1: 0.133509\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-2.014   \u001b[0m | \u001b[95m 0.71    \u001b[0m | \u001b[95m 0.4676  \u001b[0m | \u001b[95m 0.1687  \u001b[0m | \u001b[95m 26.81   \u001b[0m | \u001b[95m 74.57   \u001b[0m | \u001b[95m 284.5   \u001b[0m | \u001b[95m 0.9047  \u001b[0m | \u001b[95m 0.4953  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.131413\tvalid_1's l1: 0.174711\n",
      "[2000]\ttraining's l1: 0.102628\tvalid_1's l1: 0.154941\n",
      "[3000]\ttraining's l1: 0.0866563\tvalid_1's l1: 0.146369\n",
      "[4000]\ttraining's l1: 0.0757375\tvalid_1's l1: 0.141225\n",
      "[5000]\ttraining's l1: 0.0674293\tvalid_1's l1: 0.137821\n",
      "[6000]\ttraining's l1: 0.0608533\tvalid_1's l1: 0.135384\n",
      "[7000]\ttraining's l1: 0.0554929\tvalid_1's l1: 0.133498\n",
      "[8000]\ttraining's l1: 0.0508687\tvalid_1's l1: 0.132025\n",
      "[9000]\ttraining's l1: 0.0469673\tvalid_1's l1: 0.130704\n",
      "[10000]\ttraining's l1: 0.0435279\tvalid_1's l1: 0.129724\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0435279\tvalid_1's l1: 0.129724\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.042   \u001b[0m | \u001b[0m 0.8935  \u001b[0m | \u001b[0m 0.8726  \u001b[0m | \u001b[0m 0.08975 \u001b[0m | \u001b[0m 6.551   \u001b[0m | \u001b[0m 106.4   \u001b[0m | \u001b[0m 55.59   \u001b[0m | \u001b[0m 0.06144 \u001b[0m | \u001b[0m 0.8061  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.111971\tvalid_1's l1: 0.165958\n",
      "[2000]\ttraining's l1: 0.0823724\tvalid_1's l1: 0.148652\n",
      "[3000]\ttraining's l1: 0.066771\tvalid_1's l1: 0.141195\n",
      "[4000]\ttraining's l1: 0.0565906\tvalid_1's l1: 0.137083\n",
      "[5000]\ttraining's l1: 0.0492388\tvalid_1's l1: 0.134305\n",
      "[6000]\ttraining's l1: 0.0437441\tvalid_1's l1: 0.132454\n",
      "[7000]\ttraining's l1: 0.0394935\tvalid_1's l1: 0.131085\n",
      "[8000]\ttraining's l1: 0.0360519\tvalid_1's l1: 0.130007\n",
      "[9000]\ttraining's l1: 0.0332378\tvalid_1's l1: 0.129175\n",
      "[10000]\ttraining's l1: 0.0309147\tvalid_1's l1: 0.128498\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0309147\tvalid_1's l1: 0.128498\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.052   \u001b[0m | \u001b[0m 0.1185  \u001b[0m | \u001b[0m 0.3431  \u001b[0m | \u001b[0m 0.09772 \u001b[0m | \u001b[0m 24.94   \u001b[0m | \u001b[0m 101.8   \u001b[0m | \u001b[0m 56.3    \u001b[0m | \u001b[0m 0.7839  \u001b[0m | \u001b[0m 0.462   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.0888751\tvalid_1's l1: 0.156662\n",
      "[2000]\ttraining's l1: 0.0612613\tvalid_1's l1: 0.144844\n",
      "[3000]\ttraining's l1: 0.0467888\tvalid_1's l1: 0.139902\n",
      "[4000]\ttraining's l1: 0.0375641\tvalid_1's l1: 0.137169\n",
      "[5000]\ttraining's l1: 0.0311608\tvalid_1's l1: 0.13549\n",
      "[6000]\ttraining's l1: 0.0264676\tvalid_1's l1: 0.134354\n",
      "[7000]\ttraining's l1: 0.0229072\tvalid_1's l1: 0.133592\n",
      "[8000]\ttraining's l1: 0.0201227\tvalid_1's l1: 0.133048\n",
      "[9000]\ttraining's l1: 0.0179318\tvalid_1's l1: 0.13262\n",
      "[10000]\ttraining's l1: 0.0161494\tvalid_1's l1: 0.13226\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0161494\tvalid_1's l1: 0.13226\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.023   \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 0.5824  \u001b[0m | \u001b[0m 0.1741  \u001b[0m | \u001b[0m 46.67   \u001b[0m | \u001b[0m 136.2   \u001b[0m | \u001b[0m 56.9    \u001b[0m | \u001b[0m 0.2126  \u001b[0m | \u001b[0m 0.4816  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.100972\tvalid_1's l1: 0.153189\n",
      "[2000]\ttraining's l1: 0.0740008\tvalid_1's l1: 0.137891\n",
      "[3000]\ttraining's l1: 0.0598241\tvalid_1's l1: 0.131672\n",
      "[4000]\ttraining's l1: 0.0506473\tvalid_1's l1: 0.127796\n",
      "[5000]\ttraining's l1: 0.0439673\tvalid_1's l1: 0.125459\n",
      "[6000]\ttraining's l1: 0.0389436\tvalid_1's l1: 0.123671\n",
      "[7000]\ttraining's l1: 0.0350121\tvalid_1's l1: 0.12238\n",
      "[8000]\ttraining's l1: 0.0318766\tvalid_1's l1: 0.121385\n",
      "[9000]\ttraining's l1: 0.0293227\tvalid_1's l1: 0.12061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\ttraining's l1: 0.0271852\tvalid_1's l1: 0.120041\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0271852\tvalid_1's l1: 0.120041\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.12    \u001b[0m | \u001b[0m 0.58    \u001b[0m | \u001b[0m 0.8788  \u001b[0m | \u001b[0m 0.05806 \u001b[0m | \u001b[0m 33.03   \u001b[0m | \u001b[0m 153.8   \u001b[0m | \u001b[0m 91.89   \u001b[0m | \u001b[0m 0.7389  \u001b[0m | \u001b[0m 0.1649  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's l1: 0.0260152\tvalid_1's l1: 0.135876\n",
      "[2000]\ttraining's l1: 0.0125312\tvalid_1's l1: 0.133288\n",
      "[3000]\ttraining's l1: 0.00744442\tvalid_1's l1: 0.132612\n",
      "[4000]\ttraining's l1: 0.00484919\tvalid_1's l1: 0.132314\n",
      "[5000]\ttraining's l1: 0.00337789\tvalid_1's l1: 0.132183\n",
      "[6000]\ttraining's l1: 0.00247676\tvalid_1's l1: 0.132116\n",
      "[7000]\ttraining's l1: 0.00187435\tvalid_1's l1: 0.132068\n",
      "[8000]\ttraining's l1: 0.00145231\tvalid_1's l1: 0.132038\n",
      "[9000]\ttraining's l1: 0.00115476\tvalid_1's l1: 0.13202\n",
      "Early stopping, best iteration is:\n",
      "[9628]\ttraining's l1: 0.00100845\tvalid_1's l1: 0.13201\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.025   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.9, 0.9, 0.2, 50.0, 20.0, 300.0, 0.0, 0.0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-e72ae3d958bc>\u001b[0m in \u001b[0;36mLGB_bayesian\u001b[1;34m(learning_rate, max_depth, num_leaves, bagging_fraction, feature_fraction, min_data_in_leaf, reg_alpha, reg_lambda)\u001b[0m\n\u001b[0;32m     54\u001b[0m     model.fit(X_train, y_train, \n\u001b[0;32m     55\u001b[0m         \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         verbose=1000, early_stopping_rounds=100)    \n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    683\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "    \n",
    "\n",
    "# |  6        | -0.8103   |  0.3519   |  0.4793   |  0.01981  |  19.78    |  31.09    |  88.22    \n",
    "# |  0.7319   |  0.02046  |\n",
    "\n",
    "# |  4        | -0.398    |  0.2817   |  0.8268   |  0.0313   |  37.53    |  58.55    |  215.7    \n",
    "# |  0.6199   |  0.06773  |\n",
    "\n",
    "# |  1        | -1.96     |  0.3144   |  0.6463   |  0.0338   |  29.72    |  34.21    |  275.5    \n",
    "# |  0.738    |  0.4629   |\n",
    "\n",
    "# |  2        | -1.893    |  0.351    |  0.3879   |  0.04198  |  12.06    |  105.4    |  200.7    \n",
    "# |  0.8291   |  0.4697   |\n",
    "\n",
    "# |  10       | -1.372    |  0.1386   |  0.7393   |  0.1277   |  10.49    |  25.28    |  148.2    \n",
    "# |  0.4687   |  0.1326   |\n",
    "\n",
    "# |  9        | -1.973    |  0.1856   |  0.6099   |  0.06415  |  28.39    |  163.8    |  115.7    \n",
    "# |  0.8427   |  0.3105   |\n",
    "\n",
    "# |  6        | -1.308    |  0.2464   |  0.5808   |  0.1378   |  17.85    |  155.7    |  240.5    \n",
    "# |  0.07945  |  0.439    |\n",
    "\n",
    "# |  4        | -2.159    |  0.4323   |  0.5897   |  0.01962  |  34.39    |  114.0    |  184.0    \n",
    "# |  0.2624   |  0.3179   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesianOptimization' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-168b4adf757c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLGB_BO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BayesianOptimization' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "LGB_BO.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.1,\n",
       " 'feature_fraction': 0.1,\n",
       " 'learning_rate': 0.2,\n",
       " 'max_depth': 50.0,\n",
       " 'min_data_in_leaf': 20.0,\n",
       " 'num_leaves': 300.0,\n",
       " 'reg_alpha': 1.0,\n",
       " 'reg_lambda': 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_for_one_coupling_type(coupling_type, submission, n_atoms, n_folds=5, n_splits=5, random_state=128):\n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    \n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms)\n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "\n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "        model = LGBMRegressor(**LGB_PARAMS, n_estimators=5000, n_jobs = -1)\n",
    "        model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "            verbose=500, early_stopping_rounds=200)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        \n",
    "        cv_score += val_score / n_folds\n",
    "        y_pred += model.predict(X_test) / n_folds\n",
    "        \n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training Model for 1JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.432629\tvalid_1's l1: 0.538931\n",
      "[200]\ttraining's l1: 0.356809\tvalid_1's l1: 0.483761\n",
      "[300]\ttraining's l1: 0.309424\tvalid_1's l1: 0.455831\n",
      "[400]\ttraining's l1: 0.274702\tvalid_1's l1: 0.438134\n",
      "[500]\ttraining's l1: 0.248383\tvalid_1's l1: 0.428061\n",
      "[600]\ttraining's l1: 0.226356\tvalid_1's l1: 0.420704\n",
      "[700]\ttraining's l1: 0.208145\tvalid_1's l1: 0.413465\n",
      "[800]\ttraining's l1: 0.192187\tvalid_1's l1: 0.407994\n",
      "[900]\ttraining's l1: 0.177712\tvalid_1's l1: 0.403785\n",
      "[1000]\ttraining's l1: 0.165821\tvalid_1's l1: 0.400392\n",
      "[1100]\ttraining's l1: 0.15492\tvalid_1's l1: 0.398147\n",
      "[1200]\ttraining's l1: 0.14472\tvalid_1's l1: 0.395853\n",
      "[1300]\ttraining's l1: 0.135947\tvalid_1's l1: 0.393845\n",
      "[1400]\ttraining's l1: 0.127714\tvalid_1's l1: 0.392292\n",
      "[1500]\ttraining's l1: 0.120589\tvalid_1's l1: 0.390779\n",
      "[1600]\ttraining's l1: 0.114132\tvalid_1's l1: 0.38958\n",
      "[1700]\ttraining's l1: 0.107922\tvalid_1's l1: 0.388239\n",
      "[1800]\ttraining's l1: 0.102077\tvalid_1's l1: 0.387272\n",
      "[1900]\ttraining's l1: 0.0966055\tvalid_1's l1: 0.386208\n",
      "[2000]\ttraining's l1: 0.0919277\tvalid_1's l1: 0.38533\n",
      "[2100]\ttraining's l1: 0.0871912\tvalid_1's l1: 0.38459\n",
      "[2200]\ttraining's l1: 0.0830747\tvalid_1's l1: 0.384031\n",
      "[2300]\ttraining's l1: 0.0793666\tvalid_1's l1: 0.38375\n",
      "[2400]\ttraining's l1: 0.0758979\tvalid_1's l1: 0.383156\n",
      "[2500]\ttraining's l1: 0.0723666\tvalid_1's l1: 0.382568\n",
      "[2600]\ttraining's l1: 0.0691885\tvalid_1's l1: 0.382178\n",
      "[2700]\ttraining's l1: 0.0661387\tvalid_1's l1: 0.381961\n",
      "[2800]\ttraining's l1: 0.0632254\tvalid_1's l1: 0.3815\n",
      "[2900]\ttraining's l1: 0.0605307\tvalid_1's l1: 0.381229\n",
      "[3000]\ttraining's l1: 0.0581367\tvalid_1's l1: 0.380882\n",
      "[3100]\ttraining's l1: 0.0557202\tvalid_1's l1: 0.380532\n",
      "[3200]\ttraining's l1: 0.0535184\tvalid_1's l1: 0.38022\n",
      "[3300]\ttraining's l1: 0.0513484\tvalid_1's l1: 0.380056\n",
      "[3400]\ttraining's l1: 0.0493676\tvalid_1's l1: 0.379847\n",
      "[3500]\ttraining's l1: 0.0473978\tvalid_1's l1: 0.379629\n",
      "[3600]\ttraining's l1: 0.0456919\tvalid_1's l1: 0.379577\n",
      "[3700]\ttraining's l1: 0.0440114\tvalid_1's l1: 0.379506\n",
      "[3800]\ttraining's l1: 0.0424643\tvalid_1's l1: 0.379287\n",
      "[3900]\ttraining's l1: 0.0409045\tvalid_1's l1: 0.379212\n",
      "[4000]\ttraining's l1: 0.039314\tvalid_1's l1: 0.379118\n",
      "[4100]\ttraining's l1: 0.0378728\tvalid_1's l1: 0.37892\n",
      "[4200]\ttraining's l1: 0.0365579\tvalid_1's l1: 0.378906\n",
      "[4300]\ttraining's l1: 0.0352272\tvalid_1's l1: 0.378748\n",
      "[4400]\ttraining's l1: 0.0340458\tvalid_1's l1: 0.378645\n",
      "[4500]\ttraining's l1: 0.0328777\tvalid_1's l1: 0.378504\n",
      "[4600]\ttraining's l1: 0.0317374\tvalid_1's l1: 0.378485\n",
      "[4700]\ttraining's l1: 0.0306215\tvalid_1's l1: 0.378456\n",
      "[4800]\ttraining's l1: 0.029514\tvalid_1's l1: 0.378321\n",
      "[4900]\ttraining's l1: 0.0285965\tvalid_1's l1: 0.378267\n",
      "[5000]\ttraining's l1: 0.0276238\tvalid_1's l1: 0.378256\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0276238\tvalid_1's l1: 0.378256\n",
      "1JHN Fold 0, logMAE: -0.972183972201525\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.424326\tvalid_1's l1: 0.511964\n",
      "[200]\ttraining's l1: 0.350725\tvalid_1's l1: 0.467005\n",
      "[300]\ttraining's l1: 0.30516\tvalid_1's l1: 0.443484\n",
      "[400]\ttraining's l1: 0.27096\tvalid_1's l1: 0.428055\n",
      "[500]\ttraining's l1: 0.244288\tvalid_1's l1: 0.417345\n",
      "[600]\ttraining's l1: 0.223017\tvalid_1's l1: 0.409476\n",
      "[700]\ttraining's l1: 0.205215\tvalid_1's l1: 0.403954\n",
      "[800]\ttraining's l1: 0.189802\tvalid_1's l1: 0.398986\n",
      "[900]\ttraining's l1: 0.176133\tvalid_1's l1: 0.395611\n",
      "[1000]\ttraining's l1: 0.164402\tvalid_1's l1: 0.391545\n",
      "[1100]\ttraining's l1: 0.153724\tvalid_1's l1: 0.388434\n",
      "[1200]\ttraining's l1: 0.144337\tvalid_1's l1: 0.386247\n",
      "[1300]\ttraining's l1: 0.135661\tvalid_1's l1: 0.384063\n",
      "[1400]\ttraining's l1: 0.127822\tvalid_1's l1: 0.382442\n",
      "[1500]\ttraining's l1: 0.120584\tvalid_1's l1: 0.380979\n",
      "[1600]\ttraining's l1: 0.113987\tvalid_1's l1: 0.379923\n",
      "[1700]\ttraining's l1: 0.10796\tvalid_1's l1: 0.379024\n",
      "[1800]\ttraining's l1: 0.102355\tvalid_1's l1: 0.377808\n",
      "[1900]\ttraining's l1: 0.0970846\tvalid_1's l1: 0.37694\n",
      "[2000]\ttraining's l1: 0.0921913\tvalid_1's l1: 0.376038\n",
      "[2100]\ttraining's l1: 0.0878204\tvalid_1's l1: 0.375361\n",
      "[2200]\ttraining's l1: 0.0835405\tvalid_1's l1: 0.374701\n",
      "[2300]\ttraining's l1: 0.079642\tvalid_1's l1: 0.374173\n",
      "[2400]\ttraining's l1: 0.0760861\tvalid_1's l1: 0.373797\n",
      "[2500]\ttraining's l1: 0.0724038\tvalid_1's l1: 0.373119\n",
      "[2600]\ttraining's l1: 0.0692961\tvalid_1's l1: 0.372725\n",
      "[2700]\ttraining's l1: 0.066187\tvalid_1's l1: 0.372285\n",
      "[2800]\ttraining's l1: 0.063433\tvalid_1's l1: 0.371901\n",
      "[2900]\ttraining's l1: 0.0607207\tvalid_1's l1: 0.371675\n",
      "[3000]\ttraining's l1: 0.0580251\tvalid_1's l1: 0.371423\n",
      "[3100]\ttraining's l1: 0.05552\tvalid_1's l1: 0.371221\n",
      "[3200]\ttraining's l1: 0.0531814\tvalid_1's l1: 0.370875\n",
      "[3300]\ttraining's l1: 0.0509362\tvalid_1's l1: 0.370699\n",
      "[3400]\ttraining's l1: 0.0489558\tvalid_1's l1: 0.370534\n",
      "[3500]\ttraining's l1: 0.047055\tvalid_1's l1: 0.370267\n",
      "[3600]\ttraining's l1: 0.0453131\tvalid_1's l1: 0.370056\n",
      "[3700]\ttraining's l1: 0.0437065\tvalid_1's l1: 0.369882\n",
      "[3800]\ttraining's l1: 0.0420644\tvalid_1's l1: 0.369728\n",
      "[3900]\ttraining's l1: 0.0405168\tvalid_1's l1: 0.369634\n",
      "[4000]\ttraining's l1: 0.0390427\tvalid_1's l1: 0.369473\n",
      "[4100]\ttraining's l1: 0.0376223\tvalid_1's l1: 0.369417\n",
      "[4200]\ttraining's l1: 0.0363557\tvalid_1's l1: 0.369303\n",
      "[4300]\ttraining's l1: 0.0350512\tvalid_1's l1: 0.369224\n",
      "[4400]\ttraining's l1: 0.0338654\tvalid_1's l1: 0.369087\n",
      "[4500]\ttraining's l1: 0.0327746\tvalid_1's l1: 0.368956\n",
      "[4600]\ttraining's l1: 0.0316767\tvalid_1's l1: 0.368927\n",
      "[4700]\ttraining's l1: 0.0305988\tvalid_1's l1: 0.368815\n",
      "[4800]\ttraining's l1: 0.02966\tvalid_1's l1: 0.368783\n",
      "[4900]\ttraining's l1: 0.0286694\tvalid_1's l1: 0.368756\n",
      "[5000]\ttraining's l1: 0.027746\tvalid_1's l1: 0.368686\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.027746\tvalid_1's l1: 0.368686\n",
      "1JHN Fold 1, logMAE: -0.9978106984804568\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.422844\tvalid_1's l1: 0.511888\n",
      "[200]\ttraining's l1: 0.349835\tvalid_1's l1: 0.465977\n",
      "[300]\ttraining's l1: 0.299524\tvalid_1's l1: 0.442132\n",
      "[400]\ttraining's l1: 0.268307\tvalid_1's l1: 0.429424\n",
      "[500]\ttraining's l1: 0.242014\tvalid_1's l1: 0.419537\n",
      "[600]\ttraining's l1: 0.221189\tvalid_1's l1: 0.410956\n",
      "[700]\ttraining's l1: 0.204028\tvalid_1's l1: 0.405324\n",
      "[800]\ttraining's l1: 0.189322\tvalid_1's l1: 0.400209\n",
      "[900]\ttraining's l1: 0.174974\tvalid_1's l1: 0.395994\n",
      "[1000]\ttraining's l1: 0.162314\tvalid_1's l1: 0.392326\n",
      "[1100]\ttraining's l1: 0.152287\tvalid_1's l1: 0.389858\n",
      "[1200]\ttraining's l1: 0.142785\tvalid_1's l1: 0.387365\n",
      "[1300]\ttraining's l1: 0.134365\tvalid_1's l1: 0.385285\n",
      "[1400]\ttraining's l1: 0.126407\tvalid_1's l1: 0.383185\n",
      "[1500]\ttraining's l1: 0.119463\tvalid_1's l1: 0.381737\n",
      "[1600]\ttraining's l1: 0.113008\tvalid_1's l1: 0.380367\n",
      "[1700]\ttraining's l1: 0.10705\tvalid_1's l1: 0.37925\n",
      "[1800]\ttraining's l1: 0.101181\tvalid_1's l1: 0.377908\n",
      "[1900]\ttraining's l1: 0.0962991\tvalid_1's l1: 0.377099\n",
      "[2000]\ttraining's l1: 0.0913862\tvalid_1's l1: 0.376124\n",
      "[2100]\ttraining's l1: 0.0869091\tvalid_1's l1: 0.375591\n",
      "[2200]\ttraining's l1: 0.0826798\tvalid_1's l1: 0.37491\n",
      "[2300]\ttraining's l1: 0.078736\tvalid_1's l1: 0.374542\n",
      "[2400]\ttraining's l1: 0.0750016\tvalid_1's l1: 0.373809\n",
      "[2500]\ttraining's l1: 0.0716241\tvalid_1's l1: 0.37332\n",
      "[2600]\ttraining's l1: 0.0683641\tvalid_1's l1: 0.372925\n",
      "[2700]\ttraining's l1: 0.0654316\tvalid_1's l1: 0.37235\n",
      "[2800]\ttraining's l1: 0.0625947\tvalid_1's l1: 0.371973\n",
      "[2900]\ttraining's l1: 0.0598549\tvalid_1's l1: 0.371714\n",
      "[3000]\ttraining's l1: 0.0572724\tvalid_1's l1: 0.371361\n",
      "[3100]\ttraining's l1: 0.0549896\tvalid_1's l1: 0.370949\n",
      "[3200]\ttraining's l1: 0.0527588\tvalid_1's l1: 0.370749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3300]\ttraining's l1: 0.0506805\tvalid_1's l1: 0.370419\n",
      "[3400]\ttraining's l1: 0.0486396\tvalid_1's l1: 0.370093\n",
      "[3500]\ttraining's l1: 0.0467844\tvalid_1's l1: 0.369851\n",
      "[3600]\ttraining's l1: 0.0450308\tvalid_1's l1: 0.369605\n",
      "[3700]\ttraining's l1: 0.0433698\tvalid_1's l1: 0.369429\n",
      "[3800]\ttraining's l1: 0.0416962\tvalid_1's l1: 0.369184\n",
      "[3900]\ttraining's l1: 0.040164\tvalid_1's l1: 0.369051\n",
      "[4000]\ttraining's l1: 0.0386366\tvalid_1's l1: 0.368953\n",
      "[4100]\ttraining's l1: 0.0372103\tvalid_1's l1: 0.368725\n",
      "[4200]\ttraining's l1: 0.0358809\tvalid_1's l1: 0.368624\n",
      "[4300]\ttraining's l1: 0.0346416\tvalid_1's l1: 0.368522\n",
      "[4400]\ttraining's l1: 0.0335301\tvalid_1's l1: 0.368417\n",
      "[4500]\ttraining's l1: 0.0323609\tvalid_1's l1: 0.36832\n",
      "[4600]\ttraining's l1: 0.0312225\tvalid_1's l1: 0.368207\n",
      "[4700]\ttraining's l1: 0.0302087\tvalid_1's l1: 0.368097\n",
      "[4800]\ttraining's l1: 0.0291945\tvalid_1's l1: 0.368047\n",
      "[4900]\ttraining's l1: 0.0282399\tvalid_1's l1: 0.36796\n",
      "[5000]\ttraining's l1: 0.0273016\tvalid_1's l1: 0.367883\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0273016\tvalid_1's l1: 0.367883\n",
      "1JHN Fold 2, logMAE: -0.9999909783525776\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.422293\tvalid_1's l1: 0.504777\n",
      "[200]\ttraining's l1: 0.349239\tvalid_1's l1: 0.461321\n",
      "[300]\ttraining's l1: 0.305602\tvalid_1's l1: 0.440639\n",
      "[400]\ttraining's l1: 0.273274\tvalid_1's l1: 0.426118\n",
      "[500]\ttraining's l1: 0.247752\tvalid_1's l1: 0.414804\n",
      "[600]\ttraining's l1: 0.22577\tvalid_1's l1: 0.406606\n",
      "[700]\ttraining's l1: 0.207407\tvalid_1's l1: 0.400906\n",
      "[800]\ttraining's l1: 0.192679\tvalid_1's l1: 0.395968\n",
      "[900]\ttraining's l1: 0.178575\tvalid_1's l1: 0.391177\n",
      "[1000]\ttraining's l1: 0.165786\tvalid_1's l1: 0.387758\n",
      "[1100]\ttraining's l1: 0.154872\tvalid_1's l1: 0.384708\n",
      "[1200]\ttraining's l1: 0.145541\tvalid_1's l1: 0.38268\n",
      "[1300]\ttraining's l1: 0.1365\tvalid_1's l1: 0.380185\n",
      "[1400]\ttraining's l1: 0.128634\tvalid_1's l1: 0.377979\n",
      "[1500]\ttraining's l1: 0.121542\tvalid_1's l1: 0.376553\n",
      "[1600]\ttraining's l1: 0.114883\tvalid_1's l1: 0.375507\n",
      "[1700]\ttraining's l1: 0.108724\tvalid_1's l1: 0.374292\n",
      "[1800]\ttraining's l1: 0.102996\tvalid_1's l1: 0.373234\n",
      "[1900]\ttraining's l1: 0.0979438\tvalid_1's l1: 0.372418\n",
      "[2000]\ttraining's l1: 0.0928058\tvalid_1's l1: 0.371327\n",
      "[2100]\ttraining's l1: 0.0882068\tvalid_1's l1: 0.370473\n",
      "[2200]\ttraining's l1: 0.0840366\tvalid_1's l1: 0.369638\n",
      "[2300]\ttraining's l1: 0.0797398\tvalid_1's l1: 0.36898\n",
      "[2400]\ttraining's l1: 0.0760442\tvalid_1's l1: 0.368182\n",
      "[2500]\ttraining's l1: 0.0726149\tvalid_1's l1: 0.367783\n",
      "[2600]\ttraining's l1: 0.0693225\tvalid_1's l1: 0.367198\n",
      "[2700]\ttraining's l1: 0.066262\tvalid_1's l1: 0.366772\n",
      "[2800]\ttraining's l1: 0.0634137\tvalid_1's l1: 0.366268\n",
      "[2900]\ttraining's l1: 0.060708\tvalid_1's l1: 0.365835\n",
      "[3000]\ttraining's l1: 0.0581538\tvalid_1's l1: 0.365664\n",
      "[3100]\ttraining's l1: 0.0557112\tvalid_1's l1: 0.3655\n",
      "[3200]\ttraining's l1: 0.053387\tvalid_1's l1: 0.36533\n",
      "[3300]\ttraining's l1: 0.0512036\tvalid_1's l1: 0.36497\n",
      "[3400]\ttraining's l1: 0.0491495\tvalid_1's l1: 0.364738\n",
      "[3500]\ttraining's l1: 0.047302\tvalid_1's l1: 0.364504\n",
      "[3600]\ttraining's l1: 0.0454173\tvalid_1's l1: 0.364299\n",
      "[3700]\ttraining's l1: 0.0437453\tvalid_1's l1: 0.364153\n",
      "[3800]\ttraining's l1: 0.0421802\tvalid_1's l1: 0.363945\n",
      "[3900]\ttraining's l1: 0.0405832\tvalid_1's l1: 0.363718\n",
      "[4000]\ttraining's l1: 0.0391838\tvalid_1's l1: 0.363618\n",
      "[4100]\ttraining's l1: 0.0376748\tvalid_1's l1: 0.363464\n",
      "[4200]\ttraining's l1: 0.036364\tvalid_1's l1: 0.363362\n",
      "[4300]\ttraining's l1: 0.0351033\tvalid_1's l1: 0.363151\n",
      "[4400]\ttraining's l1: 0.0339396\tvalid_1's l1: 0.363053\n",
      "[4500]\ttraining's l1: 0.0327055\tvalid_1's l1: 0.362987\n",
      "[4600]\ttraining's l1: 0.0315468\tvalid_1's l1: 0.362905\n",
      "[4700]\ttraining's l1: 0.0304445\tvalid_1's l1: 0.362735\n",
      "[4800]\ttraining's l1: 0.0294926\tvalid_1's l1: 0.362708\n",
      "[4900]\ttraining's l1: 0.0285594\tvalid_1's l1: 0.362593\n",
      "[5000]\ttraining's l1: 0.0276817\tvalid_1's l1: 0.362502\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0276817\tvalid_1's l1: 0.362502\n",
      "1JHN Fold 3, logMAE: -1.0147261118882789\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.427031\tvalid_1's l1: 0.5221\n",
      "[200]\ttraining's l1: 0.347848\tvalid_1's l1: 0.470528\n",
      "[300]\ttraining's l1: 0.304998\tvalid_1's l1: 0.446672\n",
      "[400]\ttraining's l1: 0.27294\tvalid_1's l1: 0.430982\n",
      "[500]\ttraining's l1: 0.24856\tvalid_1's l1: 0.421206\n",
      "[600]\ttraining's l1: 0.227612\tvalid_1's l1: 0.414095\n",
      "[700]\ttraining's l1: 0.208771\tvalid_1's l1: 0.407207\n",
      "[800]\ttraining's l1: 0.193099\tvalid_1's l1: 0.402193\n",
      "[900]\ttraining's l1: 0.178844\tvalid_1's l1: 0.398289\n",
      "[1000]\ttraining's l1: 0.166596\tvalid_1's l1: 0.395323\n",
      "[1100]\ttraining's l1: 0.155486\tvalid_1's l1: 0.392091\n",
      "[1200]\ttraining's l1: 0.14595\tvalid_1's l1: 0.389602\n",
      "[1300]\ttraining's l1: 0.137138\tvalid_1's l1: 0.387007\n",
      "[1400]\ttraining's l1: 0.129497\tvalid_1's l1: 0.385288\n",
      "[1500]\ttraining's l1: 0.122537\tvalid_1's l1: 0.383846\n",
      "[1600]\ttraining's l1: 0.115787\tvalid_1's l1: 0.382022\n",
      "[1700]\ttraining's l1: 0.10937\tvalid_1's l1: 0.380543\n",
      "[1800]\ttraining's l1: 0.103606\tvalid_1's l1: 0.379619\n",
      "[1900]\ttraining's l1: 0.0982155\tvalid_1's l1: 0.378396\n",
      "[2000]\ttraining's l1: 0.0929509\tvalid_1's l1: 0.377744\n",
      "[2100]\ttraining's l1: 0.0885808\tvalid_1's l1: 0.377034\n",
      "[2200]\ttraining's l1: 0.0841893\tvalid_1's l1: 0.376165\n",
      "[2300]\ttraining's l1: 0.0802971\tvalid_1's l1: 0.375404\n",
      "[2400]\ttraining's l1: 0.0764841\tvalid_1's l1: 0.374551\n",
      "[2500]\ttraining's l1: 0.0732319\tvalid_1's l1: 0.373913\n",
      "[2600]\ttraining's l1: 0.069936\tvalid_1's l1: 0.373444\n",
      "[2700]\ttraining's l1: 0.0667648\tvalid_1's l1: 0.372922\n",
      "[2800]\ttraining's l1: 0.0638147\tvalid_1's l1: 0.372475\n",
      "[2900]\ttraining's l1: 0.0610694\tvalid_1's l1: 0.372091\n",
      "[3000]\ttraining's l1: 0.0585293\tvalid_1's l1: 0.371757\n",
      "[3100]\ttraining's l1: 0.0560629\tvalid_1's l1: 0.3714\n",
      "[3200]\ttraining's l1: 0.0536358\tvalid_1's l1: 0.370966\n",
      "[3300]\ttraining's l1: 0.0515147\tvalid_1's l1: 0.370666\n",
      "[3400]\ttraining's l1: 0.0494954\tvalid_1's l1: 0.370442\n",
      "[3500]\ttraining's l1: 0.0476341\tvalid_1's l1: 0.370235\n",
      "[3600]\ttraining's l1: 0.0458694\tvalid_1's l1: 0.369917\n",
      "[3700]\ttraining's l1: 0.0440437\tvalid_1's l1: 0.369634\n",
      "[3800]\ttraining's l1: 0.042434\tvalid_1's l1: 0.369429\n",
      "[3900]\ttraining's l1: 0.0408099\tvalid_1's l1: 0.369234\n",
      "[4000]\ttraining's l1: 0.0391541\tvalid_1's l1: 0.368992\n",
      "[4100]\ttraining's l1: 0.0377286\tvalid_1's l1: 0.368794\n",
      "[4200]\ttraining's l1: 0.0363797\tvalid_1's l1: 0.368597\n",
      "[4300]\ttraining's l1: 0.0351078\tvalid_1's l1: 0.368509\n",
      "[4400]\ttraining's l1: 0.0338996\tvalid_1's l1: 0.368423\n",
      "[4500]\ttraining's l1: 0.0327526\tvalid_1's l1: 0.368282\n",
      "[4600]\ttraining's l1: 0.0316462\tvalid_1's l1: 0.368172\n",
      "[4700]\ttraining's l1: 0.030565\tvalid_1's l1: 0.368054\n",
      "[4800]\ttraining's l1: 0.0295231\tvalid_1's l1: 0.367988\n",
      "[4900]\ttraining's l1: 0.0285187\tvalid_1's l1: 0.367955\n",
      "[5000]\ttraining's l1: 0.0275677\tvalid_1's l1: 0.367801\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0275677\tvalid_1's l1: 0.367801\n",
      "1JHN Fold 4, logMAE: -1.0002144455661905\n",
      "*** Training Model for 1JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.16565\tvalid_1's l1: 1.21709\n",
      "[200]\ttraining's l1: 0.992742\tvalid_1's l1: 1.07427\n",
      "[300]\ttraining's l1: 0.895246\tvalid_1's l1: 1.00077\n",
      "[400]\ttraining's l1: 0.82431\tvalid_1's l1: 0.952223\n",
      "[500]\ttraining's l1: 0.770229\tvalid_1's l1: 0.91723\n",
      "[600]\ttraining's l1: 0.727035\tvalid_1's l1: 0.890979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's l1: 0.690522\tvalid_1's l1: 0.870537\n",
      "[800]\ttraining's l1: 0.660323\tvalid_1's l1: 0.853856\n",
      "[900]\ttraining's l1: 0.632369\tvalid_1's l1: 0.839482\n",
      "[1000]\ttraining's l1: 0.607584\tvalid_1's l1: 0.82667\n",
      "[1100]\ttraining's l1: 0.584782\tvalid_1's l1: 0.815541\n",
      "[1200]\ttraining's l1: 0.564551\tvalid_1's l1: 0.805956\n",
      "[1300]\ttraining's l1: 0.545842\tvalid_1's l1: 0.797774\n",
      "[1400]\ttraining's l1: 0.528954\tvalid_1's l1: 0.790408\n",
      "[1500]\ttraining's l1: 0.512675\tvalid_1's l1: 0.783406\n",
      "[1600]\ttraining's l1: 0.497838\tvalid_1's l1: 0.777273\n",
      "[1700]\ttraining's l1: 0.483477\tvalid_1's l1: 0.771245\n",
      "[1800]\ttraining's l1: 0.470035\tvalid_1's l1: 0.766076\n",
      "[1900]\ttraining's l1: 0.457547\tvalid_1's l1: 0.761017\n",
      "[2000]\ttraining's l1: 0.445504\tvalid_1's l1: 0.756398\n",
      "[2100]\ttraining's l1: 0.434241\tvalid_1's l1: 0.75237\n",
      "[2200]\ttraining's l1: 0.423785\tvalid_1's l1: 0.748566\n",
      "[2300]\ttraining's l1: 0.413536\tvalid_1's l1: 0.745096\n",
      "[2400]\ttraining's l1: 0.404064\tvalid_1's l1: 0.741848\n",
      "[2500]\ttraining's l1: 0.394627\tvalid_1's l1: 0.738603\n",
      "[2600]\ttraining's l1: 0.385897\tvalid_1's l1: 0.735728\n",
      "[2700]\ttraining's l1: 0.377489\tvalid_1's l1: 0.732953\n",
      "[2800]\ttraining's l1: 0.369151\tvalid_1's l1: 0.730118\n",
      "[2900]\ttraining's l1: 0.361393\tvalid_1's l1: 0.727682\n",
      "[3000]\ttraining's l1: 0.353912\tvalid_1's l1: 0.725114\n",
      "[3100]\ttraining's l1: 0.346715\tvalid_1's l1: 0.722748\n",
      "[3200]\ttraining's l1: 0.339611\tvalid_1's l1: 0.720372\n",
      "[3300]\ttraining's l1: 0.332759\tvalid_1's l1: 0.718409\n",
      "[3400]\ttraining's l1: 0.326193\tvalid_1's l1: 0.716284\n",
      "[3500]\ttraining's l1: 0.319743\tvalid_1's l1: 0.714522\n",
      "[3600]\ttraining's l1: 0.313619\tvalid_1's l1: 0.712707\n",
      "[3700]\ttraining's l1: 0.307776\tvalid_1's l1: 0.710951\n",
      "[3800]\ttraining's l1: 0.302123\tvalid_1's l1: 0.709409\n",
      "[3900]\ttraining's l1: 0.296593\tvalid_1's l1: 0.707755\n",
      "[4000]\ttraining's l1: 0.291364\tvalid_1's l1: 0.706319\n",
      "[4100]\ttraining's l1: 0.286187\tvalid_1's l1: 0.704948\n",
      "[4200]\ttraining's l1: 0.281266\tvalid_1's l1: 0.703614\n",
      "[4300]\ttraining's l1: 0.276194\tvalid_1's l1: 0.702123\n",
      "[4400]\ttraining's l1: 0.271391\tvalid_1's l1: 0.700778\n",
      "[4500]\ttraining's l1: 0.266859\tvalid_1's l1: 0.699454\n",
      "[4600]\ttraining's l1: 0.262395\tvalid_1's l1: 0.698304\n",
      "[4700]\ttraining's l1: 0.258163\tvalid_1's l1: 0.69724\n",
      "[4800]\ttraining's l1: 0.253961\tvalid_1's l1: 0.696148\n",
      "[4900]\ttraining's l1: 0.249792\tvalid_1's l1: 0.695096\n",
      "[5000]\ttraining's l1: 0.245826\tvalid_1's l1: 0.694128\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.245826\tvalid_1's l1: 0.694128\n",
      "1JHC Fold 0, logMAE: -0.3650987895099526\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.16492\tvalid_1's l1: 1.21017\n",
      "[200]\ttraining's l1: 0.990756\tvalid_1's l1: 1.06675\n",
      "[300]\ttraining's l1: 0.89395\tvalid_1's l1: 0.994626\n",
      "[400]\ttraining's l1: 0.827085\tvalid_1's l1: 0.949104\n",
      "[500]\ttraining's l1: 0.774624\tvalid_1's l1: 0.916001\n",
      "[600]\ttraining's l1: 0.730614\tvalid_1's l1: 0.888632\n",
      "[700]\ttraining's l1: 0.692971\tvalid_1's l1: 0.866637\n",
      "[800]\ttraining's l1: 0.661577\tvalid_1's l1: 0.849251\n",
      "[900]\ttraining's l1: 0.633949\tvalid_1's l1: 0.83474\n",
      "[1000]\ttraining's l1: 0.609299\tvalid_1's l1: 0.822041\n",
      "[1100]\ttraining's l1: 0.587171\tvalid_1's l1: 0.811283\n",
      "[1200]\ttraining's l1: 0.566695\tvalid_1's l1: 0.801114\n",
      "[1300]\ttraining's l1: 0.548081\tvalid_1's l1: 0.792357\n",
      "[1400]\ttraining's l1: 0.530618\tvalid_1's l1: 0.784281\n",
      "[1500]\ttraining's l1: 0.514317\tvalid_1's l1: 0.77727\n",
      "[1600]\ttraining's l1: 0.499124\tvalid_1's l1: 0.771036\n",
      "[1700]\ttraining's l1: 0.485218\tvalid_1's l1: 0.765268\n",
      "[1800]\ttraining's l1: 0.472038\tvalid_1's l1: 0.760033\n",
      "[1900]\ttraining's l1: 0.459297\tvalid_1's l1: 0.755028\n",
      "[2000]\ttraining's l1: 0.447734\tvalid_1's l1: 0.750543\n",
      "[2100]\ttraining's l1: 0.436387\tvalid_1's l1: 0.746179\n",
      "[2200]\ttraining's l1: 0.426016\tvalid_1's l1: 0.742231\n",
      "[2300]\ttraining's l1: 0.415425\tvalid_1's l1: 0.738557\n",
      "[2400]\ttraining's l1: 0.405621\tvalid_1's l1: 0.735151\n",
      "[2500]\ttraining's l1: 0.396699\tvalid_1's l1: 0.732023\n",
      "[2600]\ttraining's l1: 0.387812\tvalid_1's l1: 0.728651\n",
      "[2700]\ttraining's l1: 0.378909\tvalid_1's l1: 0.725536\n",
      "[2800]\ttraining's l1: 0.370595\tvalid_1's l1: 0.722887\n",
      "[2900]\ttraining's l1: 0.362674\tvalid_1's l1: 0.720365\n",
      "[3000]\ttraining's l1: 0.354871\tvalid_1's l1: 0.717709\n",
      "[3100]\ttraining's l1: 0.34752\tvalid_1's l1: 0.715358\n",
      "[3200]\ttraining's l1: 0.340612\tvalid_1's l1: 0.713298\n",
      "[3300]\ttraining's l1: 0.333713\tvalid_1's l1: 0.711176\n",
      "[3400]\ttraining's l1: 0.327062\tvalid_1's l1: 0.709287\n",
      "[3500]\ttraining's l1: 0.320822\tvalid_1's l1: 0.707344\n",
      "[3600]\ttraining's l1: 0.314739\tvalid_1's l1: 0.705648\n",
      "[3700]\ttraining's l1: 0.308819\tvalid_1's l1: 0.704039\n",
      "[3800]\ttraining's l1: 0.302988\tvalid_1's l1: 0.702162\n",
      "[3900]\ttraining's l1: 0.297648\tvalid_1's l1: 0.700615\n",
      "[4000]\ttraining's l1: 0.292218\tvalid_1's l1: 0.699227\n",
      "[4100]\ttraining's l1: 0.287049\tvalid_1's l1: 0.697629\n",
      "[4200]\ttraining's l1: 0.282165\tvalid_1's l1: 0.696253\n",
      "[4300]\ttraining's l1: 0.277421\tvalid_1's l1: 0.694952\n",
      "[4400]\ttraining's l1: 0.272709\tvalid_1's l1: 0.693628\n",
      "[4500]\ttraining's l1: 0.268\tvalid_1's l1: 0.692334\n",
      "[4600]\ttraining's l1: 0.263618\tvalid_1's l1: 0.691113\n",
      "[4700]\ttraining's l1: 0.259102\tvalid_1's l1: 0.689965\n",
      "[4800]\ttraining's l1: 0.25489\tvalid_1's l1: 0.688866\n",
      "[4900]\ttraining's l1: 0.25084\tvalid_1's l1: 0.687959\n",
      "[5000]\ttraining's l1: 0.246767\tvalid_1's l1: 0.68682\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.246767\tvalid_1's l1: 0.68682\n",
      "1JHC Fold 1, logMAE: -0.3756837194847782\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.16692\tvalid_1's l1: 1.21717\n",
      "[200]\ttraining's l1: 0.991854\tvalid_1's l1: 1.07179\n",
      "[300]\ttraining's l1: 0.890951\tvalid_1's l1: 0.99472\n",
      "[400]\ttraining's l1: 0.822386\tvalid_1's l1: 0.947282\n",
      "[500]\ttraining's l1: 0.770279\tvalid_1's l1: 0.913328\n",
      "[600]\ttraining's l1: 0.726633\tvalid_1's l1: 0.886703\n",
      "[700]\ttraining's l1: 0.69038\tvalid_1's l1: 0.865904\n",
      "[800]\ttraining's l1: 0.659443\tvalid_1's l1: 0.849227\n",
      "[900]\ttraining's l1: 0.631573\tvalid_1's l1: 0.834458\n",
      "[1000]\ttraining's l1: 0.606905\tvalid_1's l1: 0.821524\n",
      "[1100]\ttraining's l1: 0.584822\tvalid_1's l1: 0.810707\n",
      "[1200]\ttraining's l1: 0.564322\tvalid_1's l1: 0.800604\n",
      "[1300]\ttraining's l1: 0.545233\tvalid_1's l1: 0.792081\n",
      "[1400]\ttraining's l1: 0.527813\tvalid_1's l1: 0.784346\n",
      "[1500]\ttraining's l1: 0.511726\tvalid_1's l1: 0.777412\n",
      "[1600]\ttraining's l1: 0.496741\tvalid_1's l1: 0.771392\n",
      "[1700]\ttraining's l1: 0.483134\tvalid_1's l1: 0.76572\n",
      "[1800]\ttraining's l1: 0.469939\tvalid_1's l1: 0.760609\n",
      "[1900]\ttraining's l1: 0.457897\tvalid_1's l1: 0.755943\n",
      "[2000]\ttraining's l1: 0.445785\tvalid_1's l1: 0.751184\n",
      "[2100]\ttraining's l1: 0.434604\tvalid_1's l1: 0.74705\n",
      "[2200]\ttraining's l1: 0.423799\tvalid_1's l1: 0.743357\n",
      "[2300]\ttraining's l1: 0.413857\tvalid_1's l1: 0.739777\n",
      "[2400]\ttraining's l1: 0.404133\tvalid_1's l1: 0.736351\n",
      "[2500]\ttraining's l1: 0.394974\tvalid_1's l1: 0.733058\n",
      "[2600]\ttraining's l1: 0.386135\tvalid_1's l1: 0.73008\n",
      "[2700]\ttraining's l1: 0.37756\tvalid_1's l1: 0.727282\n",
      "[2800]\ttraining's l1: 0.369411\tvalid_1's l1: 0.724717\n",
      "[2900]\ttraining's l1: 0.361282\tvalid_1's l1: 0.722278\n",
      "[3000]\ttraining's l1: 0.353557\tvalid_1's l1: 0.719859\n",
      "[3100]\ttraining's l1: 0.346293\tvalid_1's l1: 0.717298\n",
      "[3200]\ttraining's l1: 0.339391\tvalid_1's l1: 0.715064\n",
      "[3300]\ttraining's l1: 0.332408\tvalid_1's l1: 0.712898\n",
      "[3400]\ttraining's l1: 0.325897\tvalid_1's l1: 0.710828\n",
      "[3500]\ttraining's l1: 0.319625\tvalid_1's l1: 0.709005\n",
      "[3600]\ttraining's l1: 0.313535\tvalid_1's l1: 0.707275\n",
      "[3700]\ttraining's l1: 0.307661\tvalid_1's l1: 0.705524\n",
      "[3800]\ttraining's l1: 0.302095\tvalid_1's l1: 0.703921\n",
      "[3900]\ttraining's l1: 0.296557\tvalid_1's l1: 0.702356\n",
      "[4000]\ttraining's l1: 0.291296\tvalid_1's l1: 0.700881\n",
      "[4100]\ttraining's l1: 0.286025\tvalid_1's l1: 0.699345\n",
      "[4200]\ttraining's l1: 0.280974\tvalid_1's l1: 0.697932\n",
      "[4300]\ttraining's l1: 0.276128\tvalid_1's l1: 0.696668\n",
      "[4400]\ttraining's l1: 0.271473\tvalid_1's l1: 0.6954\n",
      "[4500]\ttraining's l1: 0.266942\tvalid_1's l1: 0.694225\n",
      "[4600]\ttraining's l1: 0.262504\tvalid_1's l1: 0.693126\n",
      "[4700]\ttraining's l1: 0.258133\tvalid_1's l1: 0.692042\n",
      "[4800]\ttraining's l1: 0.254049\tvalid_1's l1: 0.691147\n",
      "[4900]\ttraining's l1: 0.249981\tvalid_1's l1: 0.690185\n",
      "[5000]\ttraining's l1: 0.245898\tvalid_1's l1: 0.689136\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.245898\tvalid_1's l1: 0.689136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JHC Fold 2, logMAE: -0.3723167211137031\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.16226\tvalid_1's l1: 1.21588\n",
      "[200]\ttraining's l1: 0.986705\tvalid_1's l1: 1.06847\n",
      "[300]\ttraining's l1: 0.889198\tvalid_1's l1: 0.994239\n",
      "[400]\ttraining's l1: 0.819731\tvalid_1's l1: 0.944746\n",
      "[500]\ttraining's l1: 0.767442\tvalid_1's l1: 0.909807\n",
      "[600]\ttraining's l1: 0.724909\tvalid_1's l1: 0.883306\n",
      "[700]\ttraining's l1: 0.688822\tvalid_1's l1: 0.862378\n",
      "[800]\ttraining's l1: 0.65822\tvalid_1's l1: 0.845859\n",
      "[900]\ttraining's l1: 0.630896\tvalid_1's l1: 0.831494\n",
      "[1000]\ttraining's l1: 0.60608\tvalid_1's l1: 0.819381\n",
      "[1100]\ttraining's l1: 0.583188\tvalid_1's l1: 0.807271\n",
      "[1200]\ttraining's l1: 0.563212\tvalid_1's l1: 0.797898\n",
      "[1300]\ttraining's l1: 0.544408\tvalid_1's l1: 0.789176\n",
      "[1400]\ttraining's l1: 0.526866\tvalid_1's l1: 0.781146\n",
      "[1500]\ttraining's l1: 0.511231\tvalid_1's l1: 0.774655\n",
      "[1600]\ttraining's l1: 0.496281\tvalid_1's l1: 0.768115\n",
      "[1700]\ttraining's l1: 0.482257\tvalid_1's l1: 0.762335\n",
      "[1800]\ttraining's l1: 0.46904\tvalid_1's l1: 0.756975\n",
      "[1900]\ttraining's l1: 0.456203\tvalid_1's l1: 0.752049\n",
      "[2000]\ttraining's l1: 0.444179\tvalid_1's l1: 0.747103\n",
      "[2100]\ttraining's l1: 0.433197\tvalid_1's l1: 0.742934\n",
      "[2200]\ttraining's l1: 0.422695\tvalid_1's l1: 0.73914\n",
      "[2300]\ttraining's l1: 0.412433\tvalid_1's l1: 0.735518\n",
      "[2400]\ttraining's l1: 0.402534\tvalid_1's l1: 0.73206\n",
      "[2500]\ttraining's l1: 0.393243\tvalid_1's l1: 0.728828\n",
      "[2600]\ttraining's l1: 0.384542\tvalid_1's l1: 0.725889\n",
      "[2700]\ttraining's l1: 0.376169\tvalid_1's l1: 0.723102\n",
      "[2800]\ttraining's l1: 0.368141\tvalid_1's l1: 0.720475\n",
      "[2900]\ttraining's l1: 0.360277\tvalid_1's l1: 0.718008\n",
      "[3000]\ttraining's l1: 0.352676\tvalid_1's l1: 0.715651\n",
      "[3100]\ttraining's l1: 0.345401\tvalid_1's l1: 0.713343\n",
      "[3200]\ttraining's l1: 0.338324\tvalid_1's l1: 0.711048\n",
      "[3300]\ttraining's l1: 0.331477\tvalid_1's l1: 0.708844\n",
      "[3400]\ttraining's l1: 0.325103\tvalid_1's l1: 0.706989\n",
      "[3500]\ttraining's l1: 0.318939\tvalid_1's l1: 0.70513\n",
      "[3600]\ttraining's l1: 0.312963\tvalid_1's l1: 0.703531\n",
      "[3700]\ttraining's l1: 0.307118\tvalid_1's l1: 0.70196\n",
      "[3800]\ttraining's l1: 0.301406\tvalid_1's l1: 0.700264\n",
      "[3900]\ttraining's l1: 0.296069\tvalid_1's l1: 0.698581\n",
      "[4000]\ttraining's l1: 0.29072\tvalid_1's l1: 0.697183\n",
      "[4100]\ttraining's l1: 0.285611\tvalid_1's l1: 0.695748\n",
      "[4200]\ttraining's l1: 0.280642\tvalid_1's l1: 0.694446\n",
      "[4300]\ttraining's l1: 0.275876\tvalid_1's l1: 0.693165\n",
      "[4400]\ttraining's l1: 0.271192\tvalid_1's l1: 0.691913\n",
      "[4500]\ttraining's l1: 0.266548\tvalid_1's l1: 0.690663\n",
      "[4600]\ttraining's l1: 0.26212\tvalid_1's l1: 0.689531\n",
      "[4700]\ttraining's l1: 0.257849\tvalid_1's l1: 0.688357\n",
      "[4800]\ttraining's l1: 0.253734\tvalid_1's l1: 0.687299\n",
      "[4900]\ttraining's l1: 0.249736\tvalid_1's l1: 0.686276\n",
      "[5000]\ttraining's l1: 0.24578\tvalid_1's l1: 0.685212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.24578\tvalid_1's l1: 0.685212\n",
      "1JHC Fold 3, logMAE: -0.3780270141841415\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.15688\tvalid_1's l1: 1.20862\n",
      "[200]\ttraining's l1: 0.988091\tvalid_1's l1: 1.06729\n",
      "[300]\ttraining's l1: 0.89142\tvalid_1's l1: 0.994459\n",
      "[400]\ttraining's l1: 0.823271\tvalid_1's l1: 0.946845\n",
      "[500]\ttraining's l1: 0.770197\tvalid_1's l1: 0.912337\n",
      "[600]\ttraining's l1: 0.726388\tvalid_1's l1: 0.884562\n",
      "[700]\ttraining's l1: 0.689986\tvalid_1's l1: 0.863599\n",
      "[800]\ttraining's l1: 0.658465\tvalid_1's l1: 0.846135\n",
      "[900]\ttraining's l1: 0.631061\tvalid_1's l1: 0.831746\n",
      "[1000]\ttraining's l1: 0.606934\tvalid_1's l1: 0.819557\n",
      "[1100]\ttraining's l1: 0.58509\tvalid_1's l1: 0.808623\n",
      "[1200]\ttraining's l1: 0.564363\tvalid_1's l1: 0.798903\n",
      "[1300]\ttraining's l1: 0.545544\tvalid_1's l1: 0.789751\n",
      "[1400]\ttraining's l1: 0.528028\tvalid_1's l1: 0.781762\n",
      "[1500]\ttraining's l1: 0.511687\tvalid_1's l1: 0.774976\n",
      "[1600]\ttraining's l1: 0.496984\tvalid_1's l1: 0.768927\n",
      "[1700]\ttraining's l1: 0.482831\tvalid_1's l1: 0.762967\n",
      "[1800]\ttraining's l1: 0.469505\tvalid_1's l1: 0.757867\n",
      "[1900]\ttraining's l1: 0.457129\tvalid_1's l1: 0.752995\n",
      "[2000]\ttraining's l1: 0.445082\tvalid_1's l1: 0.748591\n",
      "[2100]\ttraining's l1: 0.43368\tvalid_1's l1: 0.744155\n",
      "[2200]\ttraining's l1: 0.423105\tvalid_1's l1: 0.740249\n",
      "[2300]\ttraining's l1: 0.413236\tvalid_1's l1: 0.736613\n",
      "[2400]\ttraining's l1: 0.403526\tvalid_1's l1: 0.73309\n",
      "[2500]\ttraining's l1: 0.394247\tvalid_1's l1: 0.72997\n",
      "[2600]\ttraining's l1: 0.385184\tvalid_1's l1: 0.727077\n",
      "[2700]\ttraining's l1: 0.376626\tvalid_1's l1: 0.724088\n",
      "[2800]\ttraining's l1: 0.368731\tvalid_1's l1: 0.721575\n",
      "[2900]\ttraining's l1: 0.360906\tvalid_1's l1: 0.718898\n",
      "[3000]\ttraining's l1: 0.353327\tvalid_1's l1: 0.716635\n",
      "[3100]\ttraining's l1: 0.346356\tvalid_1's l1: 0.714502\n",
      "[3200]\ttraining's l1: 0.33941\tvalid_1's l1: 0.712262\n",
      "[3300]\ttraining's l1: 0.332594\tvalid_1's l1: 0.710248\n",
      "[3400]\ttraining's l1: 0.32608\tvalid_1's l1: 0.708191\n",
      "[3500]\ttraining's l1: 0.319836\tvalid_1's l1: 0.706205\n",
      "[3600]\ttraining's l1: 0.313725\tvalid_1's l1: 0.704354\n",
      "[3700]\ttraining's l1: 0.30801\tvalid_1's l1: 0.702617\n",
      "[3800]\ttraining's l1: 0.302348\tvalid_1's l1: 0.70098\n",
      "[3900]\ttraining's l1: 0.296751\tvalid_1's l1: 0.699176\n",
      "[4000]\ttraining's l1: 0.291532\tvalid_1's l1: 0.697737\n",
      "[4100]\ttraining's l1: 0.286415\tvalid_1's l1: 0.696329\n",
      "[4200]\ttraining's l1: 0.281326\tvalid_1's l1: 0.694935\n",
      "[4300]\ttraining's l1: 0.276548\tvalid_1's l1: 0.693765\n",
      "[4400]\ttraining's l1: 0.271714\tvalid_1's l1: 0.692417\n",
      "[4500]\ttraining's l1: 0.267202\tvalid_1's l1: 0.691196\n",
      "[4600]\ttraining's l1: 0.262808\tvalid_1's l1: 0.690163\n",
      "[4700]\ttraining's l1: 0.258545\tvalid_1's l1: 0.689125\n",
      "[4800]\ttraining's l1: 0.254355\tvalid_1's l1: 0.688092\n",
      "[4900]\ttraining's l1: 0.250217\tvalid_1's l1: 0.686985\n",
      "[5000]\ttraining's l1: 0.246132\tvalid_1's l1: 0.68597\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.246132\tvalid_1's l1: 0.68597\n",
      "1JHC Fold 4, logMAE: -0.3769217203594143\n",
      "*** Training Model for 2JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.25494\tvalid_1's l1: 0.279367\n",
      "[200]\ttraining's l1: 0.209548\tvalid_1's l1: 0.244069\n",
      "[300]\ttraining's l1: 0.183189\tvalid_1's l1: 0.226056\n",
      "[400]\ttraining's l1: 0.166249\tvalid_1's l1: 0.21535\n",
      "[500]\ttraining's l1: 0.152867\tvalid_1's l1: 0.207719\n",
      "[600]\ttraining's l1: 0.142357\tvalid_1's l1: 0.202064\n",
      "[700]\ttraining's l1: 0.133523\tvalid_1's l1: 0.197544\n",
      "[800]\ttraining's l1: 0.126375\tvalid_1's l1: 0.194282\n",
      "[900]\ttraining's l1: 0.1198\tvalid_1's l1: 0.191245\n",
      "[1000]\ttraining's l1: 0.113901\tvalid_1's l1: 0.1887\n",
      "[1100]\ttraining's l1: 0.108427\tvalid_1's l1: 0.186405\n",
      "[1200]\ttraining's l1: 0.103679\tvalid_1's l1: 0.184459\n",
      "[1300]\ttraining's l1: 0.0992628\tvalid_1's l1: 0.182704\n",
      "[1400]\ttraining's l1: 0.0950614\tvalid_1's l1: 0.181015\n",
      "[1500]\ttraining's l1: 0.0912585\tvalid_1's l1: 0.179702\n",
      "[1600]\ttraining's l1: 0.0877527\tvalid_1's l1: 0.178501\n",
      "[1700]\ttraining's l1: 0.0844712\tvalid_1's l1: 0.17749\n",
      "[1800]\ttraining's l1: 0.0814524\tvalid_1's l1: 0.176516\n",
      "[1900]\ttraining's l1: 0.078602\tvalid_1's l1: 0.175585\n",
      "[2000]\ttraining's l1: 0.0758214\tvalid_1's l1: 0.174713\n",
      "[2100]\ttraining's l1: 0.07323\tvalid_1's l1: 0.17398\n",
      "[2200]\ttraining's l1: 0.0709004\tvalid_1's l1: 0.173273\n",
      "[2300]\ttraining's l1: 0.06866\tvalid_1's l1: 0.17261\n",
      "[2400]\ttraining's l1: 0.0666787\tvalid_1's l1: 0.172043\n",
      "[2500]\ttraining's l1: 0.0646381\tvalid_1's l1: 0.171486\n",
      "[2600]\ttraining's l1: 0.062673\tvalid_1's l1: 0.170945\n",
      "[2700]\ttraining's l1: 0.0608306\tvalid_1's l1: 0.170436\n",
      "[2800]\ttraining's l1: 0.0590777\tvalid_1's l1: 0.170045\n",
      "[2900]\ttraining's l1: 0.0573794\tvalid_1's l1: 0.169631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttraining's l1: 0.0557626\tvalid_1's l1: 0.169209\n",
      "[3100]\ttraining's l1: 0.0542167\tvalid_1's l1: 0.168819\n",
      "[3200]\ttraining's l1: 0.0527653\tvalid_1's l1: 0.168466\n",
      "[3300]\ttraining's l1: 0.0513104\tvalid_1's l1: 0.168096\n",
      "[3400]\ttraining's l1: 0.0499498\tvalid_1's l1: 0.167742\n",
      "[3500]\ttraining's l1: 0.0486077\tvalid_1's l1: 0.167416\n",
      "[3600]\ttraining's l1: 0.047389\tvalid_1's l1: 0.167148\n",
      "[3700]\ttraining's l1: 0.0462475\tvalid_1's l1: 0.166904\n",
      "[3800]\ttraining's l1: 0.0450676\tvalid_1's l1: 0.166627\n",
      "[3900]\ttraining's l1: 0.0439345\tvalid_1's l1: 0.166366\n",
      "[4000]\ttraining's l1: 0.0428825\tvalid_1's l1: 0.16617\n",
      "[4100]\ttraining's l1: 0.0418689\tvalid_1's l1: 0.165989\n",
      "[4200]\ttraining's l1: 0.0408746\tvalid_1's l1: 0.165793\n",
      "[4300]\ttraining's l1: 0.0399512\tvalid_1's l1: 0.165596\n",
      "[4400]\ttraining's l1: 0.0390402\tvalid_1's l1: 0.165415\n",
      "[4500]\ttraining's l1: 0.0381374\tvalid_1's l1: 0.165255\n",
      "[4600]\ttraining's l1: 0.0373097\tvalid_1's l1: 0.165095\n",
      "[4700]\ttraining's l1: 0.0364835\tvalid_1's l1: 0.164942\n",
      "[4800]\ttraining's l1: 0.0356945\tvalid_1's l1: 0.164782\n",
      "[4900]\ttraining's l1: 0.0349207\tvalid_1's l1: 0.164635\n",
      "[5000]\ttraining's l1: 0.0341545\tvalid_1's l1: 0.164473\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0341545\tvalid_1's l1: 0.164473\n",
      "2JHH Fold 0, logMAE: -1.805007326367302\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.255767\tvalid_1's l1: 0.277198\n",
      "[200]\ttraining's l1: 0.209576\tvalid_1's l1: 0.24182\n",
      "[300]\ttraining's l1: 0.185308\tvalid_1's l1: 0.22552\n",
      "[400]\ttraining's l1: 0.168402\tvalid_1's l1: 0.215451\n",
      "[500]\ttraining's l1: 0.154355\tvalid_1's l1: 0.207777\n",
      "[600]\ttraining's l1: 0.143458\tvalid_1's l1: 0.20217\n",
      "[700]\ttraining's l1: 0.134355\tvalid_1's l1: 0.197729\n",
      "[800]\ttraining's l1: 0.126654\tvalid_1's l1: 0.194046\n",
      "[900]\ttraining's l1: 0.119758\tvalid_1's l1: 0.190856\n",
      "[1000]\ttraining's l1: 0.11379\tvalid_1's l1: 0.188293\n",
      "[1100]\ttraining's l1: 0.108446\tvalid_1's l1: 0.18611\n",
      "[1200]\ttraining's l1: 0.103621\tvalid_1's l1: 0.184185\n",
      "[1300]\ttraining's l1: 0.0991141\tvalid_1's l1: 0.182527\n",
      "[1400]\ttraining's l1: 0.0951174\tvalid_1's l1: 0.181031\n",
      "[1500]\ttraining's l1: 0.0914736\tvalid_1's l1: 0.179842\n",
      "[1600]\ttraining's l1: 0.0879806\tvalid_1's l1: 0.178689\n",
      "[1700]\ttraining's l1: 0.0847145\tvalid_1's l1: 0.177594\n",
      "[1800]\ttraining's l1: 0.0816753\tvalid_1's l1: 0.176608\n",
      "[1900]\ttraining's l1: 0.0788423\tvalid_1's l1: 0.175669\n",
      "[2000]\ttraining's l1: 0.0760918\tvalid_1's l1: 0.174828\n",
      "[2100]\ttraining's l1: 0.0734995\tvalid_1's l1: 0.174053\n",
      "[2200]\ttraining's l1: 0.071046\tvalid_1's l1: 0.173317\n",
      "[2300]\ttraining's l1: 0.0687548\tvalid_1's l1: 0.172676\n",
      "[2400]\ttraining's l1: 0.0666117\tvalid_1's l1: 0.172101\n",
      "[2500]\ttraining's l1: 0.0646208\tvalid_1's l1: 0.171555\n",
      "[2600]\ttraining's l1: 0.0627268\tvalid_1's l1: 0.171022\n",
      "[2700]\ttraining's l1: 0.0608537\tvalid_1's l1: 0.170521\n",
      "[2800]\ttraining's l1: 0.0590602\tvalid_1's l1: 0.170032\n",
      "[2900]\ttraining's l1: 0.0573809\tvalid_1's l1: 0.169593\n",
      "[3000]\ttraining's l1: 0.0557519\tvalid_1's l1: 0.169172\n",
      "[3100]\ttraining's l1: 0.0542163\tvalid_1's l1: 0.168741\n",
      "[3200]\ttraining's l1: 0.0527638\tvalid_1's l1: 0.168377\n",
      "[3300]\ttraining's l1: 0.0513858\tvalid_1's l1: 0.168046\n",
      "[3400]\ttraining's l1: 0.0500893\tvalid_1's l1: 0.167685\n",
      "[3500]\ttraining's l1: 0.0487942\tvalid_1's l1: 0.167408\n",
      "[3600]\ttraining's l1: 0.0475377\tvalid_1's l1: 0.167114\n",
      "[3700]\ttraining's l1: 0.0463179\tvalid_1's l1: 0.166804\n",
      "[3800]\ttraining's l1: 0.0451996\tvalid_1's l1: 0.166586\n",
      "[3900]\ttraining's l1: 0.0441054\tvalid_1's l1: 0.166346\n",
      "[4000]\ttraining's l1: 0.0430423\tvalid_1's l1: 0.16609\n",
      "[4100]\ttraining's l1: 0.0419729\tvalid_1's l1: 0.165833\n",
      "[4200]\ttraining's l1: 0.0409916\tvalid_1's l1: 0.16566\n",
      "[4300]\ttraining's l1: 0.0400314\tvalid_1's l1: 0.165419\n",
      "[4400]\ttraining's l1: 0.0391154\tvalid_1's l1: 0.165237\n",
      "[4500]\ttraining's l1: 0.0382084\tvalid_1's l1: 0.165072\n",
      "[4600]\ttraining's l1: 0.0373448\tvalid_1's l1: 0.164894\n",
      "[4700]\ttraining's l1: 0.0364966\tvalid_1's l1: 0.164724\n",
      "[4800]\ttraining's l1: 0.0356677\tvalid_1's l1: 0.16457\n",
      "[4900]\ttraining's l1: 0.0348795\tvalid_1's l1: 0.164443\n",
      "[5000]\ttraining's l1: 0.0341384\tvalid_1's l1: 0.164295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0341384\tvalid_1's l1: 0.164295\n",
      "2JHH Fold 1, logMAE: -1.8060907231713323\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.256086\tvalid_1's l1: 0.278923\n",
      "[200]\ttraining's l1: 0.208649\tvalid_1's l1: 0.242533\n",
      "[300]\ttraining's l1: 0.183637\tvalid_1's l1: 0.226171\n",
      "[400]\ttraining's l1: 0.166602\tvalid_1's l1: 0.216192\n",
      "[500]\ttraining's l1: 0.153652\tvalid_1's l1: 0.208829\n",
      "[600]\ttraining's l1: 0.14354\tvalid_1's l1: 0.203292\n",
      "[700]\ttraining's l1: 0.134627\tvalid_1's l1: 0.19891\n",
      "[800]\ttraining's l1: 0.12707\tvalid_1's l1: 0.195414\n",
      "[900]\ttraining's l1: 0.120375\tvalid_1's l1: 0.192308\n",
      "[1000]\ttraining's l1: 0.114444\tvalid_1's l1: 0.189876\n",
      "[1100]\ttraining's l1: 0.109201\tvalid_1's l1: 0.187655\n",
      "[1200]\ttraining's l1: 0.104301\tvalid_1's l1: 0.185649\n",
      "[1300]\ttraining's l1: 0.0997418\tvalid_1's l1: 0.18393\n",
      "[1400]\ttraining's l1: 0.095707\tvalid_1's l1: 0.182387\n",
      "[1500]\ttraining's l1: 0.092028\tvalid_1's l1: 0.181103\n",
      "[1600]\ttraining's l1: 0.0885657\tvalid_1's l1: 0.179918\n",
      "[1700]\ttraining's l1: 0.0852667\tvalid_1's l1: 0.178813\n",
      "[1800]\ttraining's l1: 0.0820869\tvalid_1's l1: 0.177805\n",
      "[1900]\ttraining's l1: 0.0791898\tvalid_1's l1: 0.176899\n",
      "[2000]\ttraining's l1: 0.0764492\tvalid_1's l1: 0.176068\n",
      "[2100]\ttraining's l1: 0.073793\tvalid_1's l1: 0.175255\n",
      "[2200]\ttraining's l1: 0.0714261\tvalid_1's l1: 0.174563\n",
      "[2300]\ttraining's l1: 0.0691374\tvalid_1's l1: 0.173859\n",
      "[2400]\ttraining's l1: 0.0668235\tvalid_1's l1: 0.173143\n",
      "[2500]\ttraining's l1: 0.0647502\tvalid_1's l1: 0.172528\n",
      "[2600]\ttraining's l1: 0.062737\tvalid_1's l1: 0.171932\n",
      "[2700]\ttraining's l1: 0.0609504\tvalid_1's l1: 0.171437\n",
      "[2800]\ttraining's l1: 0.0591356\tvalid_1's l1: 0.170966\n",
      "[2900]\ttraining's l1: 0.0574332\tvalid_1's l1: 0.170539\n",
      "[3000]\ttraining's l1: 0.0558174\tvalid_1's l1: 0.170101\n",
      "[3100]\ttraining's l1: 0.0543051\tvalid_1's l1: 0.169648\n",
      "[3200]\ttraining's l1: 0.0528417\tvalid_1's l1: 0.169261\n",
      "[3300]\ttraining's l1: 0.0514544\tvalid_1's l1: 0.168925\n",
      "[3400]\ttraining's l1: 0.0500554\tvalid_1's l1: 0.168627\n",
      "[3500]\ttraining's l1: 0.0487682\tvalid_1's l1: 0.16833\n",
      "[3600]\ttraining's l1: 0.0475464\tvalid_1's l1: 0.16803\n",
      "[3700]\ttraining's l1: 0.0463973\tvalid_1's l1: 0.167763\n",
      "[3800]\ttraining's l1: 0.0452365\tvalid_1's l1: 0.167503\n",
      "[3900]\ttraining's l1: 0.0441139\tvalid_1's l1: 0.167241\n",
      "[4000]\ttraining's l1: 0.0430734\tvalid_1's l1: 0.167002\n",
      "[4100]\ttraining's l1: 0.0420706\tvalid_1's l1: 0.166793\n",
      "[4200]\ttraining's l1: 0.0410628\tvalid_1's l1: 0.166593\n",
      "[4300]\ttraining's l1: 0.0400787\tvalid_1's l1: 0.166371\n",
      "[4400]\ttraining's l1: 0.0391561\tvalid_1's l1: 0.166182\n",
      "[4500]\ttraining's l1: 0.038264\tvalid_1's l1: 0.16602\n",
      "[4600]\ttraining's l1: 0.0373963\tvalid_1's l1: 0.165849\n",
      "[4700]\ttraining's l1: 0.0365439\tvalid_1's l1: 0.165689\n",
      "[4800]\ttraining's l1: 0.0357436\tvalid_1's l1: 0.165526\n",
      "[4900]\ttraining's l1: 0.0349879\tvalid_1's l1: 0.165362\n",
      "[5000]\ttraining's l1: 0.0342436\tvalid_1's l1: 0.165225\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0342436\tvalid_1's l1: 0.165225\n",
      "2JHH Fold 2, logMAE: -1.8004489322650847\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.256164\tvalid_1's l1: 0.278781\n",
      "[200]\ttraining's l1: 0.210426\tvalid_1's l1: 0.243363\n",
      "[300]\ttraining's l1: 0.184515\tvalid_1's l1: 0.225811\n",
      "[400]\ttraining's l1: 0.167347\tvalid_1's l1: 0.215523\n",
      "[500]\ttraining's l1: 0.154247\tvalid_1's l1: 0.207939\n",
      "[600]\ttraining's l1: 0.14373\tvalid_1's l1: 0.202461\n",
      "[700]\ttraining's l1: 0.135181\tvalid_1's l1: 0.198275\n",
      "[800]\ttraining's l1: 0.127539\tvalid_1's l1: 0.194332\n",
      "[900]\ttraining's l1: 0.120495\tvalid_1's l1: 0.191063\n",
      "[1000]\ttraining's l1: 0.114492\tvalid_1's l1: 0.188584\n",
      "[1100]\ttraining's l1: 0.109298\tvalid_1's l1: 0.186435\n",
      "[1200]\ttraining's l1: 0.104685\tvalid_1's l1: 0.184668\n",
      "[1300]\ttraining's l1: 0.0999929\tvalid_1's l1: 0.182854\n",
      "[1400]\ttraining's l1: 0.0960697\tvalid_1's l1: 0.181378\n",
      "[1500]\ttraining's l1: 0.0922286\tvalid_1's l1: 0.180093\n",
      "[1600]\ttraining's l1: 0.0887545\tvalid_1's l1: 0.178857\n",
      "[1700]\ttraining's l1: 0.0853856\tvalid_1's l1: 0.177732\n",
      "[1800]\ttraining's l1: 0.0822697\tvalid_1's l1: 0.176675\n",
      "[1900]\ttraining's l1: 0.0794234\tvalid_1's l1: 0.175695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's l1: 0.076755\tvalid_1's l1: 0.174791\n",
      "[2100]\ttraining's l1: 0.0742586\tvalid_1's l1: 0.173994\n",
      "[2200]\ttraining's l1: 0.071765\tvalid_1's l1: 0.173293\n",
      "[2300]\ttraining's l1: 0.0696039\tvalid_1's l1: 0.1727\n",
      "[2400]\ttraining's l1: 0.0672701\tvalid_1's l1: 0.171974\n",
      "[2500]\ttraining's l1: 0.065189\tvalid_1's l1: 0.171335\n",
      "[2600]\ttraining's l1: 0.0631958\tvalid_1's l1: 0.170858\n",
      "[2700]\ttraining's l1: 0.0613191\tvalid_1's l1: 0.170342\n",
      "[2800]\ttraining's l1: 0.0595724\tvalid_1's l1: 0.169866\n",
      "[2900]\ttraining's l1: 0.0577665\tvalid_1's l1: 0.169395\n",
      "[3000]\ttraining's l1: 0.0562001\tvalid_1's l1: 0.169022\n",
      "[3100]\ttraining's l1: 0.0546483\tvalid_1's l1: 0.168624\n",
      "[3200]\ttraining's l1: 0.0531678\tvalid_1's l1: 0.168286\n",
      "[3300]\ttraining's l1: 0.0517576\tvalid_1's l1: 0.168018\n",
      "[3400]\ttraining's l1: 0.0503614\tvalid_1's l1: 0.167658\n",
      "[3500]\ttraining's l1: 0.0490393\tvalid_1's l1: 0.167353\n",
      "[3600]\ttraining's l1: 0.0477945\tvalid_1's l1: 0.167041\n",
      "[3700]\ttraining's l1: 0.0465998\tvalid_1's l1: 0.166754\n",
      "[3800]\ttraining's l1: 0.0454538\tvalid_1's l1: 0.166508\n",
      "[3900]\ttraining's l1: 0.0443338\tvalid_1's l1: 0.166273\n",
      "[4000]\ttraining's l1: 0.0432665\tvalid_1's l1: 0.16604\n",
      "[4100]\ttraining's l1: 0.042254\tvalid_1's l1: 0.165837\n",
      "[4200]\ttraining's l1: 0.0412509\tvalid_1's l1: 0.165674\n",
      "[4300]\ttraining's l1: 0.0403016\tvalid_1's l1: 0.16547\n",
      "[4400]\ttraining's l1: 0.0393766\tvalid_1's l1: 0.165294\n",
      "[4500]\ttraining's l1: 0.0384827\tvalid_1's l1: 0.165094\n",
      "[4600]\ttraining's l1: 0.0375965\tvalid_1's l1: 0.164902\n",
      "[4700]\ttraining's l1: 0.0367389\tvalid_1's l1: 0.164721\n",
      "[4800]\ttraining's l1: 0.0359236\tvalid_1's l1: 0.164561\n",
      "[4900]\ttraining's l1: 0.0351524\tvalid_1's l1: 0.164428\n",
      "[5000]\ttraining's l1: 0.0343852\tvalid_1's l1: 0.164253\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0343852\tvalid_1's l1: 0.164253\n",
      "2JHH Fold 3, logMAE: -1.806346385145969\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.255931\tvalid_1's l1: 0.277679\n",
      "[200]\ttraining's l1: 0.210031\tvalid_1's l1: 0.24206\n",
      "[300]\ttraining's l1: 0.184559\tvalid_1's l1: 0.224705\n",
      "[400]\ttraining's l1: 0.168038\tvalid_1's l1: 0.214584\n",
      "[500]\ttraining's l1: 0.154461\tvalid_1's l1: 0.206808\n",
      "[600]\ttraining's l1: 0.14343\tvalid_1's l1: 0.200913\n",
      "[700]\ttraining's l1: 0.134735\tvalid_1's l1: 0.196509\n",
      "[800]\ttraining's l1: 0.127146\tvalid_1's l1: 0.1929\n",
      "[900]\ttraining's l1: 0.120371\tvalid_1's l1: 0.189818\n",
      "[1000]\ttraining's l1: 0.114601\tvalid_1's l1: 0.187329\n",
      "[1100]\ttraining's l1: 0.109287\tvalid_1's l1: 0.185236\n",
      "[1200]\ttraining's l1: 0.104417\tvalid_1's l1: 0.18329\n",
      "[1300]\ttraining's l1: 0.0999036\tvalid_1's l1: 0.181704\n",
      "[1400]\ttraining's l1: 0.0957578\tvalid_1's l1: 0.180315\n",
      "[1500]\ttraining's l1: 0.0920284\tvalid_1's l1: 0.179037\n",
      "[1600]\ttraining's l1: 0.0885558\tvalid_1's l1: 0.177904\n",
      "[1700]\ttraining's l1: 0.0853591\tvalid_1's l1: 0.176844\n",
      "[1800]\ttraining's l1: 0.0822289\tvalid_1's l1: 0.175865\n",
      "[1900]\ttraining's l1: 0.0794001\tvalid_1's l1: 0.175003\n",
      "[2000]\ttraining's l1: 0.0767585\tvalid_1's l1: 0.174091\n",
      "[2100]\ttraining's l1: 0.0742129\tvalid_1's l1: 0.173311\n",
      "[2200]\ttraining's l1: 0.071819\tvalid_1's l1: 0.172547\n",
      "[2300]\ttraining's l1: 0.0695339\tvalid_1's l1: 0.171868\n",
      "[2400]\ttraining's l1: 0.0673082\tvalid_1's l1: 0.17124\n",
      "[2500]\ttraining's l1: 0.0651784\tvalid_1's l1: 0.170659\n",
      "[2600]\ttraining's l1: 0.0632136\tvalid_1's l1: 0.170115\n",
      "[2700]\ttraining's l1: 0.0613395\tvalid_1's l1: 0.169577\n",
      "[2800]\ttraining's l1: 0.0595752\tvalid_1's l1: 0.169151\n",
      "[2900]\ttraining's l1: 0.0578208\tvalid_1's l1: 0.168657\n",
      "[3000]\ttraining's l1: 0.0562092\tvalid_1's l1: 0.168238\n",
      "[3100]\ttraining's l1: 0.0547031\tvalid_1's l1: 0.167837\n",
      "[3200]\ttraining's l1: 0.053268\tvalid_1's l1: 0.167478\n",
      "[3300]\ttraining's l1: 0.0518215\tvalid_1's l1: 0.167116\n",
      "[3400]\ttraining's l1: 0.0504435\tvalid_1's l1: 0.16682\n",
      "[3500]\ttraining's l1: 0.0491788\tvalid_1's l1: 0.166527\n",
      "[3600]\ttraining's l1: 0.0479653\tvalid_1's l1: 0.166264\n",
      "[3700]\ttraining's l1: 0.0467646\tvalid_1's l1: 0.165978\n",
      "[3800]\ttraining's l1: 0.0455724\tvalid_1's l1: 0.165711\n",
      "[3900]\ttraining's l1: 0.0443679\tvalid_1's l1: 0.165417\n",
      "[4000]\ttraining's l1: 0.043314\tvalid_1's l1: 0.165186\n",
      "[4100]\ttraining's l1: 0.0422912\tvalid_1's l1: 0.164969\n",
      "[4200]\ttraining's l1: 0.0412925\tvalid_1's l1: 0.164745\n",
      "[4300]\ttraining's l1: 0.0403479\tvalid_1's l1: 0.164548\n",
      "[4400]\ttraining's l1: 0.0393995\tvalid_1's l1: 0.164345\n",
      "[4500]\ttraining's l1: 0.0385295\tvalid_1's l1: 0.164151\n",
      "[4600]\ttraining's l1: 0.0376474\tvalid_1's l1: 0.163976\n",
      "[4700]\ttraining's l1: 0.0368105\tvalid_1's l1: 0.16381\n",
      "[4800]\ttraining's l1: 0.0360422\tvalid_1's l1: 0.163661\n",
      "[4900]\ttraining's l1: 0.0352309\tvalid_1's l1: 0.163491\n",
      "[5000]\ttraining's l1: 0.0344927\tvalid_1's l1: 0.163343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0344927\tvalid_1's l1: 0.163343\n",
      "2JHH Fold 4, logMAE: -1.8119030367548765\n",
      "*** Training Model for 2JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.185945\tvalid_1's l1: 0.217823\n",
      "[200]\ttraining's l1: 0.14873\tvalid_1's l1: 0.191951\n",
      "[300]\ttraining's l1: 0.12926\tvalid_1's l1: 0.179907\n",
      "[400]\ttraining's l1: 0.11487\tvalid_1's l1: 0.171771\n",
      "[500]\ttraining's l1: 0.103931\tvalid_1's l1: 0.166101\n",
      "[600]\ttraining's l1: 0.0948925\tvalid_1's l1: 0.161725\n",
      "[700]\ttraining's l1: 0.0874624\tvalid_1's l1: 0.158514\n",
      "[800]\ttraining's l1: 0.0814073\tvalid_1's l1: 0.155709\n",
      "[900]\ttraining's l1: 0.0758884\tvalid_1's l1: 0.153502\n",
      "[1000]\ttraining's l1: 0.0710597\tvalid_1's l1: 0.151585\n",
      "[1100]\ttraining's l1: 0.0668196\tvalid_1's l1: 0.149985\n",
      "[1200]\ttraining's l1: 0.0629126\tvalid_1's l1: 0.148662\n",
      "[1300]\ttraining's l1: 0.0594142\tvalid_1's l1: 0.147528\n",
      "[1400]\ttraining's l1: 0.0562821\tvalid_1's l1: 0.146408\n",
      "[1500]\ttraining's l1: 0.0532474\tvalid_1's l1: 0.145337\n",
      "[1600]\ttraining's l1: 0.0505963\tvalid_1's l1: 0.144539\n",
      "[1700]\ttraining's l1: 0.0480628\tvalid_1's l1: 0.143778\n",
      "[1800]\ttraining's l1: 0.0457027\tvalid_1's l1: 0.143117\n",
      "[1900]\ttraining's l1: 0.0435774\tvalid_1's l1: 0.142556\n",
      "[2000]\ttraining's l1: 0.0415525\tvalid_1's l1: 0.142084\n",
      "[2100]\ttraining's l1: 0.0398092\tvalid_1's l1: 0.141599\n",
      "[2200]\ttraining's l1: 0.0380246\tvalid_1's l1: 0.141107\n",
      "[2300]\ttraining's l1: 0.0363713\tvalid_1's l1: 0.140719\n",
      "[2400]\ttraining's l1: 0.0348359\tvalid_1's l1: 0.140351\n",
      "[2500]\ttraining's l1: 0.0333363\tvalid_1's l1: 0.139885\n",
      "[2600]\ttraining's l1: 0.0319846\tvalid_1's l1: 0.139537\n",
      "[2700]\ttraining's l1: 0.0307171\tvalid_1's l1: 0.139301\n",
      "[2800]\ttraining's l1: 0.0295494\tvalid_1's l1: 0.13903\n",
      "[2900]\ttraining's l1: 0.0284082\tvalid_1's l1: 0.1388\n",
      "[3000]\ttraining's l1: 0.0273176\tvalid_1's l1: 0.13859\n",
      "[3100]\ttraining's l1: 0.0263286\tvalid_1's l1: 0.138372\n",
      "[3200]\ttraining's l1: 0.0253487\tvalid_1's l1: 0.138144\n",
      "[3300]\ttraining's l1: 0.0244187\tvalid_1's l1: 0.137915\n",
      "[3400]\ttraining's l1: 0.0235715\tvalid_1's l1: 0.137773\n",
      "[3500]\ttraining's l1: 0.0227592\tvalid_1's l1: 0.137624\n",
      "[3600]\ttraining's l1: 0.0219792\tvalid_1's l1: 0.13742\n",
      "[3700]\ttraining's l1: 0.0212539\tvalid_1's l1: 0.137274\n",
      "[3800]\ttraining's l1: 0.0205421\tvalid_1's l1: 0.137135\n",
      "[3900]\ttraining's l1: 0.019882\tvalid_1's l1: 0.136997\n",
      "[4000]\ttraining's l1: 0.019246\tvalid_1's l1: 0.136876\n",
      "[4100]\ttraining's l1: 0.0186438\tvalid_1's l1: 0.136758\n",
      "[4200]\ttraining's l1: 0.0180655\tvalid_1's l1: 0.136671\n",
      "[4300]\ttraining's l1: 0.0175139\tvalid_1's l1: 0.136598\n",
      "[4400]\ttraining's l1: 0.0169946\tvalid_1's l1: 0.136483\n",
      "[4500]\ttraining's l1: 0.0164979\tvalid_1's l1: 0.13641\n",
      "[4600]\ttraining's l1: 0.0160164\tvalid_1's l1: 0.136353\n",
      "[4700]\ttraining's l1: 0.0155569\tvalid_1's l1: 0.136249\n",
      "[4800]\ttraining's l1: 0.0151221\tvalid_1's l1: 0.136169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4900]\ttraining's l1: 0.0147121\tvalid_1's l1: 0.136084\n",
      "[5000]\ttraining's l1: 0.0143241\tvalid_1's l1: 0.136031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0143241\tvalid_1's l1: 0.136031\n",
      "2JHN Fold 0, logMAE: -1.9948713361554775\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.186716\tvalid_1's l1: 0.217876\n",
      "[200]\ttraining's l1: 0.148258\tvalid_1's l1: 0.191736\n",
      "[300]\ttraining's l1: 0.129454\tvalid_1's l1: 0.179715\n",
      "[400]\ttraining's l1: 0.115217\tvalid_1's l1: 0.171346\n",
      "[500]\ttraining's l1: 0.103975\tvalid_1's l1: 0.165695\n",
      "[600]\ttraining's l1: 0.0954156\tvalid_1's l1: 0.161839\n",
      "[700]\ttraining's l1: 0.0880363\tvalid_1's l1: 0.158628\n",
      "[800]\ttraining's l1: 0.0816495\tvalid_1's l1: 0.156021\n",
      "[900]\ttraining's l1: 0.0764297\tvalid_1's l1: 0.153958\n",
      "[1000]\ttraining's l1: 0.0716494\tvalid_1's l1: 0.152142\n",
      "[1100]\ttraining's l1: 0.0673582\tvalid_1's l1: 0.15068\n",
      "[1200]\ttraining's l1: 0.0636636\tvalid_1's l1: 0.149373\n",
      "[1300]\ttraining's l1: 0.0601437\tvalid_1's l1: 0.148281\n",
      "[1400]\ttraining's l1: 0.0568648\tvalid_1's l1: 0.147175\n",
      "[1500]\ttraining's l1: 0.0538947\tvalid_1's l1: 0.146214\n",
      "[1600]\ttraining's l1: 0.0512662\tvalid_1's l1: 0.145344\n",
      "[1700]\ttraining's l1: 0.0486443\tvalid_1's l1: 0.144567\n",
      "[1800]\ttraining's l1: 0.0463785\tvalid_1's l1: 0.143968\n",
      "[1900]\ttraining's l1: 0.0441336\tvalid_1's l1: 0.143311\n",
      "[2000]\ttraining's l1: 0.0422437\tvalid_1's l1: 0.14278\n",
      "[2100]\ttraining's l1: 0.0403988\tvalid_1's l1: 0.142236\n",
      "[2200]\ttraining's l1: 0.0386007\tvalid_1's l1: 0.141756\n",
      "[2300]\ttraining's l1: 0.0369304\tvalid_1's l1: 0.141395\n",
      "[2400]\ttraining's l1: 0.0354557\tvalid_1's l1: 0.140979\n",
      "[2500]\ttraining's l1: 0.0339575\tvalid_1's l1: 0.140649\n",
      "[2600]\ttraining's l1: 0.032543\tvalid_1's l1: 0.140314\n",
      "[2700]\ttraining's l1: 0.0312903\tvalid_1's l1: 0.140006\n",
      "[2800]\ttraining's l1: 0.0300458\tvalid_1's l1: 0.139721\n",
      "[2900]\ttraining's l1: 0.0288895\tvalid_1's l1: 0.139406\n",
      "[3000]\ttraining's l1: 0.0277751\tvalid_1's l1: 0.139171\n",
      "[3100]\ttraining's l1: 0.0267711\tvalid_1's l1: 0.138982\n",
      "[3200]\ttraining's l1: 0.0257724\tvalid_1's l1: 0.138777\n",
      "[3300]\ttraining's l1: 0.0248525\tvalid_1's l1: 0.13859\n",
      "[3400]\ttraining's l1: 0.0239717\tvalid_1's l1: 0.138388\n",
      "[3500]\ttraining's l1: 0.0231789\tvalid_1's l1: 0.138209\n",
      "[3600]\ttraining's l1: 0.0223662\tvalid_1's l1: 0.138039\n",
      "[3700]\ttraining's l1: 0.0215999\tvalid_1's l1: 0.137854\n",
      "[3800]\ttraining's l1: 0.0208871\tvalid_1's l1: 0.137722\n",
      "[3900]\ttraining's l1: 0.0202109\tvalid_1's l1: 0.137585\n",
      "[4000]\ttraining's l1: 0.0195761\tvalid_1's l1: 0.137457\n",
      "[4100]\ttraining's l1: 0.0189708\tvalid_1's l1: 0.137329\n",
      "[4200]\ttraining's l1: 0.0183773\tvalid_1's l1: 0.137186\n",
      "[4300]\ttraining's l1: 0.017835\tvalid_1's l1: 0.137083\n",
      "[4400]\ttraining's l1: 0.0173071\tvalid_1's l1: 0.136996\n",
      "[4500]\ttraining's l1: 0.0167887\tvalid_1's l1: 0.136906\n",
      "[4600]\ttraining's l1: 0.0163147\tvalid_1's l1: 0.13682\n",
      "[4700]\ttraining's l1: 0.0158565\tvalid_1's l1: 0.136745\n",
      "[4800]\ttraining's l1: 0.0154108\tvalid_1's l1: 0.136656\n",
      "[4900]\ttraining's l1: 0.0149965\tvalid_1's l1: 0.136591\n",
      "[5000]\ttraining's l1: 0.0146019\tvalid_1's l1: 0.136539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0146019\tvalid_1's l1: 0.136539\n",
      "2JHN Fold 1, logMAE: -1.991146295275967\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.188806\tvalid_1's l1: 0.216624\n",
      "[200]\ttraining's l1: 0.149825\tvalid_1's l1: 0.189542\n",
      "[300]\ttraining's l1: 0.130646\tvalid_1's l1: 0.178246\n",
      "[400]\ttraining's l1: 0.115976\tvalid_1's l1: 0.170455\n",
      "[500]\ttraining's l1: 0.10455\tvalid_1's l1: 0.165017\n",
      "[600]\ttraining's l1: 0.0958625\tvalid_1's l1: 0.160885\n",
      "[700]\ttraining's l1: 0.0886286\tvalid_1's l1: 0.157754\n",
      "[800]\ttraining's l1: 0.0822234\tvalid_1's l1: 0.155121\n",
      "[900]\ttraining's l1: 0.0769993\tvalid_1's l1: 0.152978\n",
      "[1000]\ttraining's l1: 0.0716744\tvalid_1's l1: 0.150934\n",
      "[1100]\ttraining's l1: 0.0671776\tvalid_1's l1: 0.149369\n",
      "[1200]\ttraining's l1: 0.0634262\tvalid_1's l1: 0.148115\n",
      "[1300]\ttraining's l1: 0.0596146\tvalid_1's l1: 0.146951\n",
      "[1400]\ttraining's l1: 0.0564069\tvalid_1's l1: 0.14599\n",
      "[1500]\ttraining's l1: 0.053475\tvalid_1's l1: 0.145083\n",
      "[1600]\ttraining's l1: 0.0507754\tvalid_1's l1: 0.144294\n",
      "[1700]\ttraining's l1: 0.0483458\tvalid_1's l1: 0.143549\n",
      "[1800]\ttraining's l1: 0.0460412\tvalid_1's l1: 0.142922\n",
      "[1900]\ttraining's l1: 0.0440042\tvalid_1's l1: 0.142386\n",
      "[2000]\ttraining's l1: 0.0419799\tvalid_1's l1: 0.141839\n",
      "[2100]\ttraining's l1: 0.0400746\tvalid_1's l1: 0.14127\n",
      "[2200]\ttraining's l1: 0.0383289\tvalid_1's l1: 0.140831\n",
      "[2300]\ttraining's l1: 0.0366458\tvalid_1's l1: 0.140354\n",
      "[2400]\ttraining's l1: 0.0351282\tvalid_1's l1: 0.14001\n",
      "[2500]\ttraining's l1: 0.0337174\tvalid_1's l1: 0.139653\n",
      "[2600]\ttraining's l1: 0.0323787\tvalid_1's l1: 0.139331\n",
      "[2700]\ttraining's l1: 0.0310654\tvalid_1's l1: 0.139077\n",
      "[2800]\ttraining's l1: 0.0298436\tvalid_1's l1: 0.138846\n",
      "[2900]\ttraining's l1: 0.0287132\tvalid_1's l1: 0.13859\n",
      "[3000]\ttraining's l1: 0.0276038\tvalid_1's l1: 0.13834\n",
      "[3100]\ttraining's l1: 0.0265798\tvalid_1's l1: 0.13817\n",
      "[3200]\ttraining's l1: 0.0256037\tvalid_1's l1: 0.137968\n",
      "[3300]\ttraining's l1: 0.024669\tvalid_1's l1: 0.137773\n",
      "[3400]\ttraining's l1: 0.0237925\tvalid_1's l1: 0.137614\n",
      "[3500]\ttraining's l1: 0.022966\tvalid_1's l1: 0.137447\n",
      "[3600]\ttraining's l1: 0.0221675\tvalid_1's l1: 0.137303\n",
      "[3700]\ttraining's l1: 0.0214161\tvalid_1's l1: 0.137141\n",
      "[3800]\ttraining's l1: 0.020714\tvalid_1's l1: 0.137027\n",
      "[3900]\ttraining's l1: 0.0200475\tvalid_1's l1: 0.136885\n",
      "[4000]\ttraining's l1: 0.0194174\tvalid_1's l1: 0.136749\n",
      "[4100]\ttraining's l1: 0.0188238\tvalid_1's l1: 0.136645\n",
      "[4200]\ttraining's l1: 0.018234\tvalid_1's l1: 0.136548\n",
      "[4300]\ttraining's l1: 0.0176848\tvalid_1's l1: 0.136456\n",
      "[4400]\ttraining's l1: 0.0171535\tvalid_1's l1: 0.136324\n",
      "[4500]\ttraining's l1: 0.0166745\tvalid_1's l1: 0.136234\n",
      "[4600]\ttraining's l1: 0.0161906\tvalid_1's l1: 0.136164\n",
      "[4700]\ttraining's l1: 0.0157336\tvalid_1's l1: 0.136085\n",
      "[4800]\ttraining's l1: 0.0152958\tvalid_1's l1: 0.136004\n",
      "[4900]\ttraining's l1: 0.014886\tvalid_1's l1: 0.135926\n",
      "[5000]\ttraining's l1: 0.0144804\tvalid_1's l1: 0.135833\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0144804\tvalid_1's l1: 0.135833\n",
      "2JHN Fold 2, logMAE: -1.996327307372275\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.184809\tvalid_1's l1: 0.214581\n",
      "[200]\ttraining's l1: 0.149383\tvalid_1's l1: 0.189161\n",
      "[300]\ttraining's l1: 0.127138\tvalid_1's l1: 0.174817\n",
      "[400]\ttraining's l1: 0.113056\tvalid_1's l1: 0.166784\n",
      "[500]\ttraining's l1: 0.102718\tvalid_1's l1: 0.161656\n",
      "[600]\ttraining's l1: 0.0941372\tvalid_1's l1: 0.157396\n",
      "[700]\ttraining's l1: 0.0872604\tvalid_1's l1: 0.154165\n",
      "[800]\ttraining's l1: 0.0808566\tvalid_1's l1: 0.151463\n",
      "[900]\ttraining's l1: 0.0753589\tvalid_1's l1: 0.149354\n",
      "[1000]\ttraining's l1: 0.0706507\tvalid_1's l1: 0.147561\n",
      "[1100]\ttraining's l1: 0.0663062\tvalid_1's l1: 0.146006\n",
      "[1200]\ttraining's l1: 0.0622475\tvalid_1's l1: 0.144603\n",
      "[1300]\ttraining's l1: 0.0588218\tvalid_1's l1: 0.143499\n",
      "[1400]\ttraining's l1: 0.055612\tvalid_1's l1: 0.142483\n",
      "[1500]\ttraining's l1: 0.0526733\tvalid_1's l1: 0.141554\n",
      "[1600]\ttraining's l1: 0.0499838\tvalid_1's l1: 0.140602\n",
      "[1700]\ttraining's l1: 0.0475004\tvalid_1's l1: 0.139825\n",
      "[1800]\ttraining's l1: 0.0452516\tvalid_1's l1: 0.139228\n",
      "[1900]\ttraining's l1: 0.0432033\tvalid_1's l1: 0.138659\n",
      "[2000]\ttraining's l1: 0.0412743\tvalid_1's l1: 0.138213\n",
      "[2100]\ttraining's l1: 0.0394172\tvalid_1's l1: 0.137754\n",
      "[2200]\ttraining's l1: 0.0378388\tvalid_1's l1: 0.137369\n",
      "[2300]\ttraining's l1: 0.0362473\tvalid_1's l1: 0.136967\n",
      "[2400]\ttraining's l1: 0.0347299\tvalid_1's l1: 0.136582\n",
      "[2500]\ttraining's l1: 0.0332951\tvalid_1's l1: 0.136289\n",
      "[2600]\ttraining's l1: 0.0319944\tvalid_1's l1: 0.135981\n",
      "[2700]\ttraining's l1: 0.0307385\tvalid_1's l1: 0.135692\n",
      "[2800]\ttraining's l1: 0.0295483\tvalid_1's l1: 0.135419\n",
      "[2900]\ttraining's l1: 0.0284642\tvalid_1's l1: 0.13513\n",
      "[3000]\ttraining's l1: 0.0273859\tvalid_1's l1: 0.134892\n",
      "[3100]\ttraining's l1: 0.0263863\tvalid_1's l1: 0.134655\n",
      "[3200]\ttraining's l1: 0.0254175\tvalid_1's l1: 0.134453\n",
      "[3300]\ttraining's l1: 0.0245126\tvalid_1's l1: 0.134251\n",
      "[3400]\ttraining's l1: 0.0236732\tvalid_1's l1: 0.134078\n",
      "[3500]\ttraining's l1: 0.0228411\tvalid_1's l1: 0.133916\n",
      "[3600]\ttraining's l1: 0.022071\tvalid_1's l1: 0.133757\n",
      "[3700]\ttraining's l1: 0.0213169\tvalid_1's l1: 0.133624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3800]\ttraining's l1: 0.0206016\tvalid_1's l1: 0.133504\n",
      "[3900]\ttraining's l1: 0.0199282\tvalid_1's l1: 0.133364\n",
      "[4000]\ttraining's l1: 0.0193016\tvalid_1's l1: 0.133263\n",
      "[4100]\ttraining's l1: 0.01871\tvalid_1's l1: 0.133139\n",
      "[4200]\ttraining's l1: 0.0181352\tvalid_1's l1: 0.133026\n",
      "[4300]\ttraining's l1: 0.0175781\tvalid_1's l1: 0.132919\n",
      "[4400]\ttraining's l1: 0.0170585\tvalid_1's l1: 0.132826\n",
      "[4500]\ttraining's l1: 0.0165641\tvalid_1's l1: 0.132751\n",
      "[4600]\ttraining's l1: 0.0160881\tvalid_1's l1: 0.132659\n",
      "[4700]\ttraining's l1: 0.0156412\tvalid_1's l1: 0.132586\n",
      "[4800]\ttraining's l1: 0.0152074\tvalid_1's l1: 0.132501\n",
      "[4900]\ttraining's l1: 0.0147776\tvalid_1's l1: 0.132427\n",
      "[5000]\ttraining's l1: 0.0143843\tvalid_1's l1: 0.132366\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0143843\tvalid_1's l1: 0.132366\n",
      "2JHN Fold 3, logMAE: -2.0221873761656917\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.186339\tvalid_1's l1: 0.217049\n",
      "[200]\ttraining's l1: 0.151057\tvalid_1's l1: 0.19229\n",
      "[300]\ttraining's l1: 0.13069\tvalid_1's l1: 0.179511\n",
      "[400]\ttraining's l1: 0.116593\tvalid_1's l1: 0.171754\n",
      "[500]\ttraining's l1: 0.105883\tvalid_1's l1: 0.166392\n",
      "[600]\ttraining's l1: 0.0969995\tvalid_1's l1: 0.161968\n",
      "[700]\ttraining's l1: 0.0896269\tvalid_1's l1: 0.158709\n",
      "[800]\ttraining's l1: 0.0833422\tvalid_1's l1: 0.15606\n",
      "[900]\ttraining's l1: 0.0778411\tvalid_1's l1: 0.153957\n",
      "[1000]\ttraining's l1: 0.0729452\tvalid_1's l1: 0.15205\n",
      "[1100]\ttraining's l1: 0.0687393\tvalid_1's l1: 0.150511\n",
      "[1200]\ttraining's l1: 0.0647595\tvalid_1's l1: 0.149115\n",
      "[1300]\ttraining's l1: 0.0609401\tvalid_1's l1: 0.147829\n",
      "[1400]\ttraining's l1: 0.0573553\tvalid_1's l1: 0.146698\n",
      "[1500]\ttraining's l1: 0.0542761\tvalid_1's l1: 0.145564\n",
      "[1600]\ttraining's l1: 0.0516435\tvalid_1's l1: 0.144766\n",
      "[1700]\ttraining's l1: 0.0490051\tvalid_1's l1: 0.143987\n",
      "[1800]\ttraining's l1: 0.046687\tvalid_1's l1: 0.143308\n",
      "[1900]\ttraining's l1: 0.0444911\tvalid_1's l1: 0.14269\n",
      "[2000]\ttraining's l1: 0.0424865\tvalid_1's l1: 0.142156\n",
      "[2100]\ttraining's l1: 0.0405036\tvalid_1's l1: 0.141619\n",
      "[2200]\ttraining's l1: 0.0387302\tvalid_1's l1: 0.141089\n",
      "[2300]\ttraining's l1: 0.0370724\tvalid_1's l1: 0.140647\n",
      "[2400]\ttraining's l1: 0.0354906\tvalid_1's l1: 0.140235\n",
      "[2500]\ttraining's l1: 0.0340383\tvalid_1's l1: 0.139871\n",
      "[2600]\ttraining's l1: 0.0326492\tvalid_1's l1: 0.13954\n",
      "[2700]\ttraining's l1: 0.0313674\tvalid_1's l1: 0.139228\n",
      "[2800]\ttraining's l1: 0.0301192\tvalid_1's l1: 0.138988\n",
      "[2900]\ttraining's l1: 0.0289589\tvalid_1's l1: 0.138742\n",
      "[3000]\ttraining's l1: 0.0278438\tvalid_1's l1: 0.138492\n",
      "[3100]\ttraining's l1: 0.0268235\tvalid_1's l1: 0.138236\n",
      "[3200]\ttraining's l1: 0.0258478\tvalid_1's l1: 0.138018\n",
      "[3300]\ttraining's l1: 0.0248687\tvalid_1's l1: 0.137871\n",
      "[3400]\ttraining's l1: 0.0239953\tvalid_1's l1: 0.137716\n",
      "[3500]\ttraining's l1: 0.0231792\tvalid_1's l1: 0.137535\n",
      "[3600]\ttraining's l1: 0.0224056\tvalid_1's l1: 0.137404\n",
      "[3700]\ttraining's l1: 0.0216745\tvalid_1's l1: 0.13726\n",
      "[3800]\ttraining's l1: 0.0209371\tvalid_1's l1: 0.137109\n",
      "[3900]\ttraining's l1: 0.0202535\tvalid_1's l1: 0.136982\n",
      "[4000]\ttraining's l1: 0.0195973\tvalid_1's l1: 0.136846\n",
      "[4100]\ttraining's l1: 0.018971\tvalid_1's l1: 0.136722\n",
      "[4200]\ttraining's l1: 0.0183701\tvalid_1's l1: 0.136624\n",
      "[4300]\ttraining's l1: 0.0178089\tvalid_1's l1: 0.136513\n",
      "[4400]\ttraining's l1: 0.0172707\tvalid_1's l1: 0.136433\n",
      "[4500]\ttraining's l1: 0.0167731\tvalid_1's l1: 0.136339\n",
      "[4600]\ttraining's l1: 0.0162927\tvalid_1's l1: 0.136265\n",
      "[4700]\ttraining's l1: 0.0158415\tvalid_1's l1: 0.136167\n",
      "[4800]\ttraining's l1: 0.0153917\tvalid_1's l1: 0.136097\n",
      "[4900]\ttraining's l1: 0.0149691\tvalid_1's l1: 0.136042\n",
      "[5000]\ttraining's l1: 0.0145663\tvalid_1's l1: 0.135963\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0145663\tvalid_1's l1: 0.135963\n",
      "2JHN Fold 4, logMAE: -1.9953743278050065\n",
      "*** Training Model for 2JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.497925\tvalid_1's l1: 0.513745\n",
      "[200]\ttraining's l1: 0.423337\tvalid_1's l1: 0.447164\n",
      "[300]\ttraining's l1: 0.381882\tvalid_1's l1: 0.411988\n",
      "[400]\ttraining's l1: 0.354275\tvalid_1's l1: 0.390135\n",
      "[500]\ttraining's l1: 0.332783\tvalid_1's l1: 0.373608\n",
      "[600]\ttraining's l1: 0.315793\tvalid_1's l1: 0.361103\n",
      "[700]\ttraining's l1: 0.301445\tvalid_1's l1: 0.350971\n",
      "[800]\ttraining's l1: 0.289347\tvalid_1's l1: 0.342664\n",
      "[900]\ttraining's l1: 0.278722\tvalid_1's l1: 0.335954\n",
      "[1000]\ttraining's l1: 0.269248\tvalid_1's l1: 0.330076\n",
      "[1100]\ttraining's l1: 0.260737\tvalid_1's l1: 0.324766\n",
      "[1200]\ttraining's l1: 0.253012\tvalid_1's l1: 0.320109\n",
      "[1300]\ttraining's l1: 0.245966\tvalid_1's l1: 0.316022\n",
      "[1400]\ttraining's l1: 0.239329\tvalid_1's l1: 0.312278\n",
      "[1500]\ttraining's l1: 0.233223\tvalid_1's l1: 0.308863\n",
      "[1600]\ttraining's l1: 0.227306\tvalid_1's l1: 0.305536\n",
      "[1700]\ttraining's l1: 0.222116\tvalid_1's l1: 0.302748\n",
      "[1800]\ttraining's l1: 0.217082\tvalid_1's l1: 0.300023\n",
      "[1900]\ttraining's l1: 0.212131\tvalid_1's l1: 0.297385\n",
      "[2000]\ttraining's l1: 0.207632\tvalid_1's l1: 0.295154\n",
      "[2100]\ttraining's l1: 0.203373\tvalid_1's l1: 0.293087\n",
      "[2200]\ttraining's l1: 0.199416\tvalid_1's l1: 0.291056\n",
      "[2300]\ttraining's l1: 0.195448\tvalid_1's l1: 0.289083\n",
      "[2400]\ttraining's l1: 0.19168\tvalid_1's l1: 0.287319\n",
      "[2500]\ttraining's l1: 0.188152\tvalid_1's l1: 0.285576\n",
      "[2600]\ttraining's l1: 0.184716\tvalid_1's l1: 0.284008\n",
      "[2700]\ttraining's l1: 0.181514\tvalid_1's l1: 0.282591\n",
      "[2800]\ttraining's l1: 0.178417\tvalid_1's l1: 0.281177\n",
      "[2900]\ttraining's l1: 0.175424\tvalid_1's l1: 0.27979\n",
      "[3000]\ttraining's l1: 0.172495\tvalid_1's l1: 0.278416\n",
      "[3100]\ttraining's l1: 0.169674\tvalid_1's l1: 0.277154\n",
      "[3200]\ttraining's l1: 0.166971\tvalid_1's l1: 0.275961\n",
      "[3300]\ttraining's l1: 0.164433\tvalid_1's l1: 0.274928\n",
      "[3400]\ttraining's l1: 0.161988\tvalid_1's l1: 0.273922\n",
      "[3500]\ttraining's l1: 0.159489\tvalid_1's l1: 0.272852\n",
      "[3600]\ttraining's l1: 0.157166\tvalid_1's l1: 0.271897\n",
      "[3700]\ttraining's l1: 0.154869\tvalid_1's l1: 0.270962\n",
      "[3800]\ttraining's l1: 0.152645\tvalid_1's l1: 0.270055\n",
      "[3900]\ttraining's l1: 0.15047\tvalid_1's l1: 0.269175\n",
      "[4000]\ttraining's l1: 0.148421\tvalid_1's l1: 0.268326\n",
      "[4100]\ttraining's l1: 0.146346\tvalid_1's l1: 0.267493\n",
      "[4200]\ttraining's l1: 0.144305\tvalid_1's l1: 0.26668\n",
      "[4300]\ttraining's l1: 0.142347\tvalid_1's l1: 0.265959\n",
      "[4400]\ttraining's l1: 0.14048\tvalid_1's l1: 0.265256\n",
      "[4500]\ttraining's l1: 0.138635\tvalid_1's l1: 0.264578\n",
      "[4600]\ttraining's l1: 0.136887\tvalid_1's l1: 0.263899\n",
      "[4700]\ttraining's l1: 0.135192\tvalid_1's l1: 0.263262\n",
      "[4800]\ttraining's l1: 0.133496\tvalid_1's l1: 0.262667\n",
      "[4900]\ttraining's l1: 0.131782\tvalid_1's l1: 0.261995\n",
      "[5000]\ttraining's l1: 0.130185\tvalid_1's l1: 0.26142\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.130185\tvalid_1's l1: 0.26142\n",
      "2JHC Fold 0, logMAE: -1.341627938978205\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.500469\tvalid_1's l1: 0.51488\n",
      "[200]\ttraining's l1: 0.423444\tvalid_1's l1: 0.446169\n",
      "[300]\ttraining's l1: 0.382425\tvalid_1's l1: 0.411567\n",
      "[400]\ttraining's l1: 0.354649\tvalid_1's l1: 0.389574\n",
      "[500]\ttraining's l1: 0.333249\tvalid_1's l1: 0.373245\n",
      "[600]\ttraining's l1: 0.31653\tvalid_1's l1: 0.361198\n",
      "[700]\ttraining's l1: 0.302265\tvalid_1's l1: 0.351287\n",
      "[800]\ttraining's l1: 0.290115\tvalid_1's l1: 0.343062\n",
      "[900]\ttraining's l1: 0.279248\tvalid_1's l1: 0.335801\n",
      "[1000]\ttraining's l1: 0.269587\tvalid_1's l1: 0.329593\n",
      "[1100]\ttraining's l1: 0.261271\tvalid_1's l1: 0.32432\n",
      "[1200]\ttraining's l1: 0.253669\tvalid_1's l1: 0.319787\n",
      "[1300]\ttraining's l1: 0.246619\tvalid_1's l1: 0.31555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's l1: 0.240027\tvalid_1's l1: 0.311649\n",
      "[1500]\ttraining's l1: 0.233843\tvalid_1's l1: 0.30813\n",
      "[1600]\ttraining's l1: 0.227974\tvalid_1's l1: 0.304944\n",
      "[1700]\ttraining's l1: 0.222545\tvalid_1's l1: 0.30212\n",
      "[1800]\ttraining's l1: 0.217465\tvalid_1's l1: 0.299255\n",
      "[1900]\ttraining's l1: 0.212733\tvalid_1's l1: 0.296735\n",
      "[2000]\ttraining's l1: 0.208321\tvalid_1's l1: 0.294551\n",
      "[2100]\ttraining's l1: 0.204062\tvalid_1's l1: 0.292455\n",
      "[2200]\ttraining's l1: 0.199967\tvalid_1's l1: 0.290466\n",
      "[2300]\ttraining's l1: 0.196147\tvalid_1's l1: 0.288597\n",
      "[2400]\ttraining's l1: 0.192331\tvalid_1's l1: 0.286733\n",
      "[2500]\ttraining's l1: 0.188784\tvalid_1's l1: 0.285055\n",
      "[2600]\ttraining's l1: 0.185497\tvalid_1's l1: 0.28364\n",
      "[2700]\ttraining's l1: 0.182182\tvalid_1's l1: 0.28217\n",
      "[2800]\ttraining's l1: 0.179014\tvalid_1's l1: 0.280762\n",
      "[2900]\ttraining's l1: 0.17601\tvalid_1's l1: 0.27943\n",
      "[3000]\ttraining's l1: 0.173047\tvalid_1's l1: 0.278114\n",
      "[3100]\ttraining's l1: 0.170174\tvalid_1's l1: 0.276812\n",
      "[3200]\ttraining's l1: 0.167489\tvalid_1's l1: 0.275673\n",
      "[3300]\ttraining's l1: 0.164872\tvalid_1's l1: 0.274502\n",
      "[3400]\ttraining's l1: 0.162343\tvalid_1's l1: 0.273471\n",
      "[3500]\ttraining's l1: 0.159853\tvalid_1's l1: 0.272465\n",
      "[3600]\ttraining's l1: 0.157482\tvalid_1's l1: 0.271497\n",
      "[3700]\ttraining's l1: 0.155148\tvalid_1's l1: 0.270556\n",
      "[3800]\ttraining's l1: 0.152903\tvalid_1's l1: 0.269671\n",
      "[3900]\ttraining's l1: 0.150784\tvalid_1's l1: 0.268776\n",
      "[4000]\ttraining's l1: 0.148718\tvalid_1's l1: 0.267974\n",
      "[4100]\ttraining's l1: 0.146616\tvalid_1's l1: 0.26715\n",
      "[4200]\ttraining's l1: 0.144563\tvalid_1's l1: 0.266316\n",
      "[4300]\ttraining's l1: 0.142612\tvalid_1's l1: 0.265615\n",
      "[4400]\ttraining's l1: 0.140679\tvalid_1's l1: 0.264893\n",
      "[4500]\ttraining's l1: 0.138797\tvalid_1's l1: 0.26418\n",
      "[4600]\ttraining's l1: 0.137012\tvalid_1's l1: 0.263574\n",
      "[4700]\ttraining's l1: 0.135277\tvalid_1's l1: 0.262929\n",
      "[4800]\ttraining's l1: 0.133608\tvalid_1's l1: 0.262304\n",
      "[4900]\ttraining's l1: 0.131984\tvalid_1's l1: 0.261749\n",
      "[5000]\ttraining's l1: 0.130361\tvalid_1's l1: 0.261133\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.130361\tvalid_1's l1: 0.261133\n",
      "2JHC Fold 1, logMAE: -1.3427238140331141\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.497618\tvalid_1's l1: 0.511273\n",
      "[200]\ttraining's l1: 0.424344\tvalid_1's l1: 0.445822\n",
      "[300]\ttraining's l1: 0.382347\tvalid_1's l1: 0.410616\n",
      "[400]\ttraining's l1: 0.35445\tvalid_1's l1: 0.388416\n",
      "[500]\ttraining's l1: 0.333546\tvalid_1's l1: 0.372769\n",
      "[600]\ttraining's l1: 0.315905\tvalid_1's l1: 0.359731\n",
      "[700]\ttraining's l1: 0.301539\tvalid_1's l1: 0.34966\n",
      "[800]\ttraining's l1: 0.28938\tvalid_1's l1: 0.341503\n",
      "[900]\ttraining's l1: 0.278746\tvalid_1's l1: 0.33462\n",
      "[1000]\ttraining's l1: 0.269276\tvalid_1's l1: 0.328633\n",
      "[1100]\ttraining's l1: 0.260664\tvalid_1's l1: 0.323235\n",
      "[1200]\ttraining's l1: 0.252771\tvalid_1's l1: 0.318378\n",
      "[1300]\ttraining's l1: 0.245687\tvalid_1's l1: 0.314287\n",
      "[1400]\ttraining's l1: 0.239164\tvalid_1's l1: 0.310397\n",
      "[1500]\ttraining's l1: 0.233122\tvalid_1's l1: 0.306927\n",
      "[1600]\ttraining's l1: 0.227356\tvalid_1's l1: 0.303744\n",
      "[1700]\ttraining's l1: 0.221982\tvalid_1's l1: 0.300819\n",
      "[1800]\ttraining's l1: 0.217031\tvalid_1's l1: 0.298258\n",
      "[1900]\ttraining's l1: 0.21218\tvalid_1's l1: 0.295676\n",
      "[2000]\ttraining's l1: 0.207798\tvalid_1's l1: 0.293412\n",
      "[2100]\ttraining's l1: 0.203509\tvalid_1's l1: 0.291218\n",
      "[2200]\ttraining's l1: 0.199404\tvalid_1's l1: 0.289129\n",
      "[2300]\ttraining's l1: 0.195481\tvalid_1's l1: 0.287185\n",
      "[2400]\ttraining's l1: 0.191857\tvalid_1's l1: 0.28544\n",
      "[2500]\ttraining's l1: 0.188336\tvalid_1's l1: 0.283815\n",
      "[2600]\ttraining's l1: 0.184914\tvalid_1's l1: 0.282261\n",
      "[2700]\ttraining's l1: 0.181515\tvalid_1's l1: 0.280645\n",
      "[2800]\ttraining's l1: 0.178429\tvalid_1's l1: 0.279277\n",
      "[2900]\ttraining's l1: 0.175393\tvalid_1's l1: 0.277977\n",
      "[3000]\ttraining's l1: 0.172455\tvalid_1's l1: 0.276679\n",
      "[3100]\ttraining's l1: 0.169628\tvalid_1's l1: 0.275433\n",
      "[3200]\ttraining's l1: 0.166957\tvalid_1's l1: 0.274277\n",
      "[3300]\ttraining's l1: 0.164316\tvalid_1's l1: 0.273166\n",
      "[3400]\ttraining's l1: 0.161744\tvalid_1's l1: 0.272078\n",
      "[3500]\ttraining's l1: 0.159307\tvalid_1's l1: 0.270989\n",
      "[3600]\ttraining's l1: 0.156931\tvalid_1's l1: 0.270011\n",
      "[3700]\ttraining's l1: 0.15461\tvalid_1's l1: 0.269121\n",
      "[3800]\ttraining's l1: 0.152401\tvalid_1's l1: 0.26819\n",
      "[3900]\ttraining's l1: 0.15025\tvalid_1's l1: 0.267333\n",
      "[4000]\ttraining's l1: 0.148238\tvalid_1's l1: 0.266587\n",
      "[4100]\ttraining's l1: 0.146172\tvalid_1's l1: 0.265734\n",
      "[4200]\ttraining's l1: 0.144141\tvalid_1's l1: 0.264974\n",
      "[4300]\ttraining's l1: 0.142155\tvalid_1's l1: 0.26421\n",
      "[4400]\ttraining's l1: 0.140279\tvalid_1's l1: 0.263487\n",
      "[4500]\ttraining's l1: 0.138458\tvalid_1's l1: 0.262774\n",
      "[4600]\ttraining's l1: 0.136724\tvalid_1's l1: 0.262124\n",
      "[4700]\ttraining's l1: 0.134971\tvalid_1's l1: 0.261474\n",
      "[4800]\ttraining's l1: 0.133215\tvalid_1's l1: 0.260796\n",
      "[4900]\ttraining's l1: 0.131567\tvalid_1's l1: 0.260191\n",
      "[5000]\ttraining's l1: 0.129977\tvalid_1's l1: 0.259677\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.129977\tvalid_1's l1: 0.259677\n",
      "2JHC Fold 2, logMAE: -1.3483163224133186\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.497008\tvalid_1's l1: 0.51266\n",
      "[200]\ttraining's l1: 0.422186\tvalid_1's l1: 0.445638\n",
      "[300]\ttraining's l1: 0.381318\tvalid_1's l1: 0.410865\n",
      "[400]\ttraining's l1: 0.353296\tvalid_1's l1: 0.388385\n",
      "[500]\ttraining's l1: 0.332547\tvalid_1's l1: 0.372661\n",
      "[600]\ttraining's l1: 0.315435\tvalid_1's l1: 0.359982\n",
      "[700]\ttraining's l1: 0.301221\tvalid_1's l1: 0.350096\n",
      "[800]\ttraining's l1: 0.289251\tvalid_1's l1: 0.34215\n",
      "[900]\ttraining's l1: 0.278568\tvalid_1's l1: 0.335155\n",
      "[1000]\ttraining's l1: 0.269257\tvalid_1's l1: 0.329096\n",
      "[1100]\ttraining's l1: 0.260639\tvalid_1's l1: 0.323671\n",
      "[1200]\ttraining's l1: 0.252829\tvalid_1's l1: 0.319072\n",
      "[1300]\ttraining's l1: 0.24567\tvalid_1's l1: 0.31484\n",
      "[1400]\ttraining's l1: 0.239033\tvalid_1's l1: 0.310992\n",
      "[1500]\ttraining's l1: 0.232967\tvalid_1's l1: 0.307638\n",
      "[1600]\ttraining's l1: 0.227463\tvalid_1's l1: 0.304614\n",
      "[1700]\ttraining's l1: 0.222139\tvalid_1's l1: 0.301759\n",
      "[1800]\ttraining's l1: 0.216968\tvalid_1's l1: 0.299026\n",
      "[1900]\ttraining's l1: 0.212108\tvalid_1's l1: 0.29641\n",
      "[2000]\ttraining's l1: 0.207512\tvalid_1's l1: 0.29405\n",
      "[2100]\ttraining's l1: 0.203252\tvalid_1's l1: 0.291928\n",
      "[2200]\ttraining's l1: 0.19921\tvalid_1's l1: 0.290062\n",
      "[2300]\ttraining's l1: 0.195341\tvalid_1's l1: 0.288329\n",
      "[2400]\ttraining's l1: 0.191698\tvalid_1's l1: 0.286642\n",
      "[2500]\ttraining's l1: 0.188204\tvalid_1's l1: 0.285005\n",
      "[2600]\ttraining's l1: 0.184787\tvalid_1's l1: 0.283449\n",
      "[2700]\ttraining's l1: 0.181469\tvalid_1's l1: 0.281914\n",
      "[2800]\ttraining's l1: 0.178411\tvalid_1's l1: 0.28056\n",
      "[2900]\ttraining's l1: 0.175421\tvalid_1's l1: 0.279262\n",
      "[3000]\ttraining's l1: 0.172621\tvalid_1's l1: 0.278061\n",
      "[3100]\ttraining's l1: 0.169808\tvalid_1's l1: 0.27684\n",
      "[3200]\ttraining's l1: 0.16708\tvalid_1's l1: 0.275595\n",
      "[3300]\ttraining's l1: 0.164435\tvalid_1's l1: 0.274535\n",
      "[3400]\ttraining's l1: 0.161902\tvalid_1's l1: 0.273469\n",
      "[3500]\ttraining's l1: 0.159364\tvalid_1's l1: 0.272473\n",
      "[3600]\ttraining's l1: 0.15697\tvalid_1's l1: 0.271515\n",
      "[3700]\ttraining's l1: 0.154706\tvalid_1's l1: 0.270632\n",
      "[3800]\ttraining's l1: 0.152458\tvalid_1's l1: 0.269799\n",
      "[3900]\ttraining's l1: 0.150289\tvalid_1's l1: 0.268871\n",
      "[4000]\ttraining's l1: 0.148223\tvalid_1's l1: 0.268127\n",
      "[4100]\ttraining's l1: 0.146154\tvalid_1's l1: 0.267298\n",
      "[4200]\ttraining's l1: 0.144106\tvalid_1's l1: 0.266501\n",
      "[4300]\ttraining's l1: 0.142199\tvalid_1's l1: 0.26579\n",
      "[4400]\ttraining's l1: 0.140301\tvalid_1's l1: 0.265119\n",
      "[4500]\ttraining's l1: 0.138439\tvalid_1's l1: 0.264459\n",
      "[4600]\ttraining's l1: 0.136596\tvalid_1's l1: 0.263777\n",
      "[4700]\ttraining's l1: 0.134802\tvalid_1's l1: 0.263047\n",
      "[4800]\ttraining's l1: 0.133084\tvalid_1's l1: 0.262439\n",
      "[4900]\ttraining's l1: 0.131476\tvalid_1's l1: 0.261834\n",
      "[5000]\ttraining's l1: 0.129847\tvalid_1's l1: 0.261227\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.129847\tvalid_1's l1: 0.261227\n",
      "2JHC Fold 3, logMAE: -1.3423637462826632\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.499536\tvalid_1's l1: 0.513829\n",
      "[200]\ttraining's l1: 0.423683\tvalid_1's l1: 0.447315\n",
      "[300]\ttraining's l1: 0.381526\tvalid_1's l1: 0.411954\n",
      "[400]\ttraining's l1: 0.353825\tvalid_1's l1: 0.390193\n",
      "[500]\ttraining's l1: 0.332953\tvalid_1's l1: 0.37428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's l1: 0.31577\tvalid_1's l1: 0.361687\n",
      "[700]\ttraining's l1: 0.30147\tvalid_1's l1: 0.351665\n",
      "[800]\ttraining's l1: 0.289183\tvalid_1's l1: 0.343184\n",
      "[900]\ttraining's l1: 0.278539\tvalid_1's l1: 0.336136\n",
      "[1000]\ttraining's l1: 0.269016\tvalid_1's l1: 0.32997\n",
      "[1100]\ttraining's l1: 0.260507\tvalid_1's l1: 0.32465\n",
      "[1200]\ttraining's l1: 0.252981\tvalid_1's l1: 0.320063\n",
      "[1300]\ttraining's l1: 0.245853\tvalid_1's l1: 0.315685\n",
      "[1400]\ttraining's l1: 0.239107\tvalid_1's l1: 0.311555\n",
      "[1500]\ttraining's l1: 0.232968\tvalid_1's l1: 0.307997\n",
      "[1600]\ttraining's l1: 0.22717\tvalid_1's l1: 0.304812\n",
      "[1700]\ttraining's l1: 0.221829\tvalid_1's l1: 0.301951\n",
      "[1800]\ttraining's l1: 0.216784\tvalid_1's l1: 0.29935\n",
      "[1900]\ttraining's l1: 0.212089\tvalid_1's l1: 0.296826\n",
      "[2000]\ttraining's l1: 0.207605\tvalid_1's l1: 0.294576\n",
      "[2100]\ttraining's l1: 0.203305\tvalid_1's l1: 0.292501\n",
      "[2200]\ttraining's l1: 0.199157\tvalid_1's l1: 0.290484\n",
      "[2300]\ttraining's l1: 0.195155\tvalid_1's l1: 0.288568\n",
      "[2400]\ttraining's l1: 0.191485\tvalid_1's l1: 0.286902\n",
      "[2500]\ttraining's l1: 0.187908\tvalid_1's l1: 0.285167\n",
      "[2600]\ttraining's l1: 0.184586\tvalid_1's l1: 0.283615\n",
      "[2700]\ttraining's l1: 0.181386\tvalid_1's l1: 0.282136\n",
      "[2800]\ttraining's l1: 0.178293\tvalid_1's l1: 0.280669\n",
      "[2900]\ttraining's l1: 0.175256\tvalid_1's l1: 0.279282\n",
      "[3000]\ttraining's l1: 0.172357\tvalid_1's l1: 0.277961\n",
      "[3100]\ttraining's l1: 0.169525\tvalid_1's l1: 0.276694\n",
      "[3200]\ttraining's l1: 0.166772\tvalid_1's l1: 0.275499\n",
      "[3300]\ttraining's l1: 0.164142\tvalid_1's l1: 0.274413\n",
      "[3400]\ttraining's l1: 0.161667\tvalid_1's l1: 0.273394\n",
      "[3500]\ttraining's l1: 0.159238\tvalid_1's l1: 0.272414\n",
      "[3600]\ttraining's l1: 0.156867\tvalid_1's l1: 0.271485\n",
      "[3700]\ttraining's l1: 0.154574\tvalid_1's l1: 0.270546\n",
      "[3800]\ttraining's l1: 0.152383\tvalid_1's l1: 0.269639\n",
      "[3900]\ttraining's l1: 0.15016\tvalid_1's l1: 0.268776\n",
      "[4000]\ttraining's l1: 0.148075\tvalid_1's l1: 0.267991\n",
      "[4100]\ttraining's l1: 0.14607\tvalid_1's l1: 0.267194\n",
      "[4200]\ttraining's l1: 0.144057\tvalid_1's l1: 0.26642\n",
      "[4300]\ttraining's l1: 0.142101\tvalid_1's l1: 0.265651\n",
      "[4400]\ttraining's l1: 0.140264\tvalid_1's l1: 0.264996\n",
      "[4500]\ttraining's l1: 0.138419\tvalid_1's l1: 0.264291\n",
      "[4600]\ttraining's l1: 0.136645\tvalid_1's l1: 0.263657\n",
      "[4700]\ttraining's l1: 0.134924\tvalid_1's l1: 0.262985\n",
      "[4800]\ttraining's l1: 0.133234\tvalid_1's l1: 0.26233\n",
      "[4900]\ttraining's l1: 0.131549\tvalid_1's l1: 0.261715\n",
      "[5000]\ttraining's l1: 0.129876\tvalid_1's l1: 0.261107\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.129876\tvalid_1's l1: 0.261107\n",
      "2JHC Fold 4, logMAE: -1.3428242050921455\n",
      "*** Training Model for 3JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.280327\tvalid_1's l1: 0.291067\n",
      "[200]\ttraining's l1: 0.232993\tvalid_1's l1: 0.251791\n",
      "[300]\ttraining's l1: 0.207293\tvalid_1's l1: 0.23221\n",
      "[400]\ttraining's l1: 0.189567\tvalid_1's l1: 0.219467\n",
      "[500]\ttraining's l1: 0.176123\tvalid_1's l1: 0.210163\n",
      "[600]\ttraining's l1: 0.1651\tvalid_1's l1: 0.202964\n",
      "[700]\ttraining's l1: 0.155982\tvalid_1's l1: 0.197295\n",
      "[800]\ttraining's l1: 0.148193\tvalid_1's l1: 0.192722\n",
      "[900]\ttraining's l1: 0.141385\tvalid_1's l1: 0.188949\n",
      "[1000]\ttraining's l1: 0.135449\tvalid_1's l1: 0.18584\n",
      "[1100]\ttraining's l1: 0.130066\tvalid_1's l1: 0.183147\n",
      "[1200]\ttraining's l1: 0.125088\tvalid_1's l1: 0.18065\n",
      "[1300]\ttraining's l1: 0.120682\tvalid_1's l1: 0.178515\n",
      "[1400]\ttraining's l1: 0.116524\tvalid_1's l1: 0.176642\n",
      "[1500]\ttraining's l1: 0.112711\tvalid_1's l1: 0.174937\n",
      "[1600]\ttraining's l1: 0.109127\tvalid_1's l1: 0.173437\n",
      "[1700]\ttraining's l1: 0.105933\tvalid_1's l1: 0.172055\n",
      "[1800]\ttraining's l1: 0.102843\tvalid_1's l1: 0.170719\n",
      "[1900]\ttraining's l1: 0.0999239\tvalid_1's l1: 0.169542\n",
      "[2000]\ttraining's l1: 0.0972268\tvalid_1's l1: 0.168401\n",
      "[2100]\ttraining's l1: 0.0945423\tvalid_1's l1: 0.167306\n",
      "[2200]\ttraining's l1: 0.0921075\tvalid_1's l1: 0.166367\n",
      "[2300]\ttraining's l1: 0.0897601\tvalid_1's l1: 0.165415\n",
      "[2400]\ttraining's l1: 0.0875544\tvalid_1's l1: 0.164599\n",
      "[2500]\ttraining's l1: 0.0853936\tvalid_1's l1: 0.163824\n",
      "[2600]\ttraining's l1: 0.0833644\tvalid_1's l1: 0.163095\n",
      "[2700]\ttraining's l1: 0.0813951\tvalid_1's l1: 0.16241\n",
      "[2800]\ttraining's l1: 0.0795178\tvalid_1's l1: 0.161787\n",
      "[2900]\ttraining's l1: 0.0776981\tvalid_1's l1: 0.16117\n",
      "[3000]\ttraining's l1: 0.0759961\tvalid_1's l1: 0.16056\n",
      "[3100]\ttraining's l1: 0.0742989\tvalid_1's l1: 0.160025\n",
      "[3200]\ttraining's l1: 0.0727204\tvalid_1's l1: 0.159479\n",
      "[3300]\ttraining's l1: 0.071188\tvalid_1's l1: 0.158987\n",
      "[3400]\ttraining's l1: 0.0697226\tvalid_1's l1: 0.158549\n",
      "[3500]\ttraining's l1: 0.0683186\tvalid_1's l1: 0.1581\n",
      "[3600]\ttraining's l1: 0.0669327\tvalid_1's l1: 0.157697\n",
      "[3700]\ttraining's l1: 0.0655697\tvalid_1's l1: 0.157269\n",
      "[3800]\ttraining's l1: 0.0643174\tvalid_1's l1: 0.156917\n",
      "[3900]\ttraining's l1: 0.0630766\tvalid_1's l1: 0.156521\n",
      "[4000]\ttraining's l1: 0.0618896\tvalid_1's l1: 0.15619\n",
      "[4100]\ttraining's l1: 0.0607299\tvalid_1's l1: 0.155853\n",
      "[4200]\ttraining's l1: 0.0595906\tvalid_1's l1: 0.155502\n",
      "[4300]\ttraining's l1: 0.0584916\tvalid_1's l1: 0.155177\n",
      "[4400]\ttraining's l1: 0.0574334\tvalid_1's l1: 0.154888\n",
      "[4500]\ttraining's l1: 0.0563862\tvalid_1's l1: 0.154576\n",
      "[4600]\ttraining's l1: 0.0554151\tvalid_1's l1: 0.154308\n",
      "[4700]\ttraining's l1: 0.0544762\tvalid_1's l1: 0.154043\n",
      "[4800]\ttraining's l1: 0.0535225\tvalid_1's l1: 0.153795\n",
      "[4900]\ttraining's l1: 0.0526082\tvalid_1's l1: 0.153538\n",
      "[5000]\ttraining's l1: 0.0517459\tvalid_1's l1: 0.153308\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0517459\tvalid_1's l1: 0.153308\n",
      "3JHH Fold 0, logMAE: -1.8753055306755781\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.282537\tvalid_1's l1: 0.296221\n",
      "[200]\ttraining's l1: 0.232391\tvalid_1's l1: 0.253699\n",
      "[300]\ttraining's l1: 0.205748\tvalid_1's l1: 0.232714\n",
      "[400]\ttraining's l1: 0.187811\tvalid_1's l1: 0.219787\n",
      "[500]\ttraining's l1: 0.174789\tvalid_1's l1: 0.210916\n",
      "[600]\ttraining's l1: 0.164292\tvalid_1's l1: 0.204437\n",
      "[700]\ttraining's l1: 0.155357\tvalid_1's l1: 0.199077\n",
      "[800]\ttraining's l1: 0.147782\tvalid_1's l1: 0.194634\n",
      "[900]\ttraining's l1: 0.141084\tvalid_1's l1: 0.190834\n",
      "[1000]\ttraining's l1: 0.134996\tvalid_1's l1: 0.187512\n",
      "[1100]\ttraining's l1: 0.129706\tvalid_1's l1: 0.184743\n",
      "[1200]\ttraining's l1: 0.124901\tvalid_1's l1: 0.182351\n",
      "[1300]\ttraining's l1: 0.12038\tvalid_1's l1: 0.180156\n",
      "[1400]\ttraining's l1: 0.116283\tvalid_1's l1: 0.17825\n",
      "[1500]\ttraining's l1: 0.112527\tvalid_1's l1: 0.176499\n",
      "[1600]\ttraining's l1: 0.109019\tvalid_1's l1: 0.174994\n",
      "[1700]\ttraining's l1: 0.105597\tvalid_1's l1: 0.173519\n",
      "[1800]\ttraining's l1: 0.102516\tvalid_1's l1: 0.17222\n",
      "[1900]\ttraining's l1: 0.0997134\tvalid_1's l1: 0.171147\n",
      "[2000]\ttraining's l1: 0.0970069\tvalid_1's l1: 0.170036\n",
      "[2100]\ttraining's l1: 0.094376\tvalid_1's l1: 0.169013\n",
      "[2200]\ttraining's l1: 0.0919067\tvalid_1's l1: 0.168113\n",
      "[2300]\ttraining's l1: 0.0895805\tvalid_1's l1: 0.167305\n",
      "[2400]\ttraining's l1: 0.0873842\tvalid_1's l1: 0.166477\n",
      "[2500]\ttraining's l1: 0.0852367\tvalid_1's l1: 0.165631\n",
      "[2600]\ttraining's l1: 0.0832253\tvalid_1's l1: 0.1649\n",
      "[2700]\ttraining's l1: 0.0812912\tvalid_1's l1: 0.164187\n",
      "[2800]\ttraining's l1: 0.0794467\tvalid_1's l1: 0.163509\n",
      "[2900]\ttraining's l1: 0.0777109\tvalid_1's l1: 0.162929\n",
      "[3000]\ttraining's l1: 0.0759742\tvalid_1's l1: 0.162288\n",
      "[3100]\ttraining's l1: 0.0742962\tvalid_1's l1: 0.161697\n",
      "[3200]\ttraining's l1: 0.0727332\tvalid_1's l1: 0.161189\n",
      "[3300]\ttraining's l1: 0.0712235\tvalid_1's l1: 0.160685\n",
      "[3400]\ttraining's l1: 0.0697599\tvalid_1's l1: 0.160209\n",
      "[3500]\ttraining's l1: 0.0683368\tvalid_1's l1: 0.159758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600]\ttraining's l1: 0.0669734\tvalid_1's l1: 0.15933\n",
      "[3700]\ttraining's l1: 0.065684\tvalid_1's l1: 0.15894\n",
      "[3800]\ttraining's l1: 0.0644081\tvalid_1's l1: 0.158558\n",
      "[3900]\ttraining's l1: 0.0631791\tvalid_1's l1: 0.158181\n",
      "[4000]\ttraining's l1: 0.0619467\tvalid_1's l1: 0.15784\n",
      "[4100]\ttraining's l1: 0.0607867\tvalid_1's l1: 0.157502\n",
      "[4200]\ttraining's l1: 0.0596747\tvalid_1's l1: 0.157212\n",
      "[4300]\ttraining's l1: 0.0585797\tvalid_1's l1: 0.156884\n",
      "[4400]\ttraining's l1: 0.0575518\tvalid_1's l1: 0.156616\n",
      "[4500]\ttraining's l1: 0.0565339\tvalid_1's l1: 0.156361\n",
      "[4600]\ttraining's l1: 0.0555336\tvalid_1's l1: 0.156106\n",
      "[4700]\ttraining's l1: 0.0545812\tvalid_1's l1: 0.15585\n",
      "[4800]\ttraining's l1: 0.053671\tvalid_1's l1: 0.155598\n",
      "[4900]\ttraining's l1: 0.0527622\tvalid_1's l1: 0.155372\n",
      "[5000]\ttraining's l1: 0.0518901\tvalid_1's l1: 0.155138\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0518901\tvalid_1's l1: 0.155138\n",
      "3JHH Fold 1, logMAE: -1.863437326160381\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.281002\tvalid_1's l1: 0.294665\n",
      "[200]\ttraining's l1: 0.231325\tvalid_1's l1: 0.252154\n",
      "[300]\ttraining's l1: 0.205184\tvalid_1's l1: 0.231769\n",
      "[400]\ttraining's l1: 0.187832\tvalid_1's l1: 0.21908\n",
      "[500]\ttraining's l1: 0.175041\tvalid_1's l1: 0.210338\n",
      "[600]\ttraining's l1: 0.164168\tvalid_1's l1: 0.203464\n",
      "[700]\ttraining's l1: 0.155345\tvalid_1's l1: 0.1981\n",
      "[800]\ttraining's l1: 0.147491\tvalid_1's l1: 0.193506\n",
      "[900]\ttraining's l1: 0.140779\tvalid_1's l1: 0.18976\n",
      "[1000]\ttraining's l1: 0.134851\tvalid_1's l1: 0.186627\n",
      "[1100]\ttraining's l1: 0.129587\tvalid_1's l1: 0.183906\n",
      "[1200]\ttraining's l1: 0.124769\tvalid_1's l1: 0.181513\n",
      "[1300]\ttraining's l1: 0.120233\tvalid_1's l1: 0.179332\n",
      "[1400]\ttraining's l1: 0.116118\tvalid_1's l1: 0.17735\n",
      "[1500]\ttraining's l1: 0.112377\tvalid_1's l1: 0.175624\n",
      "[1600]\ttraining's l1: 0.108877\tvalid_1's l1: 0.174129\n",
      "[1700]\ttraining's l1: 0.105473\tvalid_1's l1: 0.172646\n",
      "[1800]\ttraining's l1: 0.102389\tvalid_1's l1: 0.1713\n",
      "[1900]\ttraining's l1: 0.099442\tvalid_1's l1: 0.170096\n",
      "[2000]\ttraining's l1: 0.0967241\tvalid_1's l1: 0.16898\n",
      "[2100]\ttraining's l1: 0.0941529\tvalid_1's l1: 0.167959\n",
      "[2200]\ttraining's l1: 0.0917019\tvalid_1's l1: 0.167105\n",
      "[2300]\ttraining's l1: 0.0893762\tvalid_1's l1: 0.166272\n",
      "[2400]\ttraining's l1: 0.0871439\tvalid_1's l1: 0.165389\n",
      "[2500]\ttraining's l1: 0.0849799\tvalid_1's l1: 0.164598\n",
      "[2600]\ttraining's l1: 0.0829381\tvalid_1's l1: 0.163921\n",
      "[2700]\ttraining's l1: 0.0810625\tvalid_1's l1: 0.163233\n",
      "[2800]\ttraining's l1: 0.0791731\tvalid_1's l1: 0.162585\n",
      "[2900]\ttraining's l1: 0.0773707\tvalid_1's l1: 0.161891\n",
      "[3000]\ttraining's l1: 0.0757097\tvalid_1's l1: 0.161331\n",
      "[3100]\ttraining's l1: 0.0740876\tvalid_1's l1: 0.160834\n",
      "[3200]\ttraining's l1: 0.072476\tvalid_1's l1: 0.160298\n",
      "[3300]\ttraining's l1: 0.0709785\tvalid_1's l1: 0.159836\n",
      "[3400]\ttraining's l1: 0.0695058\tvalid_1's l1: 0.159344\n",
      "[3500]\ttraining's l1: 0.0680722\tvalid_1's l1: 0.158888\n",
      "[3600]\ttraining's l1: 0.0667107\tvalid_1's l1: 0.15846\n",
      "[3700]\ttraining's l1: 0.0654189\tvalid_1's l1: 0.158058\n",
      "[3800]\ttraining's l1: 0.0641468\tvalid_1's l1: 0.157689\n",
      "[3900]\ttraining's l1: 0.0629421\tvalid_1's l1: 0.157306\n",
      "[4000]\ttraining's l1: 0.0617356\tvalid_1's l1: 0.156943\n",
      "[4100]\ttraining's l1: 0.0605421\tvalid_1's l1: 0.156593\n",
      "[4200]\ttraining's l1: 0.0594103\tvalid_1's l1: 0.156277\n",
      "[4300]\ttraining's l1: 0.0583524\tvalid_1's l1: 0.155983\n",
      "[4400]\ttraining's l1: 0.0573192\tvalid_1's l1: 0.1557\n",
      "[4500]\ttraining's l1: 0.0562976\tvalid_1's l1: 0.155423\n",
      "[4600]\ttraining's l1: 0.0553219\tvalid_1's l1: 0.155187\n",
      "[4700]\ttraining's l1: 0.0543596\tvalid_1's l1: 0.154935\n",
      "[4800]\ttraining's l1: 0.05345\tvalid_1's l1: 0.154688\n",
      "[4900]\ttraining's l1: 0.0525538\tvalid_1's l1: 0.154441\n",
      "[5000]\ttraining's l1: 0.0516611\tvalid_1's l1: 0.154197\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0516611\tvalid_1's l1: 0.154197\n",
      "3JHH Fold 2, logMAE: -1.8695274641743753\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.279005\tvalid_1's l1: 0.294271\n",
      "[200]\ttraining's l1: 0.231358\tvalid_1's l1: 0.254219\n",
      "[300]\ttraining's l1: 0.205683\tvalid_1's l1: 0.234133\n",
      "[400]\ttraining's l1: 0.188202\tvalid_1's l1: 0.221429\n",
      "[500]\ttraining's l1: 0.174766\tvalid_1's l1: 0.212172\n",
      "[600]\ttraining's l1: 0.164192\tvalid_1's l1: 0.205582\n",
      "[700]\ttraining's l1: 0.155255\tvalid_1's l1: 0.200192\n",
      "[800]\ttraining's l1: 0.147561\tvalid_1's l1: 0.195578\n",
      "[900]\ttraining's l1: 0.140809\tvalid_1's l1: 0.191739\n",
      "[1000]\ttraining's l1: 0.134936\tvalid_1's l1: 0.188446\n",
      "[1100]\ttraining's l1: 0.129693\tvalid_1's l1: 0.185783\n",
      "[1200]\ttraining's l1: 0.124785\tvalid_1's l1: 0.183221\n",
      "[1300]\ttraining's l1: 0.120294\tvalid_1's l1: 0.181064\n",
      "[1400]\ttraining's l1: 0.116059\tvalid_1's l1: 0.179013\n",
      "[1500]\ttraining's l1: 0.1123\tvalid_1's l1: 0.177357\n",
      "[1600]\ttraining's l1: 0.108767\tvalid_1's l1: 0.175735\n",
      "[1700]\ttraining's l1: 0.105425\tvalid_1's l1: 0.174313\n",
      "[1800]\ttraining's l1: 0.102294\tvalid_1's l1: 0.173014\n",
      "[1900]\ttraining's l1: 0.099397\tvalid_1's l1: 0.171742\n",
      "[2000]\ttraining's l1: 0.0967068\tvalid_1's l1: 0.170702\n",
      "[2100]\ttraining's l1: 0.0941293\tvalid_1's l1: 0.16966\n",
      "[2200]\ttraining's l1: 0.0916677\tvalid_1's l1: 0.16869\n",
      "[2300]\ttraining's l1: 0.0893232\tvalid_1's l1: 0.16784\n",
      "[2400]\ttraining's l1: 0.087107\tvalid_1's l1: 0.167004\n",
      "[2500]\ttraining's l1: 0.0849694\tvalid_1's l1: 0.166239\n",
      "[2600]\ttraining's l1: 0.0829509\tvalid_1's l1: 0.165529\n",
      "[2700]\ttraining's l1: 0.0810145\tvalid_1's l1: 0.164832\n",
      "[2800]\ttraining's l1: 0.0791352\tvalid_1's l1: 0.16412\n",
      "[2900]\ttraining's l1: 0.0773228\tvalid_1's l1: 0.163517\n",
      "[3000]\ttraining's l1: 0.0756247\tvalid_1's l1: 0.162933\n",
      "[3100]\ttraining's l1: 0.0739768\tvalid_1's l1: 0.162358\n",
      "[3200]\ttraining's l1: 0.0723556\tvalid_1's l1: 0.161839\n",
      "[3300]\ttraining's l1: 0.0708223\tvalid_1's l1: 0.161373\n",
      "[3400]\ttraining's l1: 0.0693474\tvalid_1's l1: 0.160892\n",
      "[3500]\ttraining's l1: 0.0679309\tvalid_1's l1: 0.160428\n",
      "[3600]\ttraining's l1: 0.0665388\tvalid_1's l1: 0.160022\n",
      "[3700]\ttraining's l1: 0.0652211\tvalid_1's l1: 0.159647\n",
      "[3800]\ttraining's l1: 0.0639348\tvalid_1's l1: 0.159259\n",
      "[3900]\ttraining's l1: 0.0627088\tvalid_1's l1: 0.158916\n",
      "[4000]\ttraining's l1: 0.0615416\tvalid_1's l1: 0.158554\n",
      "[4100]\ttraining's l1: 0.0603916\tvalid_1's l1: 0.158257\n",
      "[4200]\ttraining's l1: 0.0592813\tvalid_1's l1: 0.157962\n",
      "[4300]\ttraining's l1: 0.0582333\tvalid_1's l1: 0.157657\n",
      "[4400]\ttraining's l1: 0.0571738\tvalid_1's l1: 0.157342\n",
      "[4500]\ttraining's l1: 0.0561117\tvalid_1's l1: 0.157039\n",
      "[4600]\ttraining's l1: 0.0551564\tvalid_1's l1: 0.156766\n",
      "[4700]\ttraining's l1: 0.0541953\tvalid_1's l1: 0.156503\n",
      "[4800]\ttraining's l1: 0.0532536\tvalid_1's l1: 0.156269\n",
      "[4900]\ttraining's l1: 0.0523789\tvalid_1's l1: 0.156035\n",
      "[5000]\ttraining's l1: 0.0514914\tvalid_1's l1: 0.155768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0514914\tvalid_1's l1: 0.155768\n",
      "3JHH Fold 3, logMAE: -1.8593877311471019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.281941\tvalid_1's l1: 0.295265\n",
      "[200]\ttraining's l1: 0.23154\tvalid_1's l1: 0.252261\n",
      "[300]\ttraining's l1: 0.205833\tvalid_1's l1: 0.232277\n",
      "[400]\ttraining's l1: 0.187841\tvalid_1's l1: 0.219381\n",
      "[500]\ttraining's l1: 0.174757\tvalid_1's l1: 0.210613\n",
      "[600]\ttraining's l1: 0.163708\tvalid_1's l1: 0.203605\n",
      "[700]\ttraining's l1: 0.15497\tvalid_1's l1: 0.198278\n",
      "[800]\ttraining's l1: 0.147328\tvalid_1's l1: 0.193811\n",
      "[900]\ttraining's l1: 0.14061\tvalid_1's l1: 0.190111\n",
      "[1000]\ttraining's l1: 0.134842\tvalid_1's l1: 0.187138\n",
      "[1100]\ttraining's l1: 0.12941\tvalid_1's l1: 0.184413\n",
      "[1200]\ttraining's l1: 0.124706\tvalid_1's l1: 0.182117\n",
      "[1300]\ttraining's l1: 0.120374\tvalid_1's l1: 0.180044\n",
      "[1400]\ttraining's l1: 0.116234\tvalid_1's l1: 0.178146\n",
      "[1500]\ttraining's l1: 0.112512\tvalid_1's l1: 0.176359\n",
      "[1600]\ttraining's l1: 0.109051\tvalid_1's l1: 0.174897\n",
      "[1700]\ttraining's l1: 0.105759\tvalid_1's l1: 0.173432\n",
      "[1800]\ttraining's l1: 0.102703\tvalid_1's l1: 0.172167\n",
      "[1900]\ttraining's l1: 0.0998178\tvalid_1's l1: 0.170934\n",
      "[2000]\ttraining's l1: 0.0971036\tvalid_1's l1: 0.169828\n",
      "[2100]\ttraining's l1: 0.0945147\tvalid_1's l1: 0.168806\n",
      "[2200]\ttraining's l1: 0.0920636\tvalid_1's l1: 0.167822\n",
      "[2300]\ttraining's l1: 0.0897558\tvalid_1's l1: 0.166918\n",
      "[2400]\ttraining's l1: 0.0875504\tvalid_1's l1: 0.166066\n",
      "[2500]\ttraining's l1: 0.0854103\tvalid_1's l1: 0.165315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2600]\ttraining's l1: 0.0833286\tvalid_1's l1: 0.164549\n",
      "[2700]\ttraining's l1: 0.0813919\tvalid_1's l1: 0.163799\n",
      "[2800]\ttraining's l1: 0.0795413\tvalid_1's l1: 0.163127\n",
      "[2900]\ttraining's l1: 0.0777317\tvalid_1's l1: 0.162527\n",
      "[3000]\ttraining's l1: 0.0760048\tvalid_1's l1: 0.161961\n",
      "[3100]\ttraining's l1: 0.074356\tvalid_1's l1: 0.161381\n",
      "[3200]\ttraining's l1: 0.0727546\tvalid_1's l1: 0.160855\n",
      "[3300]\ttraining's l1: 0.0712093\tvalid_1's l1: 0.160368\n",
      "[3400]\ttraining's l1: 0.0697751\tvalid_1's l1: 0.159918\n",
      "[3500]\ttraining's l1: 0.0683382\tvalid_1's l1: 0.159456\n",
      "[3600]\ttraining's l1: 0.0669548\tvalid_1's l1: 0.158996\n",
      "[3700]\ttraining's l1: 0.0656514\tvalid_1's l1: 0.158616\n",
      "[3800]\ttraining's l1: 0.0643608\tvalid_1's l1: 0.158217\n",
      "[3900]\ttraining's l1: 0.0631362\tvalid_1's l1: 0.15785\n",
      "[4000]\ttraining's l1: 0.0619564\tvalid_1's l1: 0.157528\n",
      "[4100]\ttraining's l1: 0.0607871\tvalid_1's l1: 0.157213\n",
      "[4200]\ttraining's l1: 0.0596836\tvalid_1's l1: 0.156857\n",
      "[4300]\ttraining's l1: 0.0585967\tvalid_1's l1: 0.156512\n",
      "[4400]\ttraining's l1: 0.0574998\tvalid_1's l1: 0.156197\n",
      "[4500]\ttraining's l1: 0.0564917\tvalid_1's l1: 0.155904\n",
      "[4600]\ttraining's l1: 0.0555263\tvalid_1's l1: 0.155639\n",
      "[4700]\ttraining's l1: 0.0545815\tvalid_1's l1: 0.155374\n",
      "[4800]\ttraining's l1: 0.0536331\tvalid_1's l1: 0.155116\n",
      "[4900]\ttraining's l1: 0.0527284\tvalid_1's l1: 0.15489\n",
      "[5000]\ttraining's l1: 0.0518553\tvalid_1's l1: 0.154653\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0518553\tvalid_1's l1: 0.154653\n",
      "3JHH Fold 4, logMAE: -1.8665708146971969\n",
      "*** Training Model for 3JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.553973\tvalid_1's l1: 0.564726\n",
      "[200]\ttraining's l1: 0.472044\tvalid_1's l1: 0.48982\n",
      "[300]\ttraining's l1: 0.428695\tvalid_1's l1: 0.452611\n",
      "[400]\ttraining's l1: 0.399792\tvalid_1's l1: 0.428629\n",
      "[500]\ttraining's l1: 0.378335\tvalid_1's l1: 0.411528\n",
      "[600]\ttraining's l1: 0.360634\tvalid_1's l1: 0.397982\n",
      "[700]\ttraining's l1: 0.345573\tvalid_1's l1: 0.38704\n",
      "[800]\ttraining's l1: 0.332918\tvalid_1's l1: 0.37802\n",
      "[900]\ttraining's l1: 0.321658\tvalid_1's l1: 0.370385\n",
      "[1000]\ttraining's l1: 0.311751\tvalid_1's l1: 0.363623\n",
      "[1100]\ttraining's l1: 0.302824\tvalid_1's l1: 0.357819\n",
      "[1200]\ttraining's l1: 0.294639\tvalid_1's l1: 0.35256\n",
      "[1300]\ttraining's l1: 0.287035\tvalid_1's l1: 0.347756\n",
      "[1400]\ttraining's l1: 0.280056\tvalid_1's l1: 0.343612\n",
      "[1500]\ttraining's l1: 0.273652\tvalid_1's l1: 0.339829\n",
      "[1600]\ttraining's l1: 0.267608\tvalid_1's l1: 0.336283\n",
      "[1700]\ttraining's l1: 0.262049\tvalid_1's l1: 0.333194\n",
      "[1800]\ttraining's l1: 0.256765\tvalid_1's l1: 0.330318\n",
      "[1900]\ttraining's l1: 0.251753\tvalid_1's l1: 0.327565\n",
      "[2000]\ttraining's l1: 0.247046\tvalid_1's l1: 0.325045\n",
      "[2100]\ttraining's l1: 0.242612\tvalid_1's l1: 0.322586\n",
      "[2200]\ttraining's l1: 0.238309\tvalid_1's l1: 0.320404\n",
      "[2300]\ttraining's l1: 0.234266\tvalid_1's l1: 0.318369\n",
      "[2400]\ttraining's l1: 0.230293\tvalid_1's l1: 0.316389\n",
      "[2500]\ttraining's l1: 0.226481\tvalid_1's l1: 0.314434\n",
      "[2600]\ttraining's l1: 0.222822\tvalid_1's l1: 0.312651\n",
      "[2700]\ttraining's l1: 0.219346\tvalid_1's l1: 0.310924\n",
      "[2800]\ttraining's l1: 0.215988\tvalid_1's l1: 0.309357\n",
      "[2900]\ttraining's l1: 0.212761\tvalid_1's l1: 0.307858\n",
      "[3000]\ttraining's l1: 0.209604\tvalid_1's l1: 0.306418\n",
      "[3100]\ttraining's l1: 0.206623\tvalid_1's l1: 0.305043\n",
      "[3200]\ttraining's l1: 0.203662\tvalid_1's l1: 0.303789\n",
      "[3300]\ttraining's l1: 0.200811\tvalid_1's l1: 0.302474\n",
      "[3400]\ttraining's l1: 0.198067\tvalid_1's l1: 0.301305\n",
      "[3500]\ttraining's l1: 0.195315\tvalid_1's l1: 0.300091\n",
      "[3600]\ttraining's l1: 0.1927\tvalid_1's l1: 0.298967\n",
      "[3700]\ttraining's l1: 0.190145\tvalid_1's l1: 0.297915\n",
      "[3800]\ttraining's l1: 0.187667\tvalid_1's l1: 0.296825\n",
      "[3900]\ttraining's l1: 0.185298\tvalid_1's l1: 0.295889\n",
      "[4000]\ttraining's l1: 0.182956\tvalid_1's l1: 0.294922\n",
      "[4100]\ttraining's l1: 0.180701\tvalid_1's l1: 0.294042\n",
      "[4200]\ttraining's l1: 0.178452\tvalid_1's l1: 0.293123\n",
      "[4300]\ttraining's l1: 0.176302\tvalid_1's l1: 0.29227\n",
      "[4400]\ttraining's l1: 0.174212\tvalid_1's l1: 0.291423\n",
      "[4500]\ttraining's l1: 0.172176\tvalid_1's l1: 0.290637\n",
      "[4600]\ttraining's l1: 0.170182\tvalid_1's l1: 0.289869\n",
      "[4700]\ttraining's l1: 0.168248\tvalid_1's l1: 0.289185\n",
      "[4800]\ttraining's l1: 0.166368\tvalid_1's l1: 0.288495\n",
      "[4900]\ttraining's l1: 0.164483\tvalid_1's l1: 0.287795\n",
      "[5000]\ttraining's l1: 0.162651\tvalid_1's l1: 0.287056\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.162651\tvalid_1's l1: 0.287056\n",
      "3JHC Fold 0, logMAE: -1.248076790704558\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.55589\tvalid_1's l1: 0.567759\n",
      "[200]\ttraining's l1: 0.470976\tvalid_1's l1: 0.48939\n",
      "[300]\ttraining's l1: 0.428886\tvalid_1's l1: 0.452806\n",
      "[400]\ttraining's l1: 0.399867\tvalid_1's l1: 0.428585\n",
      "[500]\ttraining's l1: 0.37783\tvalid_1's l1: 0.411081\n",
      "[600]\ttraining's l1: 0.3598\tvalid_1's l1: 0.397055\n",
      "[700]\ttraining's l1: 0.345295\tvalid_1's l1: 0.386318\n",
      "[800]\ttraining's l1: 0.332783\tvalid_1's l1: 0.377302\n",
      "[900]\ttraining's l1: 0.321503\tvalid_1's l1: 0.369364\n",
      "[1000]\ttraining's l1: 0.311757\tvalid_1's l1: 0.362922\n",
      "[1100]\ttraining's l1: 0.30268\tvalid_1's l1: 0.356992\n",
      "[1200]\ttraining's l1: 0.294585\tvalid_1's l1: 0.351756\n",
      "[1300]\ttraining's l1: 0.287114\tvalid_1's l1: 0.347128\n",
      "[1400]\ttraining's l1: 0.280123\tvalid_1's l1: 0.342784\n",
      "[1500]\ttraining's l1: 0.273817\tvalid_1's l1: 0.33889\n",
      "[1600]\ttraining's l1: 0.267803\tvalid_1's l1: 0.335371\n",
      "[1700]\ttraining's l1: 0.262069\tvalid_1's l1: 0.332129\n",
      "[1800]\ttraining's l1: 0.256721\tvalid_1's l1: 0.329188\n",
      "[1900]\ttraining's l1: 0.251798\tvalid_1's l1: 0.326538\n",
      "[2000]\ttraining's l1: 0.247049\tvalid_1's l1: 0.323968\n",
      "[2100]\ttraining's l1: 0.24255\tvalid_1's l1: 0.321564\n",
      "[2200]\ttraining's l1: 0.23819\tvalid_1's l1: 0.319239\n",
      "[2300]\ttraining's l1: 0.233996\tvalid_1's l1: 0.317204\n",
      "[2400]\ttraining's l1: 0.230033\tvalid_1's l1: 0.315287\n",
      "[2500]\ttraining's l1: 0.226182\tvalid_1's l1: 0.313398\n",
      "[2600]\ttraining's l1: 0.222582\tvalid_1's l1: 0.311666\n",
      "[2700]\ttraining's l1: 0.219128\tvalid_1's l1: 0.310016\n",
      "[2800]\ttraining's l1: 0.215722\tvalid_1's l1: 0.308447\n",
      "[2900]\ttraining's l1: 0.212451\tvalid_1's l1: 0.306931\n",
      "[3000]\ttraining's l1: 0.209294\tvalid_1's l1: 0.305515\n",
      "[3100]\ttraining's l1: 0.206235\tvalid_1's l1: 0.304118\n",
      "[3200]\ttraining's l1: 0.203288\tvalid_1's l1: 0.302817\n",
      "[3300]\ttraining's l1: 0.2004\tvalid_1's l1: 0.301498\n",
      "[3400]\ttraining's l1: 0.197723\tvalid_1's l1: 0.300296\n",
      "[3500]\ttraining's l1: 0.195058\tvalid_1's l1: 0.299138\n",
      "[3600]\ttraining's l1: 0.1925\tvalid_1's l1: 0.298065\n",
      "[3700]\ttraining's l1: 0.189961\tvalid_1's l1: 0.296913\n",
      "[3800]\ttraining's l1: 0.187549\tvalid_1's l1: 0.29596\n",
      "[3900]\ttraining's l1: 0.185205\tvalid_1's l1: 0.295024\n",
      "[4000]\ttraining's l1: 0.182925\tvalid_1's l1: 0.294155\n",
      "[4100]\ttraining's l1: 0.180633\tvalid_1's l1: 0.293233\n",
      "[4200]\ttraining's l1: 0.178414\tvalid_1's l1: 0.292328\n",
      "[4300]\ttraining's l1: 0.176317\tvalid_1's l1: 0.291503\n",
      "[4400]\ttraining's l1: 0.17419\tvalid_1's l1: 0.2907\n",
      "[4500]\ttraining's l1: 0.172117\tvalid_1's l1: 0.289901\n",
      "[4600]\ttraining's l1: 0.170135\tvalid_1's l1: 0.289088\n",
      "[4700]\ttraining's l1: 0.16815\tvalid_1's l1: 0.288311\n",
      "[4800]\ttraining's l1: 0.166202\tvalid_1's l1: 0.28759\n",
      "[4900]\ttraining's l1: 0.164289\tvalid_1's l1: 0.286877\n",
      "[5000]\ttraining's l1: 0.162453\tvalid_1's l1: 0.286204\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.162453\tvalid_1's l1: 0.286204\n",
      "3JHC Fold 1, logMAE: -1.2510512260203606\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's l1: 0.553213\tvalid_1's l1: 0.563603\n",
      "[200]\ttraining's l1: 0.472596\tvalid_1's l1: 0.490007\n",
      "[300]\ttraining's l1: 0.429747\tvalid_1's l1: 0.452807\n",
      "[400]\ttraining's l1: 0.400523\tvalid_1's l1: 0.428762\n",
      "[500]\ttraining's l1: 0.377658\tvalid_1's l1: 0.410359\n",
      "[600]\ttraining's l1: 0.360318\tvalid_1's l1: 0.3971\n",
      "[700]\ttraining's l1: 0.344906\tvalid_1's l1: 0.385462\n",
      "[800]\ttraining's l1: 0.332548\tvalid_1's l1: 0.376633\n",
      "[900]\ttraining's l1: 0.321365\tvalid_1's l1: 0.369049\n",
      "[1000]\ttraining's l1: 0.311727\tvalid_1's l1: 0.362512\n",
      "[1100]\ttraining's l1: 0.302845\tvalid_1's l1: 0.356708\n",
      "[1200]\ttraining's l1: 0.294799\tvalid_1's l1: 0.351472\n",
      "[1300]\ttraining's l1: 0.287153\tvalid_1's l1: 0.346696\n",
      "[1400]\ttraining's l1: 0.280236\tvalid_1's l1: 0.342514\n",
      "[1500]\ttraining's l1: 0.273792\tvalid_1's l1: 0.338801\n",
      "[1600]\ttraining's l1: 0.267702\tvalid_1's l1: 0.335302\n",
      "[1700]\ttraining's l1: 0.262029\tvalid_1's l1: 0.332144\n",
      "[1800]\ttraining's l1: 0.256733\tvalid_1's l1: 0.329092\n",
      "[1900]\ttraining's l1: 0.251794\tvalid_1's l1: 0.326337\n",
      "[2000]\ttraining's l1: 0.246984\tvalid_1's l1: 0.323786\n",
      "[2100]\ttraining's l1: 0.242351\tvalid_1's l1: 0.321284\n",
      "[2200]\ttraining's l1: 0.238089\tvalid_1's l1: 0.319121\n",
      "[2300]\ttraining's l1: 0.233946\tvalid_1's l1: 0.316948\n",
      "[2400]\ttraining's l1: 0.229966\tvalid_1's l1: 0.314988\n",
      "[2500]\ttraining's l1: 0.226207\tvalid_1's l1: 0.313075\n",
      "[2600]\ttraining's l1: 0.22255\tvalid_1's l1: 0.311202\n",
      "[2700]\ttraining's l1: 0.219034\tvalid_1's l1: 0.309475\n",
      "[2800]\ttraining's l1: 0.215622\tvalid_1's l1: 0.307797\n",
      "[2900]\ttraining's l1: 0.212381\tvalid_1's l1: 0.30635\n",
      "[3000]\ttraining's l1: 0.209267\tvalid_1's l1: 0.304939\n",
      "[3100]\ttraining's l1: 0.206266\tvalid_1's l1: 0.303535\n",
      "[3200]\ttraining's l1: 0.20335\tvalid_1's l1: 0.302231\n",
      "[3300]\ttraining's l1: 0.200471\tvalid_1's l1: 0.300935\n",
      "[3400]\ttraining's l1: 0.197707\tvalid_1's l1: 0.299759\n",
      "[3500]\ttraining's l1: 0.195062\tvalid_1's l1: 0.29867\n",
      "[3600]\ttraining's l1: 0.192522\tvalid_1's l1: 0.297566\n",
      "[3700]\ttraining's l1: 0.189985\tvalid_1's l1: 0.296396\n",
      "[3800]\ttraining's l1: 0.187486\tvalid_1's l1: 0.295386\n",
      "[3900]\ttraining's l1: 0.185106\tvalid_1's l1: 0.294444\n",
      "[4000]\ttraining's l1: 0.18279\tvalid_1's l1: 0.293557\n",
      "[4100]\ttraining's l1: 0.180489\tvalid_1's l1: 0.292655\n",
      "[4200]\ttraining's l1: 0.178252\tvalid_1's l1: 0.291789\n",
      "[4300]\ttraining's l1: 0.176137\tvalid_1's l1: 0.290979\n",
      "[4400]\ttraining's l1: 0.174026\tvalid_1's l1: 0.290138\n",
      "[4500]\ttraining's l1: 0.171959\tvalid_1's l1: 0.289357\n",
      "[4600]\ttraining's l1: 0.169967\tvalid_1's l1: 0.288606\n",
      "[4700]\ttraining's l1: 0.168033\tvalid_1's l1: 0.287891\n",
      "[4800]\ttraining's l1: 0.166104\tvalid_1's l1: 0.28723\n",
      "[4900]\ttraining's l1: 0.164254\tvalid_1's l1: 0.286555\n",
      "[5000]\ttraining's l1: 0.16244\tvalid_1's l1: 0.285868\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.16244\tvalid_1's l1: 0.285868\n",
      "3JHC Fold 2, logMAE: -1.252224106198485\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.552012\tvalid_1's l1: 0.562332\n",
      "[200]\ttraining's l1: 0.471638\tvalid_1's l1: 0.489045\n",
      "[300]\ttraining's l1: 0.429488\tvalid_1's l1: 0.453255\n",
      "[400]\ttraining's l1: 0.400024\tvalid_1's l1: 0.429078\n",
      "[500]\ttraining's l1: 0.377672\tvalid_1's l1: 0.411353\n",
      "[600]\ttraining's l1: 0.360196\tvalid_1's l1: 0.398055\n",
      "[700]\ttraining's l1: 0.345367\tvalid_1's l1: 0.387204\n",
      "[800]\ttraining's l1: 0.33277\tvalid_1's l1: 0.378219\n",
      "[900]\ttraining's l1: 0.321578\tvalid_1's l1: 0.370352\n",
      "[1000]\ttraining's l1: 0.311872\tvalid_1's l1: 0.363849\n",
      "[1100]\ttraining's l1: 0.302817\tvalid_1's l1: 0.35771\n",
      "[1200]\ttraining's l1: 0.29461\tvalid_1's l1: 0.352481\n",
      "[1300]\ttraining's l1: 0.287168\tvalid_1's l1: 0.347798\n",
      "[1400]\ttraining's l1: 0.280193\tvalid_1's l1: 0.343581\n",
      "[1500]\ttraining's l1: 0.273865\tvalid_1's l1: 0.339939\n",
      "[1600]\ttraining's l1: 0.267876\tvalid_1's l1: 0.336475\n",
      "[1700]\ttraining's l1: 0.26233\tvalid_1's l1: 0.333398\n",
      "[1800]\ttraining's l1: 0.257102\tvalid_1's l1: 0.330479\n",
      "[1900]\ttraining's l1: 0.252113\tvalid_1's l1: 0.327733\n",
      "[2000]\ttraining's l1: 0.247478\tvalid_1's l1: 0.325277\n",
      "[2100]\ttraining's l1: 0.242972\tvalid_1's l1: 0.32288\n",
      "[2200]\ttraining's l1: 0.238603\tvalid_1's l1: 0.320628\n",
      "[2300]\ttraining's l1: 0.234432\tvalid_1's l1: 0.318534\n",
      "[2400]\ttraining's l1: 0.230493\tvalid_1's l1: 0.316573\n",
      "[2500]\ttraining's l1: 0.226562\tvalid_1's l1: 0.314609\n",
      "[2600]\ttraining's l1: 0.223071\tvalid_1's l1: 0.312946\n",
      "[2700]\ttraining's l1: 0.219625\tvalid_1's l1: 0.3113\n",
      "[2800]\ttraining's l1: 0.216256\tvalid_1's l1: 0.309706\n",
      "[2900]\ttraining's l1: 0.21302\tvalid_1's l1: 0.308182\n",
      "[3000]\ttraining's l1: 0.209827\tvalid_1's l1: 0.306737\n",
      "[3100]\ttraining's l1: 0.206808\tvalid_1's l1: 0.305346\n",
      "[3200]\ttraining's l1: 0.203822\tvalid_1's l1: 0.303951\n",
      "[3300]\ttraining's l1: 0.201019\tvalid_1's l1: 0.302721\n",
      "[3400]\ttraining's l1: 0.198227\tvalid_1's l1: 0.301497\n",
      "[3500]\ttraining's l1: 0.195511\tvalid_1's l1: 0.300307\n",
      "[3600]\ttraining's l1: 0.192885\tvalid_1's l1: 0.29918\n",
      "[3700]\ttraining's l1: 0.190388\tvalid_1's l1: 0.298174\n",
      "[3800]\ttraining's l1: 0.187919\tvalid_1's l1: 0.297083\n",
      "[3900]\ttraining's l1: 0.185535\tvalid_1's l1: 0.296163\n",
      "[4000]\ttraining's l1: 0.183164\tvalid_1's l1: 0.295209\n",
      "[4100]\ttraining's l1: 0.180875\tvalid_1's l1: 0.294281\n",
      "[4200]\ttraining's l1: 0.178634\tvalid_1's l1: 0.293327\n",
      "[4300]\ttraining's l1: 0.176468\tvalid_1's l1: 0.292444\n",
      "[4400]\ttraining's l1: 0.17431\tvalid_1's l1: 0.291579\n",
      "[4500]\ttraining's l1: 0.172255\tvalid_1's l1: 0.290805\n",
      "[4600]\ttraining's l1: 0.170239\tvalid_1's l1: 0.290076\n",
      "[4700]\ttraining's l1: 0.168284\tvalid_1's l1: 0.289307\n",
      "[4800]\ttraining's l1: 0.166359\tvalid_1's l1: 0.288554\n",
      "[4900]\ttraining's l1: 0.164456\tvalid_1's l1: 0.287819\n",
      "[5000]\ttraining's l1: 0.162632\tvalid_1's l1: 0.287135\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.162632\tvalid_1's l1: 0.287135\n",
      "3JHC Fold 3, logMAE: -1.2478038122631787\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.550588\tvalid_1's l1: 0.563457\n",
      "[200]\ttraining's l1: 0.469196\tvalid_1's l1: 0.488695\n",
      "[300]\ttraining's l1: 0.42572\tvalid_1's l1: 0.450701\n",
      "[400]\ttraining's l1: 0.396804\tvalid_1's l1: 0.426497\n",
      "[500]\ttraining's l1: 0.375214\tvalid_1's l1: 0.409284\n",
      "[600]\ttraining's l1: 0.357793\tvalid_1's l1: 0.396046\n",
      "[700]\ttraining's l1: 0.343046\tvalid_1's l1: 0.385144\n",
      "[800]\ttraining's l1: 0.330614\tvalid_1's l1: 0.376192\n",
      "[900]\ttraining's l1: 0.319682\tvalid_1's l1: 0.368685\n",
      "[1000]\ttraining's l1: 0.309849\tvalid_1's l1: 0.361956\n",
      "[1100]\ttraining's l1: 0.301208\tvalid_1's l1: 0.356173\n",
      "[1200]\ttraining's l1: 0.293097\tvalid_1's l1: 0.350916\n",
      "[1300]\ttraining's l1: 0.285658\tvalid_1's l1: 0.346147\n",
      "[1400]\ttraining's l1: 0.278844\tvalid_1's l1: 0.34198\n",
      "[1500]\ttraining's l1: 0.272373\tvalid_1's l1: 0.338165\n",
      "[1600]\ttraining's l1: 0.266357\tvalid_1's l1: 0.334609\n",
      "[1700]\ttraining's l1: 0.26078\tvalid_1's l1: 0.331315\n",
      "[1800]\ttraining's l1: 0.255604\tvalid_1's l1: 0.32843\n",
      "[1900]\ttraining's l1: 0.250562\tvalid_1's l1: 0.325695\n",
      "[2000]\ttraining's l1: 0.245876\tvalid_1's l1: 0.323256\n",
      "[2100]\ttraining's l1: 0.241396\tvalid_1's l1: 0.320814\n",
      "[2200]\ttraining's l1: 0.237076\tvalid_1's l1: 0.318552\n",
      "[2300]\ttraining's l1: 0.232921\tvalid_1's l1: 0.316436\n",
      "[2400]\ttraining's l1: 0.229026\tvalid_1's l1: 0.314458\n",
      "[2500]\ttraining's l1: 0.2252\tvalid_1's l1: 0.312559\n",
      "[2600]\ttraining's l1: 0.221646\tvalid_1's l1: 0.310883\n",
      "[2700]\ttraining's l1: 0.218234\tvalid_1's l1: 0.309321\n",
      "[2800]\ttraining's l1: 0.214961\tvalid_1's l1: 0.30773\n",
      "[2900]\ttraining's l1: 0.21172\tvalid_1's l1: 0.30624\n",
      "[3000]\ttraining's l1: 0.20856\tvalid_1's l1: 0.304747\n",
      "[3100]\ttraining's l1: 0.205515\tvalid_1's l1: 0.303283\n",
      "[3200]\ttraining's l1: 0.202616\tvalid_1's l1: 0.301894\n",
      "[3300]\ttraining's l1: 0.199758\tvalid_1's l1: 0.300682\n",
      "[3400]\ttraining's l1: 0.197059\tvalid_1's l1: 0.299533\n",
      "[3500]\ttraining's l1: 0.194427\tvalid_1's l1: 0.298372\n",
      "[3600]\ttraining's l1: 0.191784\tvalid_1's l1: 0.297241\n",
      "[3700]\ttraining's l1: 0.1893\tvalid_1's l1: 0.296223\n",
      "[3800]\ttraining's l1: 0.186815\tvalid_1's l1: 0.295178\n",
      "[3900]\ttraining's l1: 0.18443\tvalid_1's l1: 0.294198\n",
      "[4000]\ttraining's l1: 0.18208\tvalid_1's l1: 0.293238\n",
      "[4100]\ttraining's l1: 0.179783\tvalid_1's l1: 0.292322\n",
      "[4200]\ttraining's l1: 0.177613\tvalid_1's l1: 0.29145\n",
      "[4300]\ttraining's l1: 0.175447\tvalid_1's l1: 0.290574\n",
      "[4400]\ttraining's l1: 0.17334\tvalid_1's l1: 0.289753\n",
      "[4500]\ttraining's l1: 0.171262\tvalid_1's l1: 0.288924\n",
      "[4600]\ttraining's l1: 0.169284\tvalid_1's l1: 0.288144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4700]\ttraining's l1: 0.16733\tvalid_1's l1: 0.287373\n",
      "[4800]\ttraining's l1: 0.165408\tvalid_1's l1: 0.286639\n",
      "[4900]\ttraining's l1: 0.163514\tvalid_1's l1: 0.285949\n",
      "[5000]\ttraining's l1: 0.161663\tvalid_1's l1: 0.285285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.161663\tvalid_1's l1: 0.285285\n",
      "3JHC Fold 4, logMAE: -1.2542663573183155\n",
      "*** Training Model for 3JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.151929\tvalid_1's l1: 0.174543\n",
      "[200]\ttraining's l1: 0.121337\tvalid_1's l1: 0.152625\n",
      "[300]\ttraining's l1: 0.104198\tvalid_1's l1: 0.142135\n",
      "[400]\ttraining's l1: 0.0923639\tvalid_1's l1: 0.135647\n",
      "[500]\ttraining's l1: 0.0835492\tvalid_1's l1: 0.1313\n",
      "[600]\ttraining's l1: 0.0761152\tvalid_1's l1: 0.12784\n",
      "[700]\ttraining's l1: 0.070359\tvalid_1's l1: 0.125531\n",
      "[800]\ttraining's l1: 0.0653813\tvalid_1's l1: 0.123403\n",
      "[900]\ttraining's l1: 0.0610364\tvalid_1's l1: 0.121704\n",
      "[1000]\ttraining's l1: 0.0571154\tvalid_1's l1: 0.120165\n",
      "[1100]\ttraining's l1: 0.053632\tvalid_1's l1: 0.118834\n",
      "[1200]\ttraining's l1: 0.0504255\tvalid_1's l1: 0.117655\n",
      "[1300]\ttraining's l1: 0.0475085\tvalid_1's l1: 0.116661\n",
      "[1400]\ttraining's l1: 0.0448523\tvalid_1's l1: 0.115756\n",
      "[1500]\ttraining's l1: 0.0423459\tvalid_1's l1: 0.114977\n",
      "[1600]\ttraining's l1: 0.0402283\tvalid_1's l1: 0.114373\n",
      "[1700]\ttraining's l1: 0.0382544\tvalid_1's l1: 0.113799\n",
      "[1800]\ttraining's l1: 0.0363378\tvalid_1's l1: 0.113267\n",
      "[1900]\ttraining's l1: 0.0345996\tvalid_1's l1: 0.112805\n",
      "[2000]\ttraining's l1: 0.0330218\tvalid_1's l1: 0.11235\n",
      "[2100]\ttraining's l1: 0.0315652\tvalid_1's l1: 0.111933\n",
      "[2200]\ttraining's l1: 0.0302357\tvalid_1's l1: 0.111594\n",
      "[2300]\ttraining's l1: 0.0290395\tvalid_1's l1: 0.111302\n",
      "[2400]\ttraining's l1: 0.0278549\tvalid_1's l1: 0.111013\n",
      "[2500]\ttraining's l1: 0.026707\tvalid_1's l1: 0.110725\n",
      "[2600]\ttraining's l1: 0.0256513\tvalid_1's l1: 0.110482\n",
      "[2700]\ttraining's l1: 0.0246545\tvalid_1's l1: 0.110247\n",
      "[2800]\ttraining's l1: 0.0236939\tvalid_1's l1: 0.110038\n",
      "[2900]\ttraining's l1: 0.0228322\tvalid_1's l1: 0.10983\n",
      "[3000]\ttraining's l1: 0.0220019\tvalid_1's l1: 0.109636\n",
      "[3100]\ttraining's l1: 0.0212059\tvalid_1's l1: 0.109454\n",
      "[3200]\ttraining's l1: 0.0204596\tvalid_1's l1: 0.109283\n",
      "[3300]\ttraining's l1: 0.0197419\tvalid_1's l1: 0.109121\n",
      "[3400]\ttraining's l1: 0.0190927\tvalid_1's l1: 0.108966\n",
      "[3500]\ttraining's l1: 0.0184803\tvalid_1's l1: 0.108842\n",
      "[3600]\ttraining's l1: 0.0178929\tvalid_1's l1: 0.108724\n",
      "[3700]\ttraining's l1: 0.0173227\tvalid_1's l1: 0.108611\n",
      "[3800]\ttraining's l1: 0.0167943\tvalid_1's l1: 0.108491\n",
      "[3900]\ttraining's l1: 0.0162871\tvalid_1's l1: 0.108401\n",
      "[4000]\ttraining's l1: 0.0158173\tvalid_1's l1: 0.108296\n",
      "[4100]\ttraining's l1: 0.0153696\tvalid_1's l1: 0.108203\n",
      "[4200]\ttraining's l1: 0.0149342\tvalid_1's l1: 0.10813\n",
      "[4300]\ttraining's l1: 0.0145069\tvalid_1's l1: 0.108031\n",
      "[4400]\ttraining's l1: 0.0141091\tvalid_1's l1: 0.107953\n",
      "[4500]\ttraining's l1: 0.013727\tvalid_1's l1: 0.107874\n",
      "[4600]\ttraining's l1: 0.0133674\tvalid_1's l1: 0.107818\n",
      "[4700]\ttraining's l1: 0.0130223\tvalid_1's l1: 0.107758\n",
      "[4800]\ttraining's l1: 0.012688\tvalid_1's l1: 0.107693\n",
      "[4900]\ttraining's l1: 0.0123813\tvalid_1's l1: 0.107626\n",
      "[5000]\ttraining's l1: 0.0120821\tvalid_1's l1: 0.10758\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0120821\tvalid_1's l1: 0.10758\n",
      "3JHN Fold 0, logMAE: -2.2295179763973922\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.15221\tvalid_1's l1: 0.171628\n",
      "[200]\ttraining's l1: 0.120532\tvalid_1's l1: 0.149404\n",
      "[300]\ttraining's l1: 0.103942\tvalid_1's l1: 0.139494\n",
      "[400]\ttraining's l1: 0.0923787\tvalid_1's l1: 0.133448\n",
      "[500]\ttraining's l1: 0.0836509\tvalid_1's l1: 0.12917\n",
      "[600]\ttraining's l1: 0.0765042\tvalid_1's l1: 0.12601\n",
      "[700]\ttraining's l1: 0.0705763\tvalid_1's l1: 0.123558\n",
      "[800]\ttraining's l1: 0.0657071\tvalid_1's l1: 0.121589\n",
      "[900]\ttraining's l1: 0.061137\tvalid_1's l1: 0.119803\n",
      "[1000]\ttraining's l1: 0.0572738\tvalid_1's l1: 0.118346\n",
      "[1100]\ttraining's l1: 0.0537096\tvalid_1's l1: 0.117088\n",
      "[1200]\ttraining's l1: 0.050421\tvalid_1's l1: 0.115889\n",
      "[1300]\ttraining's l1: 0.0475472\tvalid_1's l1: 0.11493\n",
      "[1400]\ttraining's l1: 0.0448976\tvalid_1's l1: 0.114054\n",
      "[1500]\ttraining's l1: 0.042504\tvalid_1's l1: 0.11329\n",
      "[1600]\ttraining's l1: 0.040354\tvalid_1's l1: 0.112679\n",
      "[1700]\ttraining's l1: 0.0383388\tvalid_1's l1: 0.112078\n",
      "[1800]\ttraining's l1: 0.0365418\tvalid_1's l1: 0.111531\n",
      "[1900]\ttraining's l1: 0.0348059\tvalid_1's l1: 0.111015\n",
      "[2000]\ttraining's l1: 0.0331779\tvalid_1's l1: 0.110571\n",
      "[2100]\ttraining's l1: 0.0316906\tvalid_1's l1: 0.110163\n",
      "[2200]\ttraining's l1: 0.030289\tvalid_1's l1: 0.109822\n",
      "[2300]\ttraining's l1: 0.0290326\tvalid_1's l1: 0.109514\n",
      "[2400]\ttraining's l1: 0.0278227\tvalid_1's l1: 0.109221\n",
      "[2500]\ttraining's l1: 0.0266891\tvalid_1's l1: 0.108964\n",
      "[2600]\ttraining's l1: 0.0256581\tvalid_1's l1: 0.108707\n",
      "[2700]\ttraining's l1: 0.0246896\tvalid_1's l1: 0.108489\n",
      "[2800]\ttraining's l1: 0.0237653\tvalid_1's l1: 0.108277\n",
      "[2900]\ttraining's l1: 0.0228862\tvalid_1's l1: 0.10808\n",
      "[3000]\ttraining's l1: 0.0220515\tvalid_1's l1: 0.107868\n",
      "[3100]\ttraining's l1: 0.0212866\tvalid_1's l1: 0.107688\n",
      "[3200]\ttraining's l1: 0.0205235\tvalid_1's l1: 0.10753\n",
      "[3300]\ttraining's l1: 0.0198409\tvalid_1's l1: 0.107358\n",
      "[3400]\ttraining's l1: 0.0191853\tvalid_1's l1: 0.107245\n",
      "[3500]\ttraining's l1: 0.0185794\tvalid_1's l1: 0.107099\n",
      "[3600]\ttraining's l1: 0.0179988\tvalid_1's l1: 0.106968\n",
      "[3700]\ttraining's l1: 0.017434\tvalid_1's l1: 0.10684\n",
      "[3800]\ttraining's l1: 0.0169056\tvalid_1's l1: 0.106749\n",
      "[3900]\ttraining's l1: 0.0164013\tvalid_1's l1: 0.106637\n",
      "[4000]\ttraining's l1: 0.01591\tvalid_1's l1: 0.106517\n",
      "[4100]\ttraining's l1: 0.015464\tvalid_1's l1: 0.106429\n",
      "[4200]\ttraining's l1: 0.0150327\tvalid_1's l1: 0.106351\n",
      "[4300]\ttraining's l1: 0.0146236\tvalid_1's l1: 0.106273\n",
      "[4400]\ttraining's l1: 0.0142218\tvalid_1's l1: 0.106201\n",
      "[4500]\ttraining's l1: 0.0138532\tvalid_1's l1: 0.106132\n",
      "[4600]\ttraining's l1: 0.013498\tvalid_1's l1: 0.106062\n",
      "[4700]\ttraining's l1: 0.0131558\tvalid_1's l1: 0.105993\n",
      "[4800]\ttraining's l1: 0.0128322\tvalid_1's l1: 0.105922\n",
      "[4900]\ttraining's l1: 0.0125194\tvalid_1's l1: 0.105858\n",
      "[5000]\ttraining's l1: 0.0122236\tvalid_1's l1: 0.105799\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0122236\tvalid_1's l1: 0.105799\n",
      "3JHN Fold 1, logMAE: -2.2462126911910745\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.15062\tvalid_1's l1: 0.172499\n",
      "[200]\ttraining's l1: 0.11949\tvalid_1's l1: 0.150921\n",
      "[300]\ttraining's l1: 0.102811\tvalid_1's l1: 0.141496\n",
      "[400]\ttraining's l1: 0.0911121\tvalid_1's l1: 0.13552\n",
      "[500]\ttraining's l1: 0.0825231\tvalid_1's l1: 0.131276\n",
      "[600]\ttraining's l1: 0.0755034\tvalid_1's l1: 0.12814\n",
      "[700]\ttraining's l1: 0.0696416\tvalid_1's l1: 0.125538\n",
      "[800]\ttraining's l1: 0.0646652\tvalid_1's l1: 0.123496\n",
      "[900]\ttraining's l1: 0.0605551\tvalid_1's l1: 0.121969\n",
      "[1000]\ttraining's l1: 0.0567217\tvalid_1's l1: 0.120691\n",
      "[1100]\ttraining's l1: 0.05315\tvalid_1's l1: 0.119515\n",
      "[1200]\ttraining's l1: 0.0499871\tvalid_1's l1: 0.118476\n",
      "[1300]\ttraining's l1: 0.0470801\tvalid_1's l1: 0.117456\n",
      "[1400]\ttraining's l1: 0.0445834\tvalid_1's l1: 0.116678\n",
      "[1500]\ttraining's l1: 0.0422282\tvalid_1's l1: 0.115862\n",
      "[1600]\ttraining's l1: 0.0401601\tvalid_1's l1: 0.115241\n",
      "[1700]\ttraining's l1: 0.0381105\tvalid_1's l1: 0.114567\n",
      "[1800]\ttraining's l1: 0.0362724\tvalid_1's l1: 0.114045\n",
      "[1900]\ttraining's l1: 0.0346446\tvalid_1's l1: 0.113548\n",
      "[2000]\ttraining's l1: 0.0330307\tvalid_1's l1: 0.113136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\ttraining's l1: 0.0315993\tvalid_1's l1: 0.112737\n",
      "[2200]\ttraining's l1: 0.0302043\tvalid_1's l1: 0.112379\n",
      "[2300]\ttraining's l1: 0.0289224\tvalid_1's l1: 0.11199\n",
      "[2400]\ttraining's l1: 0.0277592\tvalid_1's l1: 0.111709\n",
      "[2500]\ttraining's l1: 0.0266605\tvalid_1's l1: 0.111479\n",
      "[2600]\ttraining's l1: 0.0256072\tvalid_1's l1: 0.111183\n",
      "[2700]\ttraining's l1: 0.0246408\tvalid_1's l1: 0.110963\n",
      "[2800]\ttraining's l1: 0.0236961\tvalid_1's l1: 0.110715\n",
      "[2900]\ttraining's l1: 0.0228299\tvalid_1's l1: 0.110498\n",
      "[3000]\ttraining's l1: 0.0220133\tvalid_1's l1: 0.110276\n",
      "[3100]\ttraining's l1: 0.0212234\tvalid_1's l1: 0.110104\n",
      "[3200]\ttraining's l1: 0.0204943\tvalid_1's l1: 0.109938\n",
      "[3300]\ttraining's l1: 0.0198098\tvalid_1's l1: 0.109783\n",
      "[3400]\ttraining's l1: 0.019158\tvalid_1's l1: 0.10963\n",
      "[3500]\ttraining's l1: 0.018543\tvalid_1's l1: 0.109511\n",
      "[3600]\ttraining's l1: 0.0179399\tvalid_1's l1: 0.109391\n",
      "[3700]\ttraining's l1: 0.017377\tvalid_1's l1: 0.109257\n",
      "[3800]\ttraining's l1: 0.0168456\tvalid_1's l1: 0.109162\n",
      "[3900]\ttraining's l1: 0.0163384\tvalid_1's l1: 0.109049\n",
      "[4000]\ttraining's l1: 0.015848\tvalid_1's l1: 0.108955\n",
      "[4100]\ttraining's l1: 0.0153925\tvalid_1's l1: 0.108859\n",
      "[4200]\ttraining's l1: 0.0149546\tvalid_1's l1: 0.108782\n",
      "[4300]\ttraining's l1: 0.0145417\tvalid_1's l1: 0.1087\n",
      "[4400]\ttraining's l1: 0.0141483\tvalid_1's l1: 0.108628\n",
      "[4500]\ttraining's l1: 0.0137689\tvalid_1's l1: 0.108547\n",
      "[4600]\ttraining's l1: 0.0134187\tvalid_1's l1: 0.1085\n",
      "[4700]\ttraining's l1: 0.0130751\tvalid_1's l1: 0.108428\n",
      "[4800]\ttraining's l1: 0.012744\tvalid_1's l1: 0.108355\n",
      "[4900]\ttraining's l1: 0.0124363\tvalid_1's l1: 0.108297\n",
      "[5000]\ttraining's l1: 0.0121421\tvalid_1's l1: 0.108233\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0121421\tvalid_1's l1: 0.108233\n",
      "3JHN Fold 2, logMAE: -2.2234679109544806\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.151454\tvalid_1's l1: 0.173516\n",
      "[200]\ttraining's l1: 0.120317\tvalid_1's l1: 0.152028\n",
      "[300]\ttraining's l1: 0.103656\tvalid_1's l1: 0.142381\n",
      "[400]\ttraining's l1: 0.091662\tvalid_1's l1: 0.135789\n",
      "[500]\ttraining's l1: 0.0827899\tvalid_1's l1: 0.131427\n",
      "[600]\ttraining's l1: 0.0756839\tvalid_1's l1: 0.128046\n",
      "[700]\ttraining's l1: 0.0697745\tvalid_1's l1: 0.125671\n",
      "[800]\ttraining's l1: 0.0644363\tvalid_1's l1: 0.123357\n",
      "[900]\ttraining's l1: 0.059953\tvalid_1's l1: 0.121676\n",
      "[1000]\ttraining's l1: 0.0560729\tvalid_1's l1: 0.120219\n",
      "[1100]\ttraining's l1: 0.0527156\tvalid_1's l1: 0.119061\n",
      "[1200]\ttraining's l1: 0.0496161\tvalid_1's l1: 0.117943\n",
      "[1300]\ttraining's l1: 0.0467907\tvalid_1's l1: 0.117077\n",
      "[1400]\ttraining's l1: 0.0442291\tvalid_1's l1: 0.116247\n",
      "[1500]\ttraining's l1: 0.0419185\tvalid_1's l1: 0.115593\n",
      "[1600]\ttraining's l1: 0.0398307\tvalid_1's l1: 0.114966\n",
      "[1700]\ttraining's l1: 0.0379317\tvalid_1's l1: 0.114449\n",
      "[1800]\ttraining's l1: 0.036111\tvalid_1's l1: 0.113901\n",
      "[1900]\ttraining's l1: 0.0344129\tvalid_1's l1: 0.113435\n",
      "[2000]\ttraining's l1: 0.0328678\tvalid_1's l1: 0.11298\n",
      "[2100]\ttraining's l1: 0.0314603\tvalid_1's l1: 0.11261\n",
      "[2200]\ttraining's l1: 0.0300976\tvalid_1's l1: 0.112251\n",
      "[2300]\ttraining's l1: 0.0288209\tvalid_1's l1: 0.111942\n",
      "[2400]\ttraining's l1: 0.0276685\tvalid_1's l1: 0.11164\n",
      "[2500]\ttraining's l1: 0.0265277\tvalid_1's l1: 0.11136\n",
      "[2600]\ttraining's l1: 0.0255119\tvalid_1's l1: 0.111072\n",
      "[2700]\ttraining's l1: 0.0245706\tvalid_1's l1: 0.110881\n",
      "[2800]\ttraining's l1: 0.02364\tvalid_1's l1: 0.11065\n",
      "[2900]\ttraining's l1: 0.0227915\tvalid_1's l1: 0.110447\n",
      "[3000]\ttraining's l1: 0.0219884\tvalid_1's l1: 0.110252\n",
      "[3100]\ttraining's l1: 0.0212305\tvalid_1's l1: 0.110087\n",
      "[3200]\ttraining's l1: 0.0204902\tvalid_1's l1: 0.109928\n",
      "[3300]\ttraining's l1: 0.0197927\tvalid_1's l1: 0.109752\n",
      "[3400]\ttraining's l1: 0.0191339\tvalid_1's l1: 0.10962\n",
      "[3500]\ttraining's l1: 0.0185011\tvalid_1's l1: 0.109491\n",
      "[3600]\ttraining's l1: 0.0179116\tvalid_1's l1: 0.109362\n",
      "[3700]\ttraining's l1: 0.0173442\tvalid_1's l1: 0.109242\n",
      "[3800]\ttraining's l1: 0.01683\tvalid_1's l1: 0.109144\n",
      "[3900]\ttraining's l1: 0.0163342\tvalid_1's l1: 0.109055\n",
      "[4000]\ttraining's l1: 0.0158576\tvalid_1's l1: 0.108956\n",
      "[4100]\ttraining's l1: 0.0154004\tvalid_1's l1: 0.108862\n",
      "[4200]\ttraining's l1: 0.0149702\tvalid_1's l1: 0.108778\n",
      "[4300]\ttraining's l1: 0.0145668\tvalid_1's l1: 0.108706\n",
      "[4400]\ttraining's l1: 0.0141681\tvalid_1's l1: 0.108629\n",
      "[4500]\ttraining's l1: 0.0137897\tvalid_1's l1: 0.10855\n",
      "[4600]\ttraining's l1: 0.0134197\tvalid_1's l1: 0.108469\n",
      "[4700]\ttraining's l1: 0.0130749\tvalid_1's l1: 0.108394\n",
      "[4800]\ttraining's l1: 0.012746\tvalid_1's l1: 0.108339\n",
      "[4900]\ttraining's l1: 0.0124392\tvalid_1's l1: 0.108281\n",
      "[5000]\ttraining's l1: 0.0121402\tvalid_1's l1: 0.108216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0121402\tvalid_1's l1: 0.108216\n",
      "3JHN Fold 3, logMAE: -2.2236302798337664\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.150315\tvalid_1's l1: 0.171992\n",
      "[200]\ttraining's l1: 0.120195\tvalid_1's l1: 0.150804\n",
      "[300]\ttraining's l1: 0.103704\tvalid_1's l1: 0.140927\n",
      "[400]\ttraining's l1: 0.0920379\tvalid_1's l1: 0.134777\n",
      "[500]\ttraining's l1: 0.0832837\tvalid_1's l1: 0.130342\n",
      "[600]\ttraining's l1: 0.0758724\tvalid_1's l1: 0.126915\n",
      "[700]\ttraining's l1: 0.0698767\tvalid_1's l1: 0.124333\n",
      "[800]\ttraining's l1: 0.06482\tvalid_1's l1: 0.122264\n",
      "[900]\ttraining's l1: 0.060479\tvalid_1's l1: 0.120591\n",
      "[1000]\ttraining's l1: 0.0566854\tvalid_1's l1: 0.119211\n",
      "[1100]\ttraining's l1: 0.0533231\tvalid_1's l1: 0.117921\n",
      "[1200]\ttraining's l1: 0.0501126\tvalid_1's l1: 0.11685\n",
      "[1300]\ttraining's l1: 0.0473132\tvalid_1's l1: 0.115975\n",
      "[1400]\ttraining's l1: 0.044636\tvalid_1's l1: 0.115091\n",
      "[1500]\ttraining's l1: 0.0422946\tvalid_1's l1: 0.114441\n",
      "[1600]\ttraining's l1: 0.0400862\tvalid_1's l1: 0.113808\n",
      "[1700]\ttraining's l1: 0.0380544\tvalid_1's l1: 0.113196\n",
      "[1800]\ttraining's l1: 0.0362382\tvalid_1's l1: 0.11271\n",
      "[1900]\ttraining's l1: 0.0345943\tvalid_1's l1: 0.112243\n",
      "[2000]\ttraining's l1: 0.0329806\tvalid_1's l1: 0.11182\n",
      "[2100]\ttraining's l1: 0.031555\tvalid_1's l1: 0.111503\n",
      "[2200]\ttraining's l1: 0.0301852\tvalid_1's l1: 0.111117\n",
      "[2300]\ttraining's l1: 0.0289807\tvalid_1's l1: 0.110815\n",
      "[2400]\ttraining's l1: 0.0277999\tvalid_1's l1: 0.110547\n",
      "[2500]\ttraining's l1: 0.0266884\tvalid_1's l1: 0.110246\n",
      "[2600]\ttraining's l1: 0.0256219\tvalid_1's l1: 0.109994\n",
      "[2700]\ttraining's l1: 0.0246316\tvalid_1's l1: 0.109744\n",
      "[2800]\ttraining's l1: 0.0236857\tvalid_1's l1: 0.109522\n",
      "[2900]\ttraining's l1: 0.0228367\tvalid_1's l1: 0.109332\n",
      "[3000]\ttraining's l1: 0.0220356\tvalid_1's l1: 0.109163\n",
      "[3100]\ttraining's l1: 0.0212789\tvalid_1's l1: 0.108981\n",
      "[3200]\ttraining's l1: 0.0205313\tvalid_1's l1: 0.108823\n",
      "[3300]\ttraining's l1: 0.0198397\tvalid_1's l1: 0.108658\n",
      "[3400]\ttraining's l1: 0.0191863\tvalid_1's l1: 0.108503\n",
      "[3500]\ttraining's l1: 0.0185743\tvalid_1's l1: 0.108381\n",
      "[3600]\ttraining's l1: 0.0179903\tvalid_1's l1: 0.108261\n",
      "[3700]\ttraining's l1: 0.0174373\tvalid_1's l1: 0.108128\n",
      "[3800]\ttraining's l1: 0.0169\tvalid_1's l1: 0.107997\n",
      "[3900]\ttraining's l1: 0.0163909\tvalid_1's l1: 0.107902\n",
      "[4000]\ttraining's l1: 0.0159153\tvalid_1's l1: 0.107816\n",
      "[4100]\ttraining's l1: 0.0154663\tvalid_1's l1: 0.107718\n",
      "[4200]\ttraining's l1: 0.015024\tvalid_1's l1: 0.107632\n",
      "[4300]\ttraining's l1: 0.0146193\tvalid_1's l1: 0.107556\n",
      "[4400]\ttraining's l1: 0.0142217\tvalid_1's l1: 0.107484\n",
      "[4500]\ttraining's l1: 0.0138548\tvalid_1's l1: 0.107406\n",
      "[4600]\ttraining's l1: 0.0134838\tvalid_1's l1: 0.107342\n",
      "[4700]\ttraining's l1: 0.0131435\tvalid_1's l1: 0.107266\n",
      "[4800]\ttraining's l1: 0.0128168\tvalid_1's l1: 0.107212\n",
      "[4900]\ttraining's l1: 0.0125074\tvalid_1's l1: 0.107149\n",
      "[5000]\ttraining's l1: 0.0122057\tvalid_1's l1: 0.107102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l1: 0.0122057\tvalid_1's l1: 0.107102\n",
      "3JHN Fold 4, logMAE: -2.2339728742651306\n",
      "Wall time: 3h 26min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_params = {\n",
    "    '1JHN': 7,\n",
    "    '1JHC': 10,\n",
    "    '2JHH': 9,\n",
    "    '2JHN': 9,\n",
    "    '2JHC': 9,\n",
    "    '3JHH': 9,\n",
    "    '3JHC': 10,\n",
    "    '3JHN': 10\n",
    "}\n",
    "N_FOLDS = 5\n",
    "submission = submission_csv.copy()\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission, n_atoms=model_params[coupling_type], n_folds=N_FOLDS)\n",
    "    cv_scores[coupling_type] = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1JHN</td>\n",
       "      <td>-0.996985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1JHC</td>\n",
       "      <td>-0.373610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2JHH</td>\n",
       "      <td>-1.805959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2JHN</td>\n",
       "      <td>-1.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2JHC</td>\n",
       "      <td>-1.343571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3JHH</td>\n",
       "      <td>-1.866846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3JHC</td>\n",
       "      <td>-1.250684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3JHN</td>\n",
       "      <td>-2.231360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  cv_score\n",
       "0  1JHN -0.996985\n",
       "1  1JHC -0.373610\n",
       "2  2JHH -1.805959\n",
       "3  2JHN -1.999981\n",
       "4  2JHC -1.343571\n",
       "5  3JHH -1.866846\n",
       "6  3JHC -1.250684\n",
       "7  3JHN -2.231360"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4836246534105204"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['scalar_coupling_constant'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgb_5fold_5k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
